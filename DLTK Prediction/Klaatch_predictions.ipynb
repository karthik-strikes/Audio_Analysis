{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~/dlatk_aug18/dlatk/dlatkInterface.py -d alz_dem -t goo -c message_id -f 'feat$1to3gram$goo$message_id$16to16' 'feat$cat_LIWC2015$goo$message_id$1gra' 'feat$cat_goo_50_cp_w$goo$message_id$1gra' --outcome_table goo_labels --outcomes label --train_classifiers --model etc --picklefile 1to3grams_LIWC_50topics_etc_goo_health.pickl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! python /home/karthik9/TheDlatk/dlatk/dlatkInterface.py -d alz_dem -t goo  -c message_id \\\n",
    "# -f  'feat$cat_LIWC2015$goo$message_id$1gra' 'feat$cat_goo_50_cp_w$goo$message_id$1gra' \\\n",
    "# --predict_classifiers_to_outcome_table label \\\n",
    "# --load_model --picklefile '/home/karthik9/LIWC_50topics_etc_goo_health.pickle'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! python /home/karthik9/TheDlatk/dlatk/dlatkInterface.py -d alz_dem -t goo  -c message_id \\\n",
    "# -f  'feat$cat_LIWC2015$goo$message_id$1gra' 'feat$cat_goo_50_cp_w$goo$message_id$1gra' \\\n",
    "#     --outcome_table goo_labels --outcomes label \\\n",
    "#     --save_model \\\n",
    "#     --train_classifiers --model etc --picklefile LIWC_50topics_etc_goo_health.pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Warning: Cannot import langid (cannot use addLanguageFilterTable)\n",
      "TopicExtractor: gensim Mallet wrapper unavailable, using Mallet directly.\n",
      "\n",
      "-----\n",
      "DLATK Interface Initiated: 2025-03-19 14:35:00\n",
      "-----\n",
      "Loading Outcomes and Getting Groups for: {'CEL_Total'}\n",
      "    ***explicit fold labels specified, not splitting again***\n",
      "[number of groups: 1468 (5 Folds)]\n",
      "\n",
      "\n",
      "|COMBO: ()|\n",
      "===========\n",
      "\n",
      "= CEL_Total (w/ lang.)=\n",
      "-----------------------\n",
      "Fold 0 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1175    Test size: 293]\n",
      " X[0]: (N, features): (1175, 38)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1175, 38)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (293, 38)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 38), ('_n_samples', 1175), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: -0.0364 (MSE: 2.9639; MAE: 1.3477; mean train mae: 1.3558)\n",
      "Fold 1 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1175    Test size: 293]\n",
      " X[0]: (N, features): (1175, 38)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1175, 38)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (293, 38)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 38), ('_n_samples', 1175), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: -0.0088 (MSE: 4.6720; MAE: 1.6994; mean train mae: 1.6470)\n",
      "Fold 2 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1174    Test size: 294]\n",
      " X[0]: (N, features): (1174, 38)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1174, 38)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (294, 38)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 38), ('_n_samples', 1174), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: -0.0272 (MSE: 4.4845; MAE: 1.5061; mean train mae: 1.5240)\n",
      "Fold 3 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1174    Test size: 294]\n",
      " X[0]: (N, features): (1174, 38)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1174, 38)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (294, 38)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 38), ('_n_samples', 1174), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: 0.0425 (MSE: 4.7137; MAE: 1.6757; mean train mae: 1.7162)\n",
      "Fold 4 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1174    Test size: 294]\n",
      " X[0]: (N, features): (1174, 38)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1174, 38)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (294, 38)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 38), ('_n_samples', 1174), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: -0.0755 (MSE: 3.4135; MAE: 1.4151; mean train mae: 1.3278)\n",
      "/home/karthik9/TheDlatk/dlatk/dlatk/regressionPredictor.py:1398: RuntimeWarning: invalid value encountered in sqrt\n",
      "  reportStats['R'] = sqrt(reportStats['R2'])\n",
      "*Overall R^2:          -0.0051\n",
      "*Overall FOLDS R^2:    -0.0211 (+- 0.0172)\n",
      "*R (sqrt R^2):         nan\n",
      "*Pearson r:            0.1523 (p = 0.00000)\n",
      "*Folds Pearson r:      0.1595 (p = 0.01592)\n",
      "*Spearman rho:         0.1706 (p = 0.00000)\n",
      "*Mean Squared Error:   4.0499\n",
      "*Mean Absolute Error:  1.5288\n",
      "*Train_Mean MAE:       0.5004\n",
      "\n",
      "[TEST COMPLETE]\n",
      "\n",
      "{'CEL_Total': {(): {1: {'N': 1468,\n",
      "                        'R': np.float64(nan),\n",
      "                        'R2': -0.005093248943054185,\n",
      "                        'R2_folds': np.float64(-0.021084416438038),\n",
      "                        'mae': 1.5287971162579472,\n",
      "                        'mae_folds': np.float64(1.528789934062362),\n",
      "                        'mse': 4.0498510497085976,\n",
      "                        'mse_folds': np.float64(4.049535584227529),\n",
      "                        'num_features': 38,\n",
      "                        'predictions': {'103_2021-04-21': np.float64(3.433333333333333),\n",
      "                                        '105_2021-04-29': np.float64(2.1508333333333334),\n",
      "                                        '106_2021-04-28': np.float64(2.776666666666667),\n",
      "                                        '107_2021-04-12': np.float64(3.9091666666666667),\n",
      "                                        '107_2021-04-20': np.float64(2.140833333333333),\n",
      "                                        '107_2021-06-01': np.float64(2.02),\n",
      "                                        '108_2021-04-30': np.float64(2.6633333333333336),\n",
      "                                        '109_2021-02-23': np.float64(3.2283333333333335),\n",
      "                                        '109_2021-04-19': np.float64(2.4525),\n",
      "                                        '111_2021-02-03': np.float64(2.6341666666666668),\n",
      "                                        '111_2021-11-10': np.float64(3.3383333333333334),\n",
      "                                        '111_2022-02-11': np.float64(2.9908333333333332),\n",
      "                                        '111_2022-06-08': np.float64(2.485),\n",
      "                                        '111_2022-09-20': np.float64(1.7508333333333332),\n",
      "                                        '111_2023-01-17': np.float64(3.1308333333333334),\n",
      "                                        '111_2023-05-03': np.float64(2.4225),\n",
      "                                        '111_2023-09-21': np.float64(2.8608333333333333),\n",
      "                                        '111_2024-01-11': np.float64(3.0075),\n",
      "                                        '111_2024-06-27': np.float64(2.8441666666666667),\n",
      "                                        '113_2021-04-19': np.float64(1.8166666666666667),\n",
      "                                        '117_2021-02-08': np.float64(2.881666666666667),\n",
      "                                        '117_2021-05-11': np.float64(3.17),\n",
      "                                        '117_2021-06-01': np.float64(3.2941666666666665),\n",
      "                                        '117_2021-12-13': np.float64(2.5525),\n",
      "                                        '117_2022-03-24': np.float64(2.535833333333333),\n",
      "                                        '117_2022-06-28': np.float64(3.0033333333333334),\n",
      "                                        '117_2022-12-07': np.float64(2.6416666666666666),\n",
      "                                        '117_2023-03-13': np.float64(3.0375),\n",
      "                                        '117_2023-05-11': np.float64(2.2016666666666667),\n",
      "                                        '117_2023-10-11': np.float64(2.65),\n",
      "                                        '117_2024-03-27': np.float64(2.9208333333333334),\n",
      "                                        '121_2021-04-27': np.float64(2.763333333333333),\n",
      "                                        '121_2021-06-09': np.float64(2.6875),\n",
      "                                        '124_2021-04-27': np.float64(2.6766666666666667),\n",
      "                                        '128_2021-04-28': np.float64(2.1675),\n",
      "                                        '128_2021-06-09': np.float64(2.92),\n",
      "                                        '138_2021-04-21': np.float64(2.175),\n",
      "                                        '143_2021-04-19': np.float64(2.2925),\n",
      "                                        '144_2021-02-10': np.float64(1.9816666666666667),\n",
      "                                        '144_2021-04-19': np.float64(1.7516666666666667),\n",
      "                                        '144_2021-11-01': np.float64(1.3775),\n",
      "                                        '144_2022-01-17': np.float64(1.235),\n",
      "                                        '144_2022-05-09': np.float64(0.9766666666666667),\n",
      "                                        '144_2022-09-05': np.float64(1.145),\n",
      "                                        '144_2023-01-10': np.float64(1.7758333333333334),\n",
      "                                        '144_2023-05-02': np.float64(1.0658333333333334),\n",
      "                                        '144_2023-10-06': np.float64(1.4525),\n",
      "                                        '144_2024-02-08': np.float64(1.2925),\n",
      "                                        '144_2024-07-17': np.float64(1.4166666666666667),\n",
      "                                        '144_2024-10-07': np.float64(1.4516666666666667),\n",
      "                                        '146_2021-04-23': np.float64(2.3725),\n",
      "                                        '146_2021-06-04': np.float64(2.785),\n",
      "                                        '148_2021-04-20': np.float64(3.2916666666666665),\n",
      "                                        '149_2021-05-07': np.float64(2.7975),\n",
      "                                        '154_2021-04-27': np.float64(3.7841666666666667),\n",
      "                                        '155_2021-04-20': np.float64(3.1525),\n",
      "                                        '155_2021-06-02': np.float64(2.495),\n",
      "                                        '156_2021-05-05': np.float64(2.841666666666667),\n",
      "                                        '156_2021-06-03': np.float64(2.6816666666666666),\n",
      "                                        '158_2021-04-26': np.float64(2.236666666666667),\n",
      "                                        '158_2021-11-08': np.float64(2.5525),\n",
      "                                        '158_2022-02-03': np.float64(2.6133333333333333),\n",
      "                                        '158_2022-06-13': np.float64(2.3175),\n",
      "                                        '158_2022-12-02': np.float64(2.2983333333333333),\n",
      "                                        '158_2023-03-09': np.float64(2.5391666666666666),\n",
      "                                        '158_2023-05-08': np.float64(2.6558333333333333),\n",
      "                                        '158_2023-09-21': np.float64(3.1625),\n",
      "                                        '158_2024-01-11': np.float64(3.4366666666666665),\n",
      "                                        '158_2024-07-17': np.float64(2.3966666666666665),\n",
      "                                        '162_2021-04-26': np.float64(2.2108333333333334),\n",
      "                                        '162_2021-12-21': np.float64(2.1133333333333333),\n",
      "                                        '162_2022-03-28': np.float64(2.2283333333333335),\n",
      "                                        '162_2022-07-19': np.float64(2.475),\n",
      "                                        '162_2022-12-01': np.float64(4.013333333333334),\n",
      "                                        '162_2023-02-28': np.float64(3.0775),\n",
      "                                        '162_2023-05-08': np.float64(2.54),\n",
      "                                        '162_2024-02-01': np.float64(3.0383333333333336),\n",
      "                                        '162_2024-06-24': np.float64(3.45),\n",
      "                                        '168_2021-02-22': np.float64(3.5125),\n",
      "                                        '168_2021-12-27': np.float64(3.473333333333333),\n",
      "                                        '168_2022-01-31': np.float64(3.1983333333333333),\n",
      "                                        '168_2022-08-03': np.float64(1.9533333333333334),\n",
      "                                        '168_2022-12-02': np.float64(3.2175),\n",
      "                                        '168_2023-03-10': np.float64(2.390833333333333),\n",
      "                                        '168_2023-06-21': np.float64(2.7683333333333335),\n",
      "                                        '168_2024-02-05': np.float64(3.1258333333333335),\n",
      "                                        '168_2024-08-01': np.float64(3.4183333333333334),\n",
      "                                        '170_2021-03-08': np.float64(1.9275),\n",
      "                                        '170_2022-01-20': np.float64(2.0633333333333335),\n",
      "                                        '170_2022-05-23': np.float64(2.3025),\n",
      "                                        '170_2022-12-08': np.float64(1.7616666666666667),\n",
      "                                        '170_2023-03-30': np.float64(2.2975),\n",
      "                                        '170_2023-07-31': np.float64(2.2575),\n",
      "                                        '170_2024-01-23': np.float64(2.319166666666667),\n",
      "                                        '170_2024-08-14': np.float64(2.200833333333333),\n",
      "                                        '173_2021-09-21': np.float64(2.0975),\n",
      "                                        '173_2022-03-07': np.float64(1.8675),\n",
      "                                        '173_2022-05-25': np.float64(2.6366666666666667),\n",
      "                                        '173_2022-11-10': np.float64(2.165),\n",
      "                                        '173_2023-04-11': np.float64(2.6566666666666667),\n",
      "                                        '173_2023-06-12': np.float64(2.2983333333333333),\n",
      "                                        '173_2023-11-13': np.float64(2.33),\n",
      "                                        '173_2024-02-20': np.float64(2.715),\n",
      "                                        '173_2024-08-01': np.float64(3.0325),\n",
      "                                        '180_2021-04-28': np.float64(2.7041666666666666),\n",
      "                                        '180_2021-12-02': np.float64(3.5375),\n",
      "                                        '180_2022-02-16': np.float64(2.28),\n",
      "                                        '190_2021-06-28': np.float64(3.3825),\n",
      "                                        '190_2021-12-17': np.float64(3.216666666666667),\n",
      "                                        '190_2022-03-28': np.float64(2.3891666666666667),\n",
      "                                        '190_2022-07-18': np.float64(2.985),\n",
      "                                        '190_2022-12-02': np.float64(3.3383333333333334),\n",
      "                                        '208_2021-06-03': np.float64(2.0308333333333333),\n",
      "                                        '208_2021-12-09': np.float64(2.1483333333333334),\n",
      "                                        '208_2022-03-18': np.float64(2.4058333333333333),\n",
      "                                        '208_2022-09-27': np.float64(2.7516666666666665),\n",
      "                                        '208_2023-02-08': np.float64(2.77),\n",
      "                                        '208_2023-07-19': np.float64(2.7216666666666667),\n",
      "                                        '208_2023-12-19': np.float64(2.86),\n",
      "                                        '208_2024-03-22': np.float64(2.908333333333333),\n",
      "                                        '208_2024-07-08': np.float64(3.828333333333333),\n",
      "                                        '217_2021-05-24': np.float64(2.2808333333333333),\n",
      "                                        '217_2021-12-01': np.float64(2.5658333333333334),\n",
      "                                        '217_2022-02-15': np.float64(2.5633333333333335),\n",
      "                                        '220_2021-02-11': np.float64(1.9258333333333333),\n",
      "                                        '223_2021-01-29': np.float64(2.645),\n",
      "                                        '223_2022-03-28': np.float64(1.6108333333333333),\n",
      "                                        '223_2022-07-29': np.float64(1.215),\n",
      "                                        '223_2022-12-02': np.float64(2.9166666666666665),\n",
      "                                        '223_2023-03-10': np.float64(1.68),\n",
      "                                        '237_2021-02-26': np.float64(1.6016666666666666),\n",
      "                                        '237_2021-11-30': np.float64(2.5025),\n",
      "                                        '237_2022-03-15': np.float64(1.2483333333333333),\n",
      "                                        '237_2022-06-15': np.float64(2.6341666666666668),\n",
      "                                        '237_2022-11-09': np.float64(2.0366666666666666),\n",
      "                                        '237_2023-02-01': np.float64(1.7816666666666667),\n",
      "                                        '237_2023-05-12': np.float64(1.68),\n",
      "                                        '237_2023-10-13': np.float64(3.0766666666666667),\n",
      "                                        '237_2024-01-10': np.float64(2.578333333333333),\n",
      "                                        '237_2024-05-22': np.float64(2.0741666666666667),\n",
      "                                        '241_2021-02-08': np.float64(3.4941666666666666),\n",
      "                                        '241_2021-11-01': np.float64(4.571666666666666),\n",
      "                                        '241_2022-01-31': np.float64(3.2175),\n",
      "                                        '241_2022-05-09': np.float64(3.25),\n",
      "                                        '241_2022-10-04': np.float64(3.5275),\n",
      "                                        '241_2023-02-21': np.float64(3.4858333333333333),\n",
      "                                        '241_2023-06-12': np.float64(3.7191666666666667),\n",
      "                                        '24_2021-02-09': np.float64(2.4425),\n",
      "                                        '24_2022-04-06': np.float64(1.9466666666666668),\n",
      "                                        '24_2022-08-16': np.float64(2.2983333333333333),\n",
      "                                        '24_2023-01-27': np.float64(2.7158333333333333),\n",
      "                                        '24_2023-07-19': np.float64(3.339166666666667),\n",
      "                                        '24_2024-03-13': np.float64(2.57),\n",
      "                                        '24_2024-08-29': np.float64(2.755),\n",
      "                                        '250_2021-02-01': np.float64(3.5075),\n",
      "                                        '250_2022-03-25': np.float64(3.370833333333333),\n",
      "                                        '250_2022-08-10': np.float64(2.6925),\n",
      "                                        '250_2022-12-02': np.float64(2.64),\n",
      "                                        '250_2023-04-20': np.float64(2.7866666666666666),\n",
      "                                        '255_2021-02-24': np.float64(2.9366666666666665),\n",
      "                                        '255_2021-12-29': np.float64(2.5108333333333333),\n",
      "                                        '25_2021-02-05': np.float64(3.3025),\n",
      "                                        '25_2021-07-01': np.float64(2.683333333333333),\n",
      "                                        '25_2021-12-28': np.float64(3.1175),\n",
      "                                        '25_2023-04-04': np.float64(2.5533333333333332),\n",
      "                                        '25_2023-05-02': np.float64(2.1708333333333334),\n",
      "                                        '25_2023-09-18': np.float64(3.015),\n",
      "                                        '25_2023-10-30': np.float64(3.8108333333333335),\n",
      "                                        '25_2024-01-12': np.float64(2.4758333333333336),\n",
      "                                        '25_2024-06-28': np.float64(3.15),\n",
      "                                        '264_2021-06-10': np.float64(3.37),\n",
      "                                        '264_2022-04-06': np.float64(2.8925),\n",
      "                                        '265_2021-04-27': np.float64(3.225),\n",
      "                                        '265_2021-11-15': np.float64(2.5125),\n",
      "                                        '265_2022-02-07': np.float64(2.16),\n",
      "                                        '265_2022-05-09': np.float64(3.305),\n",
      "                                        '265_2022-09-05': np.float64(2.6433333333333335),\n",
      "                                        '265_2023-01-09': np.float64(2.4233333333333333),\n",
      "                                        '265_2023-05-02': np.float64(2.7383333333333333),\n",
      "                                        '265_2023-10-05': np.float64(2.4233333333333333),\n",
      "                                        '265_2024-01-30': np.float64(2.504166666666667),\n",
      "                                        '265_2024-06-24': np.float64(2.4525),\n",
      "                                        '265_2024-09-26': np.float64(2.723333333333333),\n",
      "                                        '266_2021-04-26': np.float64(2.9191666666666665),\n",
      "                                        '266_2021-11-08': np.float64(2.1891666666666665),\n",
      "                                        '266_2022-05-16': np.float64(1.8666666666666667),\n",
      "                                        '266_2022-09-08': np.float64(2.2666666666666666),\n",
      "                                        '267_2021-06-21': np.float64(2.76),\n",
      "                                        '267_2021-11-22': np.float64(1.6966666666666668),\n",
      "                                        '267_2022-02-14': np.float64(2.3858333333333333),\n",
      "                                        '267_2022-05-25': np.float64(2.315),\n",
      "                                        '267_2022-09-13': np.float64(2.4483333333333333),\n",
      "                                        '267_2023-01-13': np.float64(2.0033333333333334),\n",
      "                                        '268_2021-02-09': np.float64(2.3091666666666666),\n",
      "                                        '270_2021-05-04': np.float64(2.6683333333333334),\n",
      "                                        '270_2021-12-01': np.float64(3.3008333333333333),\n",
      "                                        '271_2021-03-24': np.float64(2.841666666666667),\n",
      "                                        '279_2021-02-09': np.float64(1.8741666666666668),\n",
      "                                        '279_2021-12-09': np.float64(3.0108333333333333),\n",
      "                                        '279_2022-03-09': np.float64(3.7091666666666665),\n",
      "                                        '279_2022-06-09': np.float64(3.0116666666666667),\n",
      "                                        '279_2022-10-04': np.float64(1.71),\n",
      "                                        '279_2023-01-19': np.float64(2.7691666666666666),\n",
      "                                        '279_2023-06-26': np.float64(2.160833333333333),\n",
      "                                        '279_2023-11-09': np.float64(3.7708333333333335),\n",
      "                                        '279_2024-02-27': np.float64(2.8333333333333335),\n",
      "                                        '289_2021-05-18': np.float64(3.533333333333333),\n",
      "                                        '289_2021-12-01': np.float64(3.6616666666666666),\n",
      "                                        '289_2022-03-22': np.float64(3.2016666666666667),\n",
      "                                        '289_2022-06-24': np.float64(2.0075),\n",
      "                                        '289_2022-11-21': np.float64(2.2058333333333335),\n",
      "                                        '289_2023-03-03': np.float64(2.5725),\n",
      "                                        '289_2023-06-23': np.float64(2.165),\n",
      "                                        '289_2023-11-16': np.float64(2.8516666666666666),\n",
      "                                        '289_2024-02-08': np.float64(2.2333333333333334),\n",
      "                                        '289_2024-07-08': np.float64(3.2),\n",
      "                                        '30_2021-05-07': np.float64(2.0325),\n",
      "                                        '30_2021-12-02': np.float64(2.1641666666666666),\n",
      "                                        '30_2022-03-14': np.float64(1.9933333333333334),\n",
      "                                        '30_2022-06-08': np.float64(2.465),\n",
      "                                        '30_2022-10-10': np.float64(3.5283333333333333),\n",
      "                                        '30_2023-10-09': np.float64(2.5458333333333334),\n",
      "                                        '319_2021-02-10': np.float64(3.015833333333333),\n",
      "                                        '319_2021-11-02': np.float64(2.5833333333333335),\n",
      "                                        '319_2022-05-25': np.float64(3.046666666666667),\n",
      "                                        '319_2022-11-10': np.float64(3.425),\n",
      "                                        '319_2023-01-27': np.float64(2.825833333333333),\n",
      "                                        '319_2023-12-19': np.float64(2.4908333333333332),\n",
      "                                        '32_2021-05-12': np.float64(3.3),\n",
      "                                        '32_2021-11-15': np.float64(3.370833333333333),\n",
      "                                        '32_2022-02-10': np.float64(3.6358333333333333),\n",
      "                                        '32_2022-05-16': np.float64(2.466666666666667),\n",
      "                                        '32_2022-09-13': np.float64(3.5275),\n",
      "                                        '32_2023-01-13': np.float64(2.6375),\n",
      "                                        '32_2023-05-03': np.float64(2.6925),\n",
      "                                        '32_2023-09-20': np.float64(3.6441666666666666),\n",
      "                                        '32_2024-01-08': np.float64(3.54),\n",
      "                                        '32_2024-06-07': np.float64(2.404166666666667),\n",
      "                                        '32_2024-09-20': np.float64(3.9883333333333333),\n",
      "                                        '332_2021-02-09': np.float64(2.1258333333333335),\n",
      "                                        '332_2021-11-19': np.float64(2.2158333333333333),\n",
      "                                        '332_2022-02-10': np.float64(2.194166666666667),\n",
      "                                        '340_2021-01-26': np.float64(2.0866666666666664),\n",
      "                                        '340_2022-06-06': np.float64(2.995833333333333),\n",
      "                                        '340_2023-01-13': np.float64(2.4625),\n",
      "                                        '340_2023-11-09': np.float64(3.486666666666667),\n",
      "                                        '340_2024-03-18': np.float64(3.8766666666666665),\n",
      "                                        '343_2021-01-26': np.float64(2.6366666666666667),\n",
      "                                        '343_2021-11-08': np.float64(2.0075),\n",
      "                                        '343_2022-04-08': np.float64(2.4425),\n",
      "                                        '343_2022-08-01': np.float64(2.466666666666667),\n",
      "                                        '345_2021-04-26': np.float64(1.8341666666666667),\n",
      "                                        '345_2021-11-09': np.float64(1.8291666666666666),\n",
      "                                        '345_2022-02-07': np.float64(2.0083333333333333),\n",
      "                                        '345_2022-05-09': np.float64(1.7941666666666667),\n",
      "                                        '345_2022-09-06': np.float64(1.77),\n",
      "                                        '345_2023-01-17': np.float64(2.0658333333333334),\n",
      "                                        '345_2023-05-08': np.float64(1.7075),\n",
      "                                        '345_2023-09-27': np.float64(2.3025),\n",
      "                                        '345_2024-03-28': np.float64(2.685),\n",
      "                                        '345_2024-08-01': np.float64(2.359166666666667),\n",
      "                                        '360_2021-06-21': np.float64(3.174166666666667),\n",
      "                                        '360_2021-12-13': np.float64(2.6416666666666666),\n",
      "                                        '360_2022-02-18': np.float64(1.925),\n",
      "                                        '360_2022-06-06': np.float64(2.8541666666666665),\n",
      "                                        '360_2022-09-30': np.float64(3.3275),\n",
      "                                        '360_2023-02-21': np.float64(2.55),\n",
      "                                        '360_2023-06-07': np.float64(3.0283333333333333),\n",
      "                                        '361_2021-02-08': np.float64(1.6116666666666666),\n",
      "                                        '361_2021-11-02': np.float64(2.450833333333333),\n",
      "                                        '361_2022-02-10': np.float64(2.1275),\n",
      "                                        '361_2022-05-16': np.float64(1.5208333333333333),\n",
      "                                        '361_2022-09-06': np.float64(1.1958333333333333),\n",
      "                                        '361_2023-01-09': np.float64(1.8666666666666667),\n",
      "                                        '361_2023-05-12': np.float64(1.37),\n",
      "                                        '361_2023-09-13': np.float64(1.6775),\n",
      "                                        '361_2024-01-08': np.float64(1.67),\n",
      "                                        '361_2024-06-11': np.float64(1.5908333333333333),\n",
      "                                        '361_2024-09-23': np.float64(1.5975),\n",
      "                                        '369_2021-02-08': np.float64(3.3833333333333333),\n",
      "                                        '369_2021-12-07': np.float64(3.4133333333333336),\n",
      "                                        '369_2022-01-25': np.float64(2.421666666666667),\n",
      "                                        '369_2022-06-14': np.float64(3.2258333333333336),\n",
      "                                        '369_2022-10-10': np.float64(2.655),\n",
      "                                        '369_2023-01-23': np.float64(3.815),\n",
      "                                        '369_2023-05-16': np.float64(2.6158333333333332),\n",
      "                                        '369_2023-10-13': np.float64(2.705),\n",
      "                                        '369_2024-02-06': np.float64(3.3025),\n",
      "                                        '369_2024-07-11': np.float64(2.8516666666666666),\n",
      "                                        '372_2021-03-02': np.float64(3.1133333333333333),\n",
      "                                        '372_2021-12-02': np.float64(3.2083333333333335),\n",
      "                                        '372_2022-03-09': np.float64(2.408333333333333),\n",
      "                                        '372_2022-06-15': np.float64(3.0733333333333333),\n",
      "                                        '374_2021-07-01': np.float64(2.495833333333333),\n",
      "                                        '375_2021-05-10': np.float64(2.6133333333333333),\n",
      "                                        '375_2022-02-16': np.float64(2.205),\n",
      "                                        '375_2022-06-07': np.float64(2.75),\n",
      "                                        '375_2023-04-20': np.float64(1.9),\n",
      "                                        '375_2023-05-08': np.float64(2.335),\n",
      "                                        '383_2021-01-27': np.float64(2.941666666666667),\n",
      "                                        '383_2022-05-23': np.float64(2.7758333333333334),\n",
      "                                        '383_2022-11-09': np.float64(3.055),\n",
      "                                        '383_2023-01-24': np.float64(2.9091666666666667),\n",
      "                                        '383_2023-12-13': np.float64(2.441666666666667),\n",
      "                                        '386_2021-04-09': np.float64(2.3425),\n",
      "                                        '386_2021-11-02': np.float64(2.783333333333333),\n",
      "                                        '386_2022-02-03': np.float64(2.145),\n",
      "                                        '386_2022-05-25': np.float64(3.4366666666666665),\n",
      "                                        '386_2022-09-14': np.float64(2.6775),\n",
      "                                        '386_2023-01-27': np.float64(2.6058333333333334),\n",
      "                                        '386_2023-06-07': np.float64(2.3475),\n",
      "                                        '386_2023-12-06': np.float64(2.3008333333333333),\n",
      "                                        '386_2024-03-19': np.float64(2.42),\n",
      "                                        '386_2024-08-07': np.float64(2.4483333333333333),\n",
      "                                        '387_2021-05-11': np.float64(3.3358333333333334),\n",
      "                                        '387_2021-11-15': np.float64(3.2041666666666666),\n",
      "                                        '387_2022-02-10': np.float64(3.0975),\n",
      "                                        '387_2022-06-13': np.float64(3.1875),\n",
      "                                        '387_2022-12-02': np.float64(2.3133333333333335),\n",
      "                                        '387_2023-03-20': np.float64(2.96),\n",
      "                                        '393_2021-04-28': np.float64(2.2958333333333334),\n",
      "                                        '393_2021-12-20': np.float64(2.4908333333333332),\n",
      "                                        '393_2022-03-21': np.float64(2.7583333333333333),\n",
      "                                        '393_2022-07-18': np.float64(2.3633333333333333),\n",
      "                                        '393_2024-08-12': np.float64(2.2933333333333334),\n",
      "                                        '417_2021-06-03': np.float64(2.8833333333333333),\n",
      "                                        '417_2021-12-08': np.float64(2.904166666666667),\n",
      "                                        '417_2022-02-18': np.float64(3.0241666666666664),\n",
      "                                        '417_2022-06-21': np.float64(2.638333333333333),\n",
      "                                        '417_2022-11-18': np.float64(3.8233333333333333),\n",
      "                                        '417_2023-02-06': np.float64(3.3108333333333335),\n",
      "                                        '417_2023-07-19': np.float64(3.816666666666667),\n",
      "                                        '419_2021-05-17': np.float64(2.285833333333333),\n",
      "                                        '419_2022-03-25': np.float64(2.16),\n",
      "                                        '419_2022-07-18': np.float64(2.445),\n",
      "                                        '419_2022-12-08': np.float64(1.7966666666666666),\n",
      "                                        '419_2023-02-28': np.float64(1.6883333333333332),\n",
      "                                        '419_2023-05-16': np.float64(1.7025),\n",
      "                                        '419_2024-02-21': np.float64(2.625),\n",
      "                                        '419_2024-07-29': np.float64(1.4366666666666668),\n",
      "                                        '429_2021-05-10': np.float64(3.1258333333333335),\n",
      "                                        '429_2022-01-13': np.float64(3.6008333333333336),\n",
      "                                        '429_2022-06-17': np.float64(2.9025),\n",
      "                                        '429_2022-12-01': np.float64(2.890833333333333),\n",
      "                                        '429_2023-02-23': np.float64(1.8275),\n",
      "                                        '429_2023-06-07': np.float64(3.095833333333333),\n",
      "                                        '429_2023-11-30': np.float64(3.3975),\n",
      "                                        '429_2024-03-21': np.float64(3.64),\n",
      "                                        '430_2021-06-29': np.float64(2.3933333333333335),\n",
      "                                        '430_2021-12-15': np.float64(3.160833333333333),\n",
      "                                        '430_2022-03-16': np.float64(3.2558333333333334),\n",
      "                                        '430_2022-06-27': np.float64(2.470833333333333),\n",
      "                                        '435_2021-02-19': np.float64(2.5183333333333335),\n",
      "                                        '435_2022-03-14': np.float64(2.631666666666667),\n",
      "                                        '435_2022-06-13': np.float64(2.485),\n",
      "                                        '435_2022-11-01': np.float64(2.51),\n",
      "                                        '437_2021-05-10': np.float64(2.6066666666666665),\n",
      "                                        '437_2021-11-09': np.float64(2.7266666666666666),\n",
      "                                        '437_2022-02-07': np.float64(1.5991666666666666),\n",
      "                                        '437_2022-05-16': np.float64(1.5483333333333333),\n",
      "                                        '437_2022-09-06': np.float64(1.645),\n",
      "                                        '437_2023-02-17': np.float64(1.5741666666666667),\n",
      "                                        '442_2021-08-31': np.float64(3.25),\n",
      "                                        '442_2021-11-22': np.float64(3.816666666666667),\n",
      "                                        '442_2022-03-29': np.float64(2.405),\n",
      "                                        '449_2021-02-03': np.float64(1.8025),\n",
      "                                        '449_2021-12-09': np.float64(2.605),\n",
      "                                        '449_2022-09-20': np.float64(2.7825),\n",
      "                                        '453_2021-05-10': np.float64(1.8),\n",
      "                                        '453_2022-02-03': np.float64(2.2491666666666665),\n",
      "                                        '453_2022-07-06': np.float64(2.3533333333333335),\n",
      "                                        '453_2022-12-07': np.float64(1.91),\n",
      "                                        '453_2023-01-27': np.float64(2.005),\n",
      "                                        '453_2023-07-24': np.float64(2.0741666666666667),\n",
      "                                        '453_2023-12-19': np.float64(2.033333333333333),\n",
      "                                        '453_2024-03-05': np.float64(2.0225),\n",
      "                                        '453_2024-07-29': np.float64(2.5283333333333333),\n",
      "                                        '458_2021-04-28': np.float64(2.194166666666667),\n",
      "                                        '45_2021-02-05': np.float64(2.6816666666666666),\n",
      "                                        '45_2021-09-20': np.float64(2.223333333333333),\n",
      "                                        '45_2021-11-16': np.float64(2.4491666666666667),\n",
      "                                        '45_2022-02-09': np.float64(3.1908333333333334),\n",
      "                                        '45_2022-06-13': np.float64(3.515833333333333),\n",
      "                                        '45_2022-09-06': np.float64(2.34),\n",
      "                                        '45_2023-01-09': np.float64(3.3016666666666667),\n",
      "                                        '45_2023-05-02': np.float64(3.75),\n",
      "                                        '45_2023-09-13': np.float64(2.4491666666666667),\n",
      "                                        '45_2024-01-08': np.float64(2.3041666666666667),\n",
      "                                        '45_2024-07-01': np.float64(2.89),\n",
      "                                        '45_2024-09-27': np.float64(2.859166666666667),\n",
      "                                        '466_2021-02-08': np.float64(3.795),\n",
      "                                        '466_2021-12-21': np.float64(2.2),\n",
      "                                        '466_2022-01-13': np.float64(3.365),\n",
      "                                        '466_2022-06-02': np.float64(3.3325),\n",
      "                                        '466_2022-12-09': np.float64(2.3675),\n",
      "                                        '466_2023-03-02': np.float64(2.8741666666666665),\n",
      "                                        '466_2023-07-26': np.float64(2.8716666666666666),\n",
      "                                        '468_2021-05-10': np.float64(2.4391666666666665),\n",
      "                                        '468_2022-03-23': np.float64(2.7216666666666667),\n",
      "                                        '468_2022-07-11': np.float64(3.0775),\n",
      "                                        '468_2022-12-01': np.float64(3.3641666666666667),\n",
      "                                        '468_2023-02-06': np.float64(3.433333333333333),\n",
      "                                        '468_2023-05-18': np.float64(3.3633333333333333),\n",
      "                                        '468_2023-10-31': np.float64(3.035833333333333),\n",
      "                                        '468_2024-01-25': np.float64(4.050833333333333),\n",
      "                                        '469_2021-05-04': np.float64(2.6366666666666667),\n",
      "                                        '469_2021-12-06': np.float64(2.7241666666666666),\n",
      "                                        '469_2022-03-15': np.float64(3.0741666666666667),\n",
      "                                        '469_2022-07-15': np.float64(2.6175),\n",
      "                                        '469_2022-12-01': np.float64(2.7958333333333334),\n",
      "                                        '469_2023-02-23': np.float64(2.8358333333333334),\n",
      "                                        '469_2023-05-15': np.float64(2.4391666666666665),\n",
      "                                        '469_2023-10-23': np.float64(2.9408333333333334),\n",
      "                                        '469_2024-02-23': np.float64(1.6016666666666666),\n",
      "                                        '469_2024-07-02': np.float64(2.160833333333333),\n",
      "                                        '469_2024-09-27': np.float64(1.98),\n",
      "                                        '474_2021-05-10': np.float64(2.8808333333333334),\n",
      "                                        '476_2021-04-28': np.float64(2.180833333333333),\n",
      "                                        '479_2021-04-29': np.float64(2.5441666666666665),\n",
      "                                        '479_2021-11-23': np.float64(2.4716666666666667),\n",
      "                                        '483_2021-02-22': np.float64(2.3658333333333332),\n",
      "                                        '483_2022-03-28': np.float64(1.5133333333333334),\n",
      "                                        '483_2022-08-04': np.float64(2.4158333333333335),\n",
      "                                        '484_2021-03-10': np.float64(2.9633333333333334),\n",
      "                                        '485_2021-04-29': np.float64(2.4658333333333333),\n",
      "                                        '485_2021-11-15': np.float64(3.0825),\n",
      "                                        '485_2022-02-07': np.float64(2.6258333333333335),\n",
      "                                        '489_2021-05-13': np.float64(3.4358333333333335),\n",
      "                                        '489_2021-12-02': np.float64(3.7583333333333333),\n",
      "                                        '489_2022-02-01': np.float64(2.1233333333333335),\n",
      "                                        '489_2022-11-03': np.float64(2.0708333333333333),\n",
      "                                        '489_2024-03-19': np.float64(3.2666666666666666),\n",
      "                                        '48_2021-06-21': np.float64(2.7416666666666667),\n",
      "                                        '48_2021-11-19': np.float64(2.7691666666666666),\n",
      "                                        '48_2022-02-10': np.float64(3.0433333333333334),\n",
      "                                        '48_2022-05-27': np.float64(3.1991666666666667),\n",
      "                                        '48_2022-09-14': np.float64(2.8933333333333335),\n",
      "                                        '48_2023-01-10': np.float64(4.315833333333333),\n",
      "                                        '48_2023-05-03': np.float64(3.2491666666666665),\n",
      "                                        '48_2023-10-02': np.float64(4.255833333333333),\n",
      "                                        '48_2024-01-30': np.float64(3.5866666666666664),\n",
      "                                        '490_2021-05-10': np.float64(2.308333333333333),\n",
      "                                        '490_2022-03-29': np.float64(1.9533333333333334),\n",
      "                                        '490_2023-04-27': np.float64(3.2066666666666666),\n",
      "                                        '492_2021-03-08': np.float64(2.8808333333333334),\n",
      "                                        '492_2021-11-02': np.float64(2.0516666666666667),\n",
      "                                        '492_2022-02-03': np.float64(1.9925),\n",
      "                                        '492_2022-05-09': np.float64(1.9258333333333333),\n",
      "                                        '492_2022-09-06': np.float64(2.3041666666666667),\n",
      "                                        '492_2023-01-10': np.float64(2.2158333333333333),\n",
      "                                        '492_2023-05-03': np.float64(2.1075),\n",
      "                                        '492_2023-09-21': np.float64(2.9166666666666665),\n",
      "                                        '492_2024-01-11': np.float64(1.9975),\n",
      "                                        '494_2021-06-03': np.float64(2.8925),\n",
      "                                        '498_2021-04-13': np.float64(2.025),\n",
      "                                        '498_2021-11-08': np.float64(1.7908333333333333),\n",
      "                                        '498_2022-01-31': np.float64(2.3625),\n",
      "                                        '498_2022-06-13': np.float64(2.5516666666666667),\n",
      "                                        '498_2022-11-10': np.float64(2.1575),\n",
      "                                        '498_2023-02-07': np.float64(2.2475),\n",
      "                                        '498_2023-05-24': np.float64(2.5616666666666665),\n",
      "                                        '498_2023-10-13': np.float64(2.6566666666666667),\n",
      "                                        '498_2024-03-01': np.float64(2.46),\n",
      "                                        '498_2024-08-05': np.float64(2.674166666666667),\n",
      "                                        '501_2021-02-02': np.float64(2.7716666666666665),\n",
      "                                        '501_2022-01-07': np.float64(2.8808333333333334),\n",
      "                                        '501_2022-05-09': np.float64(3.545),\n",
      "                                        '501_2022-11-16': np.float64(1.9558333333333333),\n",
      "                                        '501_2023-02-02': np.float64(2.2425),\n",
      "                                        '501_2023-05-11': np.float64(1.9791666666666667),\n",
      "                                        '501_2023-10-30': np.float64(2.6191666666666666),\n",
      "                                        '501_2024-01-12': np.float64(2.9741666666666666),\n",
      "                                        '501_2024-06-07': np.float64(2.763333333333333),\n",
      "                                        '504_2021-03-08': np.float64(3.6366666666666667),\n",
      "                                        '504_2021-11-02': np.float64(3.5025),\n",
      "                                        '504_2022-02-03': np.float64(3.2316666666666665),\n",
      "                                        '504_2022-05-18': np.float64(3.395),\n",
      "                                        '504_2022-09-08': np.float64(3.4908333333333332),\n",
      "                                        '504_2023-01-27': np.float64(3.6908333333333334),\n",
      "                                        '504_2023-08-02': np.float64(3.171666666666667),\n",
      "                                        '504_2023-11-15': np.float64(3.6508333333333334),\n",
      "                                        '504_2024-02-12': np.float64(4.3575),\n",
      "                                        '504_2024-09-27': np.float64(2.8041666666666667),\n",
      "                                        '506_2021-02-25': np.float64(3.4366666666666665),\n",
      "                                        '506_2022-07-19': np.float64(4.424166666666666),\n",
      "                                        '506_2022-12-13': np.float64(3.505),\n",
      "                                        '507_2021-02-09': np.float64(2.9966666666666666),\n",
      "                                        '507_2022-07-13': np.float64(3.1233333333333335),\n",
      "                                        '507_2022-12-06': np.float64(2.4341666666666666),\n",
      "                                        '507_2023-03-20': np.float64(2.9066666666666667),\n",
      "                                        '507_2023-07-31': np.float64(2.8466666666666667),\n",
      "                                        '507_2023-11-27': np.float64(2.37),\n",
      "                                        '509_2021-08-25': np.float64(2.8175),\n",
      "                                        '509_2022-03-22': np.float64(2.348333333333333),\n",
      "                                        '509_2022-08-03': np.float64(3.0508333333333333),\n",
      "                                        '509_2023-04-27': np.float64(1.8683333333333334),\n",
      "                                        '509_2023-08-28': np.float64(2.2733333333333334),\n",
      "                                        '509_2023-11-17': np.float64(3.160833333333333),\n",
      "                                        '509_2024-02-16': np.float64(2.591666666666667),\n",
      "                                        '509_2024-08-16': np.float64(2.2591666666666668),\n",
      "                                        '50_2021-01-29': np.float64(2.5675),\n",
      "                                        '50_2022-01-19': np.float64(2.6366666666666667),\n",
      "                                        '50_2022-05-19': np.float64(2.618333333333333),\n",
      "                                        '511_2021-02-25': np.float64(2.7641666666666667),\n",
      "                                        '511_2021-12-27': np.float64(3.1375),\n",
      "                                        '511_2022-03-25': np.float64(3.046666666666667),\n",
      "                                        '511_2022-07-14': np.float64(3.015),\n",
      "                                        '511_2022-12-07': np.float64(3.5283333333333333),\n",
      "                                        '511_2023-03-10': np.float64(4.655833333333334),\n",
      "                                        '511_2023-06-26': np.float64(3.6483333333333334),\n",
      "                                        '511_2023-12-18': np.float64(2.7816666666666667),\n",
      "                                        '511_2024-03-25': np.float64(3.2083333333333335),\n",
      "                                        '511_2024-08-26': np.float64(4.145),\n",
      "                                        '512_2021-02-03': np.float64(2.3766666666666665),\n",
      "                                        '512_2022-03-22': np.float64(2.9183333333333334),\n",
      "                                        '512_2022-07-19': np.float64(2.3383333333333334),\n",
      "                                        '517_2021-05-17': np.float64(2.4458333333333333),\n",
      "                                        '517_2021-12-21': np.float64(2.5625),\n",
      "                                        '517_2022-04-11': np.float64(2.466666666666667),\n",
      "                                        '517_2022-08-16': np.float64(2.1616666666666666),\n",
      "                                        '517_2022-11-22': np.float64(2.45),\n",
      "                                        '517_2023-04-10': np.float64(2.695),\n",
      "                                        '517_2023-08-14': np.float64(2.1108333333333333),\n",
      "                                        '517_2024-03-28': np.float64(2.734166666666667),\n",
      "                                        '519_2021-06-14': np.float64(2.5883333333333334),\n",
      "                                        '519_2021-12-09': np.float64(2.4633333333333334),\n",
      "                                        '519_2022-02-18': np.float64(2.4125),\n",
      "                                        '519_2022-06-21': np.float64(2.0658333333333334),\n",
      "                                        '519_2022-11-18': np.float64(2.9925),\n",
      "                                        '519_2023-02-10': np.float64(2.859166666666667),\n",
      "                                        '519_2023-05-19': np.float64(2.78),\n",
      "                                        '519_2023-11-13': np.float64(2.4741666666666666),\n",
      "                                        '519_2024-02-12': np.float64(2.19),\n",
      "                                        '519_2024-06-05': np.float64(2.7883333333333336),\n",
      "                                        '519_2024-09-18': np.float64(2.8316666666666666),\n",
      "                                        '51_2021-05-04': np.float64(1.71),\n",
      "                                        '522_2021-06-18': np.float64(1.9808333333333332),\n",
      "                                        '522_2021-12-10': np.float64(1.9391666666666667),\n",
      "                                        '522_2022-03-18': np.float64(1.9758333333333333),\n",
      "                                        '522_2022-07-13': np.float64(1.6941666666666666),\n",
      "                                        '522_2022-12-01': np.float64(1.9666666666666666),\n",
      "                                        '522_2023-02-21': np.float64(1.435),\n",
      "                                        '522_2023-10-05': np.float64(1.9458333333333333),\n",
      "                                        '522_2024-02-01': np.float64(1.445),\n",
      "                                        '522_2024-08-13': np.float64(2.1891666666666665),\n",
      "                                        '523_2021-05-10': np.float64(2.2983333333333333),\n",
      "                                        '523_2021-12-22': np.float64(2.7758333333333334),\n",
      "                                        '523_2022-03-29': np.float64(2.5475),\n",
      "                                        '523_2022-07-13': np.float64(2.8325),\n",
      "                                        '526_2021-05-24': np.float64(3.6475),\n",
      "                                        '526_2022-03-18': np.float64(2.6133333333333333),\n",
      "                                        '526_2022-06-23': np.float64(2.8991666666666664),\n",
      "                                        '526_2023-01-13': np.float64(3.155),\n",
      "                                        '526_2023-05-10': np.float64(2.671666666666667),\n",
      "                                        '526_2023-09-19': np.float64(4.189166666666667),\n",
      "                                        '526_2024-03-19': np.float64(2.675),\n",
      "                                        '526_2024-08-08': np.float64(4.786666666666667),\n",
      "                                        '527_2021-02-05': np.float64(3.098333333333333),\n",
      "                                        '527_2021-07-01': np.float64(4.9375),\n",
      "                                        '527_2021-12-22': np.float64(2.4466666666666668),\n",
      "                                        '527_2022-04-19': np.float64(2.22),\n",
      "                                        '527_2022-07-19': np.float64(3.3133333333333335),\n",
      "                                        '527_2023-03-09': np.float64(2.595),\n",
      "                                        '527_2023-05-02': np.float64(2.99),\n",
      "                                        '527_2023-09-08': np.float64(2.9125),\n",
      "                                        '527_2024-03-13': np.float64(2.691666666666667),\n",
      "                                        '530_2021-05-13': np.float64(3.2683333333333335),\n",
      "                                        '530_2021-11-24': np.float64(2.7816666666666667),\n",
      "                                        '530_2022-02-14': np.float64(3.0416666666666665),\n",
      "                                        '530_2022-06-07': np.float64(2.5541666666666667),\n",
      "                                        '530_2023-01-09': np.float64(2.0725),\n",
      "                                        '530_2023-05-02': np.float64(2.216666666666667),\n",
      "                                        '530_2023-09-20': np.float64(2.125),\n",
      "                                        '530_2024-01-11': np.float64(2.2266666666666666),\n",
      "                                        '530_2024-06-10': np.float64(1.7233333333333334),\n",
      "                                        '530_2024-09-17': np.float64(2.2466666666666666),\n",
      "                                        '533_2021-05-07': np.float64(2.9475),\n",
      "                                        '533_2021-12-02': np.float64(3.29),\n",
      "                                        '533_2022-07-14': np.float64(3.1058333333333334),\n",
      "                                        '534_2021-02-26': np.float64(2.6508333333333334),\n",
      "                                        '535_2021-07-16': np.float64(2.8183333333333334),\n",
      "                                        '536_2021-05-05': np.float64(3.6491666666666664),\n",
      "                                        '536_2022-02-14': np.float64(2.0033333333333334),\n",
      "                                        '536_2022-05-24': np.float64(2.3466666666666667),\n",
      "                                        '542_2021-02-25': np.float64(1.6375),\n",
      "                                        '542_2021-09-21': np.float64(1.8283333333333334),\n",
      "                                        '542_2022-03-22': np.float64(1.9825),\n",
      "                                        '545_2021-06-02': np.float64(2.9225),\n",
      "                                        '545_2022-03-07': np.float64(2.1416666666666666),\n",
      "                                        '545_2022-06-08': np.float64(2.7158333333333333),\n",
      "                                        '545_2023-04-06': np.float64(2.555),\n",
      "                                        '545_2023-05-15': np.float64(2.2533333333333334),\n",
      "                                        '545_2023-09-18': np.float64(3.129166666666667),\n",
      "                                        '545_2024-02-08': np.float64(3.385),\n",
      "                                        '545_2024-07-24': np.float64(3.0516666666666667),\n",
      "                                        '546_2021-07-20': np.float64(3.225),\n",
      "                                        '546_2022-03-15': np.float64(2.855),\n",
      "                                        '546_2022-05-31': np.float64(1.8683333333333334),\n",
      "                                        '547_2021-02-24': np.float64(2.125),\n",
      "                                        '547_2021-12-06': np.float64(3.0591666666666666),\n",
      "                                        '548_2021-06-11': np.float64(2.2316666666666665),\n",
      "                                        '548_2021-12-09': np.float64(2.53),\n",
      "                                        '548_2022-03-16': np.float64(2.785),\n",
      "                                        '548_2022-08-03': np.float64(2.4758333333333336),\n",
      "                                        '548_2023-04-07': np.float64(2.533333333333333),\n",
      "                                        '548_2023-05-03': np.float64(1.8025),\n",
      "                                        '548_2023-09-07': np.float64(1.9375),\n",
      "                                        '548_2024-01-12': np.float64(2.0241666666666664),\n",
      "                                        '548_2024-07-30': np.float64(1.6133333333333333),\n",
      "                                        '549_2021-07-13': np.float64(3.2425),\n",
      "                                        '553_2021-07-13': np.float64(2.515),\n",
      "                                        '553_2022-08-03': np.float64(2.245),\n",
      "                                        '553_2023-03-01': np.float64(2.6341666666666668),\n",
      "                                        '553_2023-05-10': np.float64(1.56),\n",
      "                                        '553_2023-06-02': np.float64(2.5566666666666666),\n",
      "                                        '555_2021-05-05': np.float64(3.2175),\n",
      "                                        '555_2021-11-30': np.float64(4.493333333333333),\n",
      "                                        '555_2022-03-16': np.float64(4.278333333333333),\n",
      "                                        '555_2022-07-13': np.float64(3.049166666666667),\n",
      "                                        '555_2023-04-03': np.float64(4.155),\n",
      "                                        '555_2023-05-03': np.float64(2.9408333333333334),\n",
      "                                        '555_2023-10-09': np.float64(3.41),\n",
      "                                        '555_2024-03-01': np.float64(4.99),\n",
      "                                        '555_2024-06-28': np.float64(4.5441666666666665),\n",
      "                                        '555_2024-09-27': np.float64(3.0183333333333335),\n",
      "                                        '557_2021-05-24': np.float64(3.1725),\n",
      "                                        '557_2022-02-14': np.float64(2.935),\n",
      "                                        '557_2022-05-31': np.float64(3.0),\n",
      "                                        '557_2023-04-19': np.float64(2.4825),\n",
      "                                        '557_2023-05-15': np.float64(2.9791666666666665),\n",
      "                                        '559_2021-01-22': np.float64(3.02),\n",
      "                                        '559_2021-09-13': np.float64(3.091666666666667),\n",
      "                                        '560_2021-06-03': np.float64(3.4966666666666666),\n",
      "                                        '560_2022-03-14': np.float64(2.7733333333333334),\n",
      "                                        '560_2022-08-29': np.float64(2.8541666666666665),\n",
      "                                        '560_2023-04-12': np.float64(2.5833333333333335),\n",
      "                                        '561_2021-07-20': np.float64(2.8333333333333335),\n",
      "                                        '562_2021-06-09': np.float64(2.7508333333333335),\n",
      "                                        '562_2021-12-14': np.float64(2.755),\n",
      "                                        '562_2022-03-14': np.float64(2.9608333333333334),\n",
      "                                        '562_2022-05-31': np.float64(2.8375),\n",
      "                                        '562_2023-03-13': np.float64(2.7525),\n",
      "                                        '562_2023-05-04': np.float64(2.9675),\n",
      "                                        '562_2023-09-05': np.float64(3.533333333333333),\n",
      "                                        '562_2024-03-20': np.float64(3.1683333333333334),\n",
      "                                        '562_2024-08-07': np.float64(3.0883333333333334),\n",
      "                                        '563_2021-06-07': np.float64(4.180833333333333),\n",
      "                                        '563_2021-12-14': np.float64(2.4225),\n",
      "                                        '563_2022-03-18': np.float64(3.065),\n",
      "                                        '563_2022-06-22': np.float64(3.425),\n",
      "                                        '563_2022-11-10': np.float64(4.1433333333333335),\n",
      "                                        '563_2023-04-19': np.float64(2.6708333333333334),\n",
      "                                        '563_2023-06-12': np.float64(1.6116666666666666),\n",
      "                                        '563_2023-11-13': np.float64(2.1725),\n",
      "                                        '563_2024-04-02': np.float64(1.8),\n",
      "                                        '564_2021-05-21': np.float64(3.3108333333333335),\n",
      "                                        '564_2022-03-29': np.float64(3.1841666666666666),\n",
      "                                        '566_2021-06-17': np.float64(2.5483333333333333),\n",
      "                                        '566_2021-12-14': np.float64(3.0175),\n",
      "                                        '566_2022-03-16': np.float64(3.2308333333333334),\n",
      "                                        '566_2022-06-22': np.float64(2.8675),\n",
      "                                        '567_2022-03-07': np.float64(2.575833333333333),\n",
      "                                        '567_2022-06-15': np.float64(3.430833333333333),\n",
      "                                        '567_2022-11-14': np.float64(2.5675),\n",
      "                                        '567_2023-04-25': np.float64(2.8741666666666665),\n",
      "                                        '567_2023-12-12': np.float64(2.5258333333333334),\n",
      "                                        '567_2024-02-20': np.float64(2.7516666666666665),\n",
      "                                        '567_2024-07-23': np.float64(2.4858333333333333),\n",
      "                                        '569_2021-05-24': np.float64(2.319166666666667),\n",
      "                                        '569_2022-03-07': np.float64(2.1275),\n",
      "                                        '569_2022-06-22': np.float64(2.5016666666666665),\n",
      "                                        '569_2023-04-13': np.float64(2.1225),\n",
      "                                        '569_2023-05-08': np.float64(2.3558333333333334),\n",
      "                                        '56_2021-04-29': np.float64(2.7575),\n",
      "                                        '56_2021-11-15': np.float64(3.243333333333333),\n",
      "                                        '571_2021-03-08': np.float64(1.7216666666666667),\n",
      "                                        '573_2021-09-13': np.float64(2.3266666666666667),\n",
      "                                        '573_2022-03-22': np.float64(2.22),\n",
      "                                        '573_2023-03-14': np.float64(2.9141666666666666),\n",
      "                                        '573_2023-05-04': np.float64(3.8825),\n",
      "                                        '573_2023-12-13': np.float64(3.2733333333333334),\n",
      "                                        '573_2024-03-22': np.float64(3.34),\n",
      "                                        '577_2021-02-24': np.float64(2.7025),\n",
      "                                        '577_2022-03-18': np.float64(2.379166666666667),\n",
      "                                        '577_2022-08-02': np.float64(3.3133333333333335),\n",
      "                                        '580_2021-08-25': np.float64(3.145),\n",
      "                                        '581_2021-06-01': np.float64(2.464166666666667),\n",
      "                                        '581_2022-02-15': np.float64(2.8208333333333333),\n",
      "                                        '581_2022-08-03': np.float64(2.7075),\n",
      "                                        '581_2023-04-11': np.float64(2.6375),\n",
      "                                        '581_2023-06-22': np.float64(2.985),\n",
      "                                        '581_2023-10-12': np.float64(2.835),\n",
      "                                        '581_2024-03-01': np.float64(2.995833333333333),\n",
      "                                        '581_2024-07-31': np.float64(2.8033333333333332),\n",
      "                                        '584_2021-07-01': np.float64(2.225),\n",
      "                                        '584_2022-04-19': np.float64(2.3241666666666667),\n",
      "                                        '584_2022-08-02': np.float64(2.585),\n",
      "                                        '584_2023-04-13': np.float64(3.4591666666666665),\n",
      "                                        '593_2021-06-02': np.float64(4.615),\n",
      "                                        '593_2021-12-23': np.float64(4.189166666666667),\n",
      "                                        '593_2022-07-18': np.float64(3.1841666666666666),\n",
      "                                        '593_2023-04-14': np.float64(3.381666666666667),\n",
      "                                        '593_2023-05-24': np.float64(3.7941666666666665),\n",
      "                                        '593_2023-11-10': np.float64(3.1491666666666664),\n",
      "                                        '598_2021-06-01': np.float64(2.0075),\n",
      "                                        '598_2021-12-21': np.float64(2.7758333333333334),\n",
      "                                        '598_2022-04-19': np.float64(2.2716666666666665),\n",
      "                                        '598_2022-07-20': np.float64(2.1875),\n",
      "                                        '598_2023-04-07': np.float64(2.4341666666666666),\n",
      "                                        '598_2023-05-08': np.float64(1.9225),\n",
      "                                        '598_2023-09-14': np.float64(2.6258333333333335),\n",
      "                                        '598_2024-01-12': np.float64(2.935),\n",
      "                                        '598_2024-09-27': np.float64(2.07),\n",
      "                                        '599_2021-06-17': np.float64(3.3766666666666665),\n",
      "                                        '599_2021-12-23': np.float64(2.263333333333333),\n",
      "                                        '599_2022-03-30': np.float64(3.0508333333333333),\n",
      "                                        '600_2021-03-08': np.float64(3.3366666666666664),\n",
      "                                        '600_2021-11-02': np.float64(2.2291666666666665),\n",
      "                                        '600_2022-02-07': np.float64(2.6866666666666665),\n",
      "                                        '600_2022-05-16': np.float64(2.2308333333333334),\n",
      "                                        '600_2022-09-07': np.float64(2.3116666666666665),\n",
      "                                        '600_2023-01-10': np.float64(2.216666666666667),\n",
      "                                        '600_2023-05-08': np.float64(2.0608333333333335),\n",
      "                                        '600_2023-09-21': np.float64(1.8908333333333334),\n",
      "                                        '600_2024-01-11': np.float64(1.88),\n",
      "                                        '600_2024-07-17': np.float64(2.0533333333333332),\n",
      "                                        '601_2021-07-13': np.float64(3.845),\n",
      "                                        '601_2022-03-29': np.float64(2.299166666666667),\n",
      "                                        '601_2022-07-13': np.float64(3.2391666666666667),\n",
      "                                        '601_2023-04-28': np.float64(3.194166666666667),\n",
      "                                        '604_2021-06-17': np.float64(1.9308333333333334),\n",
      "                                        '604_2021-12-23': np.float64(2.0091666666666668),\n",
      "                                        '604_2022-04-26': np.float64(2.0125),\n",
      "                                        '604_2022-08-29': np.float64(2.5033333333333334),\n",
      "                                        '604_2023-02-23': np.float64(2.2466666666666666),\n",
      "                                        '604_2023-06-09': np.float64(2.4783333333333335),\n",
      "                                        '604_2023-11-07': np.float64(1.8866666666666667),\n",
      "                                        '604_2024-03-05': np.float64(2.3941666666666666),\n",
      "                                        '604_2024-08-12': np.float64(2.6483333333333334),\n",
      "                                        '606_2021-01-28': np.float64(3.1033333333333335),\n",
      "                                        '606_2021-07-01': np.float64(2.5991666666666666),\n",
      "                                        '606_2021-12-22': np.float64(1.8875),\n",
      "                                        '606_2022-03-30': np.float64(2.245833333333333),\n",
      "                                        '606_2022-07-18': np.float64(2.2083333333333335),\n",
      "                                        '606_2022-11-15': np.float64(3.055833333333333),\n",
      "                                        '606_2023-04-11': np.float64(2.5166666666666666),\n",
      "                                        '606_2023-05-03': np.float64(2.6008333333333336),\n",
      "                                        '606_2023-10-25': np.float64(2.8716666666666666),\n",
      "                                        '606_2024-01-12': np.float64(2.9716666666666667),\n",
      "                                        '606_2024-06-28': np.float64(2.4491666666666667),\n",
      "                                        '606_2024-09-27': np.float64(2.8916666666666666),\n",
      "                                        '607_2021-07-13': np.float64(3.7641666666666667),\n",
      "                                        '607_2021-12-28': np.float64(3.795),\n",
      "                                        '608_2021-09-21': np.float64(2.2925),\n",
      "                                        '609_2021-06-17': np.float64(2.6875),\n",
      "                                        '609_2021-12-29': np.float64(3.225),\n",
      "                                        '609_2022-04-19': np.float64(3.0083333333333333),\n",
      "                                        '609_2022-07-19': np.float64(2.8425),\n",
      "                                        '609_2023-05-02': np.float64(2.925),\n",
      "                                        '609_2023-09-18': np.float64(2.455),\n",
      "                                        '609_2024-03-13': np.float64(2.725),\n",
      "                                        '609_2024-08-26': np.float64(2.8891666666666667),\n",
      "                                        '611_2021-05-05': np.float64(3.0125),\n",
      "                                        '611_2021-12-13': np.float64(3.986666666666667),\n",
      "                                        '613_2021-06-29': np.float64(3.7116666666666664),\n",
      "                                        '613_2022-03-14': np.float64(2.8625),\n",
      "                                        '616_2021-03-11': np.float64(2.3175),\n",
      "                                        '616_2021-12-22': np.float64(1.9233333333333333),\n",
      "                                        '617_2021-02-05': np.float64(3.4233333333333333),\n",
      "                                        '617_2021-07-09': np.float64(3.6283333333333334),\n",
      "                                        '618_2021-07-01': np.float64(2.3266666666666667),\n",
      "                                        '618_2021-12-28': np.float64(1.9975),\n",
      "                                        '618_2022-04-19': np.float64(2.129166666666667),\n",
      "                                        '618_2022-08-02': np.float64(2.2716666666666665),\n",
      "                                        '618_2023-04-06': np.float64(2.3991666666666664),\n",
      "                                        '618_2023-05-03': np.float64(2.631666666666667),\n",
      "                                        '618_2023-10-09': np.float64(3.0233333333333334),\n",
      "                                        '618_2024-01-12': np.float64(3.325),\n",
      "                                        '618_2024-08-06': np.float64(2.5808333333333335),\n",
      "                                        '61_2021-05-11': np.float64(2.6075),\n",
      "                                        '61_2021-12-27': np.float64(3.1816666666666666),\n",
      "                                        '61_2022-03-18': np.float64(2.1058333333333334),\n",
      "                                        '621_2021-12-13': np.float64(4.325833333333334),\n",
      "                                        '621_2022-03-30': np.float64(2.1283333333333334),\n",
      "                                        '621_2022-07-18': np.float64(3.506666666666667),\n",
      "                                        '621_2023-04-21': np.float64(3.73),\n",
      "                                        '621_2023-05-08': np.float64(3.2416666666666667),\n",
      "                                        '621_2023-09-06': np.float64(3.0316666666666667),\n",
      "                                        '621_2024-02-16': np.float64(3.0541666666666667),\n",
      "                                        '622_2021-06-17': np.float64(2.785833333333333),\n",
      "                                        '622_2021-12-13': np.float64(3.299166666666667),\n",
      "                                        '622_2022-03-18': np.float64(4.016666666666667),\n",
      "                                        '622_2022-06-27': np.float64(3.1958333333333333),\n",
      "                                        '622_2022-11-18': np.float64(2.7841666666666667),\n",
      "                                        '622_2023-02-21': np.float64(3.578333333333333),\n",
      "                                        '628_2021-02-01': np.float64(4.001666666666667),\n",
      "                                        '628_2021-12-02': np.float64(2.546666666666667),\n",
      "                                        '628_2022-04-11': np.float64(2.0541666666666667),\n",
      "                                        '628_2022-08-18': np.float64(2.4166666666666665),\n",
      "                                        '628_2022-11-15': np.float64(3.105),\n",
      "                                        '628_2023-03-02': np.float64(2.4466666666666668),\n",
      "                                        '628_2023-08-04': np.float64(2.6141666666666667),\n",
      "                                        '628_2024-03-27': np.float64(2.4091666666666667),\n",
      "                                        '628_2024-09-27': np.float64(2.38),\n",
      "                                        '629_2021-02-05': np.float64(2.5208333333333335),\n",
      "                                        '629_2021-07-09': np.float64(2.3983333333333334),\n",
      "                                        '629_2022-03-18': np.float64(1.7483333333333333),\n",
      "                                        '629_2022-06-28': np.float64(1.34),\n",
      "                                        '631_2021-07-01': np.float64(1.7666666666666666),\n",
      "                                        '631_2021-12-17': np.float64(1.63),\n",
      "                                        '631_2022-03-15': np.float64(1.8741666666666668),\n",
      "                                        '631_2022-07-06': np.float64(1.9516666666666667),\n",
      "                                        '631_2022-12-02': np.float64(1.8208333333333333),\n",
      "                                        '631_2023-03-13': np.float64(1.9475),\n",
      "                                        '631_2023-08-14': np.float64(2.8041666666666667),\n",
      "                                        '631_2023-11-13': np.float64(2.1016666666666666),\n",
      "                                        '633_2021-05-07': np.float64(2.638333333333333),\n",
      "                                        '633_2021-12-21': np.float64(3.45),\n",
      "                                        '633_2022-06-14': np.float64(2.4316666666666666),\n",
      "                                        '633_2022-12-01': np.float64(2.4316666666666666),\n",
      "                                        '633_2023-03-09': np.float64(2.6083333333333334),\n",
      "                                        '633_2023-07-13': np.float64(1.9033333333333333),\n",
      "                                        '634_2021-05-24': np.float64(2.861666666666667),\n",
      "                                        '634_2022-01-12': np.float64(2.3666666666666667),\n",
      "                                        '634_2022-06-08': np.float64(2.756666666666667),\n",
      "                                        '634_2022-10-10': np.float64(1.55),\n",
      "                                        '634_2023-01-27': np.float64(1.3491666666666666),\n",
      "                                        '634_2023-05-31': np.float64(2.3316666666666666),\n",
      "                                        '634_2023-11-20': np.float64(2.620833333333333),\n",
      "                                        '634_2024-03-18': np.float64(2.5991666666666666),\n",
      "                                        '634_2024-06-25': np.float64(2.9691666666666667),\n",
      "                                        '635_2021-02-05': np.float64(3.1225),\n",
      "                                        '635_2021-07-12': np.float64(3.5258333333333334),\n",
      "                                        '635_2022-03-07': np.float64(2.0),\n",
      "                                        '635_2022-11-08': np.float64(2.7816666666666667),\n",
      "                                        '635_2023-04-28': np.float64(2.0675),\n",
      "                                        '635_2023-06-22': np.float64(2.465),\n",
      "                                        '635_2024-03-14': np.float64(1.7475),\n",
      "                                        '636_2021-02-05': np.float64(1.9875),\n",
      "                                        '636_2021-09-20': np.float64(2.569166666666667),\n",
      "                                        '636_2022-05-25': np.float64(2.1783333333333332),\n",
      "                                        '636_2022-12-12': np.float64(2.345),\n",
      "                                        '636_2023-06-27': np.float64(2.8583333333333334),\n",
      "                                        '636_2023-12-18': np.float64(2.8425),\n",
      "                                        '640_2021-08-02': np.float64(2.885),\n",
      "                                        '640_2021-12-10': np.float64(2.9225),\n",
      "                                        '640_2022-03-18': np.float64(3.9166666666666665),\n",
      "                                        '640_2022-07-07': np.float64(3.2125),\n",
      "                                        '640_2022-12-05': np.float64(2.131666666666667),\n",
      "                                        '640_2023-03-09': np.float64(4.069166666666667),\n",
      "                                        '641_2021-05-21': np.float64(3.265833333333333),\n",
      "                                        '641_2022-03-24': np.float64(2.6375),\n",
      "                                        '641_2022-07-27': np.float64(2.4141666666666666),\n",
      "                                        '642_2021-02-09': np.float64(2.0233333333333334),\n",
      "                                        '642_2021-11-23': np.float64(2.6783333333333332),\n",
      "                                        '642_2022-05-31': np.float64(2.2466666666666666),\n",
      "                                        '642_2022-11-14': np.float64(3.4191666666666665),\n",
      "                                        '643_2021-05-13': np.float64(3.31),\n",
      "                                        '643_2021-12-17': np.float64(2.2191666666666667),\n",
      "                                        '643_2023-04-19': np.float64(2.7925),\n",
      "                                        '643_2023-12-21': np.float64(2.5283333333333333),\n",
      "                                        '643_2024-04-01': np.float64(2.609166666666667),\n",
      "                                        '644_2021-05-10': np.float64(1.9558333333333333),\n",
      "                                        '644_2022-03-18': np.float64(1.9166666666666667),\n",
      "                                        '644_2022-09-14': np.float64(2.4058333333333333),\n",
      "                                        '644_2023-01-18': np.float64(1.9183333333333332),\n",
      "                                        '645_2021-05-10': np.float64(2.755),\n",
      "                                        '645_2021-12-27': np.float64(3.118333333333333),\n",
      "                                        '645_2022-04-06': np.float64(2.445),\n",
      "                                        '645_2022-08-05': np.float64(2.7758333333333334),\n",
      "                                        '645_2022-12-06': np.float64(2.25),\n",
      "                                        '645_2023-04-04': np.float64(2.381666666666667),\n",
      "                                        '645_2023-08-22': np.float64(2.7583333333333333),\n",
      "                                        '645_2023-12-12': np.float64(2.6708333333333334),\n",
      "                                        '645_2024-03-27': np.float64(3.6733333333333333),\n",
      "                                        '645_2024-08-26': np.float64(3.7691666666666666),\n",
      "                                        '646_2021-02-03': np.float64(3.675),\n",
      "                                        '646_2022-03-31': np.float64(2.6958333333333333),\n",
      "                                        '646_2022-07-27': np.float64(2.3183333333333334),\n",
      "                                        '646_2022-12-13': np.float64(2.6341666666666668),\n",
      "                                        '646_2023-04-07': np.float64(3.158333333333333),\n",
      "                                        '646_2023-08-22': np.float64(2.8625),\n",
      "                                        '646_2024-03-27': np.float64(3.779166666666667),\n",
      "                                        '646_2024-08-27': np.float64(3.6225),\n",
      "                                        '650_2021-05-11': np.float64(2.4925),\n",
      "                                        '650_2021-12-06': np.float64(1.8533333333333333),\n",
      "                                        '650_2022-03-29': np.float64(3.0216666666666665),\n",
      "                                        '650_2022-07-29': np.float64(2.591666666666667),\n",
      "                                        '650_2022-12-02': np.float64(3.6283333333333334),\n",
      "                                        '650_2023-03-10': np.float64(2.5675),\n",
      "                                        '650_2023-08-04': np.float64(2.8566666666666665),\n",
      "                                        '650_2023-12-13': np.float64(3.0775),\n",
      "                                        '650_2024-03-28': np.float64(2.924166666666667),\n",
      "                                        '650_2024-08-26': np.float64(3.31),\n",
      "                                        '651_2021-05-13': np.float64(3.5175),\n",
      "                                        '651_2021-12-08': np.float64(2.375),\n",
      "                                        '651_2022-04-05': np.float64(3.2125),\n",
      "                                        '651_2022-07-21': np.float64(3.7741666666666664),\n",
      "                                        '651_2022-12-19': np.float64(2.6591666666666667),\n",
      "                                        '651_2024-08-01': np.float64(3.9191666666666665),\n",
      "                                        '652_2021-08-24': np.float64(3.2183333333333333),\n",
      "                                        '652_2021-12-15': np.float64(3.745833333333333),\n",
      "                                        '652_2022-07-11': np.float64(3.8608333333333333),\n",
      "                                        '652_2022-12-19': np.float64(3.5675),\n",
      "                                        '652_2023-01-27': np.float64(3.9458333333333333),\n",
      "                                        '652_2023-07-31': np.float64(3.005),\n",
      "                                        '653_2021-05-11': np.float64(3.0858333333333334),\n",
      "                                        '653_2022-01-11': np.float64(2.87),\n",
      "                                        '653_2022-07-11': np.float64(3.109166666666667),\n",
      "                                        '653_2022-12-06': np.float64(3.6158333333333332),\n",
      "                                        '656_2021-06-29': np.float64(3.3575),\n",
      "                                        '656_2021-12-23': np.float64(3.0991666666666666),\n",
      "                                        '656_2022-04-04': np.float64(2.6883333333333335),\n",
      "                                        '656_2022-07-21': np.float64(2.5641666666666665),\n",
      "                                        '656_2023-08-23': np.float64(1.8075),\n",
      "                                        '656_2023-12-04': np.float64(2.464166666666667),\n",
      "                                        '656_2024-02-16': np.float64(2.5141666666666667),\n",
      "                                        '656_2024-07-08': np.float64(2.2491666666666665),\n",
      "                                        '661_2021-06-23': np.float64(2.925),\n",
      "                                        '661_2021-12-01': np.float64(2.8291666666666666),\n",
      "                                        '661_2022-02-16': np.float64(2.8116666666666665),\n",
      "                                        '661_2022-06-22': np.float64(3.485),\n",
      "                                        '661_2022-11-22': np.float64(3.0166666666666666),\n",
      "                                        '661_2023-03-27': np.float64(3.0383333333333336),\n",
      "                                        '661_2023-05-15': np.float64(3.2125),\n",
      "                                        '662_2021-06-18': np.float64(2.16),\n",
      "                                        '662_2021-12-08': np.float64(2.2416666666666667),\n",
      "                                        '662_2022-02-28': np.float64(1.8383333333333334),\n",
      "                                        '662_2022-06-13': np.float64(2.245),\n",
      "                                        '662_2022-09-30': np.float64(2.5825),\n",
      "                                        '662_2023-02-13': np.float64(2.4975),\n",
      "                                        '662_2023-05-19': np.float64(2.4591666666666665),\n",
      "                                        '662_2023-10-09': np.float64(2.21),\n",
      "                                        '662_2024-03-18': np.float64(1.4508333333333334),\n",
      "                                        '662_2024-07-29': np.float64(2.3775),\n",
      "                                        '664_2021-05-13': np.float64(3.3308333333333335),\n",
      "                                        '664_2021-12-28': np.float64(3.45),\n",
      "                                        '664_2022-04-19': np.float64(3.2258333333333336),\n",
      "                                        '664_2022-08-29': np.float64(2.915),\n",
      "                                        '664_2023-04-27': np.float64(2.5108333333333333),\n",
      "                                        '664_2024-03-22': np.float64(3.1041666666666665),\n",
      "                                        '66_2021-01-26': np.float64(2.2883333333333336),\n",
      "                                        '66_2021-09-20': np.float64(2.4025),\n",
      "                                        '66_2022-02-11': np.float64(2.67),\n",
      "                                        '66_2022-05-26': np.float64(2.055833333333333),\n",
      "                                        '66_2022-10-03': np.float64(1.7708333333333333),\n",
      "                                        '66_2023-01-18': np.float64(2.0325),\n",
      "                                        '66_2023-05-10': np.float64(2.075833333333333),\n",
      "                                        '66_2023-09-11': np.float64(2.4816666666666665),\n",
      "                                        '66_2024-01-11': np.float64(2.1433333333333335),\n",
      "                                        '66_2024-06-07': np.float64(2.3575),\n",
      "                                        '66_2024-09-27': np.float64(2.5258333333333334),\n",
      "                                        '670_2022-04-19': np.float64(4.2283333333333335),\n",
      "                                        '670_2022-08-02': np.float64(2.9883333333333333),\n",
      "                                        '670_2023-04-07': np.float64(1.835),\n",
      "                                        '670_2023-05-18': np.float64(2.6341666666666668),\n",
      "                                        '670_2023-10-13': np.float64(3.0816666666666666),\n",
      "                                        '671_2021-12-02': np.float64(3.615),\n",
      "                                        '671_2022-04-14': np.float64(1.9758333333333333),\n",
      "                                        '671_2022-12-15': np.float64(1.8208333333333333),\n",
      "                                        '671_2023-04-12': np.float64(2.1533333333333333),\n",
      "                                        '673_2021-03-24': np.float64(3.046666666666667),\n",
      "                                        '673_2021-12-09': np.float64(3.348333333333333),\n",
      "                                        '673_2022-01-07': np.float64(2.815),\n",
      "                                        '673_2022-06-09': np.float64(1.7491666666666668),\n",
      "                                        '675_2021-08-11': np.float64(2.4925),\n",
      "                                        '676_2021-08-03': np.float64(3.0341666666666667),\n",
      "                                        '676_2021-12-14': np.float64(2.3),\n",
      "                                        '676_2022-04-04': np.float64(2.925),\n",
      "                                        '676_2022-07-15': np.float64(2.265833333333333),\n",
      "                                        '676_2022-11-30': np.float64(2.415),\n",
      "                                        '676_2023-06-13': np.float64(2.1175),\n",
      "                                        '676_2023-09-21': np.float64(3.0416666666666665),\n",
      "                                        '677_2021-03-03': np.float64(2.3366666666666664),\n",
      "                                        '677_2021-12-06': np.float64(2.075),\n",
      "                                        '677_2022-03-14': np.float64(1.7316666666666667),\n",
      "                                        '677_2022-12-12': np.float64(2.1141666666666667),\n",
      "                                        '677_2023-04-06': np.float64(2.1783333333333332),\n",
      "                                        '677_2023-11-15': np.float64(2.1791666666666667),\n",
      "                                        '677_2024-03-27': np.float64(1.9525),\n",
      "                                        '677_2024-08-02': np.float64(2.9166666666666665),\n",
      "                                        '678_2022-03-30': np.float64(3.984166666666667),\n",
      "                                        '678_2022-08-18': np.float64(3.8508333333333336),\n",
      "                                        '678_2022-12-08': np.float64(2.7808333333333333),\n",
      "                                        '678_2023-03-01': np.float64(3.859166666666667),\n",
      "                                        '678_2023-06-07': np.float64(3.5625),\n",
      "                                        '678_2024-03-18': np.float64(2.7941666666666665),\n",
      "                                        '678_2024-06-25': np.float64(3.1341666666666668),\n",
      "                                        '679_2021-06-07': np.float64(3.1325),\n",
      "                                        '679_2021-11-15': np.float64(3.3975),\n",
      "                                        '679_2022-02-07': np.float64(3.0733333333333333),\n",
      "                                        '679_2022-05-10': np.float64(2.6733333333333333),\n",
      "                                        '679_2022-09-08': np.float64(2.5075),\n",
      "                                        '679_2023-02-09': np.float64(3.1825),\n",
      "                                        '679_2023-05-25': np.float64(3.3291666666666666),\n",
      "                                        '679_2023-11-22': np.float64(2.779166666666667),\n",
      "                                        '679_2024-02-16': np.float64(3.0791666666666666),\n",
      "                                        '679_2024-08-12': np.float64(2.7291666666666665),\n",
      "                                        '680_2021-07-09': np.float64(2.7666666666666666),\n",
      "                                        '680_2021-10-08': np.float64(2.8141666666666665),\n",
      "                                        '680_2022-06-13': np.float64(2.74),\n",
      "                                        '680_2022-10-04': np.float64(2.9183333333333334),\n",
      "                                        '680_2023-06-01': np.float64(2.2508333333333335),\n",
      "                                        '681_2021-12-10': np.float64(2.9908333333333332),\n",
      "                                        '681_2022-03-22': np.float64(2.6325),\n",
      "                                        '681_2022-08-29': np.float64(2.6283333333333334),\n",
      "                                        '682_2021-08-04': np.float64(2.0058333333333334),\n",
      "                                        '683_2021-07-08': np.float64(2.2558333333333334),\n",
      "                                        '683_2021-12-01': np.float64(3.6875),\n",
      "                                        '683_2022-01-25': np.float64(3.6066666666666665),\n",
      "                                        '683_2022-05-19': np.float64(3.138333333333333),\n",
      "                                        '683_2022-11-02': np.float64(2.13),\n",
      "                                        '683_2023-02-09': np.float64(3.5091666666666668),\n",
      "                                        '683_2023-05-12': np.float64(2.3941666666666666),\n",
      "                                        '683_2023-10-24': np.float64(2.2583333333333333),\n",
      "                                        '683_2024-02-21': np.float64(2.424166666666667),\n",
      "                                        '683_2024-07-11': np.float64(3.154166666666667),\n",
      "                                        '685_2021-07-19': np.float64(3.029166666666667),\n",
      "                                        '686_2021-03-04': np.float64(3.549166666666667),\n",
      "                                        '686_2021-10-28': np.float64(3.2525),\n",
      "                                        '686_2022-03-25': np.float64(1.835),\n",
      "                                        '686_2022-06-17': np.float64(3.703333333333333),\n",
      "                                        '686_2022-11-18': np.float64(3.2025),\n",
      "                                        '686_2023-02-24': np.float64(3.46),\n",
      "                                        '687_2021-12-10': np.float64(2.700833333333333),\n",
      "                                        '687_2022-04-04': np.float64(2.6358333333333333),\n",
      "                                        '687_2022-08-08': np.float64(1.6683333333333332),\n",
      "                                        '687_2022-12-08': np.float64(1.5616666666666668),\n",
      "                                        '687_2023-03-13': np.float64(2.4291666666666667),\n",
      "                                        '687_2023-05-30': np.float64(2.5566666666666666),\n",
      "                                        '687_2024-02-21': np.float64(3.0058333333333334),\n",
      "                                        '689_2021-04-28': np.float64(2.82),\n",
      "                                        '689_2022-06-10': np.float64(2.8725),\n",
      "                                        '689_2022-12-06': np.float64(2.6),\n",
      "                                        '689_2023-02-27': np.float64(3.435),\n",
      "                                        '689_2023-05-08': np.float64(2.9466666666666668),\n",
      "                                        '689_2023-10-09': np.float64(2.3241666666666667),\n",
      "                                        '689_2024-02-12': np.float64(2.3975),\n",
      "                                        '689_2024-07-02': np.float64(1.6616666666666666),\n",
      "                                        '692_2022-03-28': np.float64(1.7741666666666667),\n",
      "                                        '692_2023-04-24': np.float64(3.3033333333333332),\n",
      "                                        '692_2023-09-01': np.float64(3.8033333333333332),\n",
      "                                        '692_2023-11-13': np.float64(3.03),\n",
      "                                        '692_2024-02-09': np.float64(2.5075),\n",
      "                                        '692_2024-07-30': np.float64(2.924166666666667),\n",
      "                                        '693_2021-03-05': np.float64(3.4575),\n",
      "                                        '695_2021-06-02': np.float64(1.5483333333333333),\n",
      "                                        '695_2022-03-29': np.float64(1.3766666666666667),\n",
      "                                        '695_2023-04-04': np.float64(2.7483333333333335),\n",
      "                                        '695_2023-05-04': np.float64(2.9283333333333332),\n",
      "                                        '695_2023-12-08': np.float64(3.0175),\n",
      "                                        '695_2024-03-14': np.float64(1.5425),\n",
      "                                        '695_2024-07-25': np.float64(3.0816666666666666),\n",
      "                                        '698_2021-06-18': np.float64(1.905),\n",
      "                                        '698_2022-03-18': np.float64(2.4566666666666666),\n",
      "                                        '698_2022-06-27': np.float64(1.8716666666666666),\n",
      "                                        '698_2022-12-05': np.float64(1.8791666666666667),\n",
      "                                        '698_2023-02-28': np.float64(2.145),\n",
      "                                        '698_2023-07-05': np.float64(1.7908333333333333),\n",
      "                                        '699_2022-12-05': np.float64(2.135),\n",
      "                                        '699_2023-04-19': np.float64(2.3866666666666667),\n",
      "                                        '699_2023-08-17': np.float64(2.381666666666667),\n",
      "                                        '699_2023-12-13': np.float64(2.04),\n",
      "                                        '699_2024-03-27': np.float64(2.1633333333333336),\n",
      "                                        '700_2021-11-04': np.float64(2.2275),\n",
      "                                        '700_2022-05-24': np.float64(2.1391666666666667),\n",
      "                                        '702_2021-07-08': np.float64(2.1225),\n",
      "                                        '702_2021-12-10': np.float64(2.0308333333333333),\n",
      "                                        '702_2022-04-19': np.float64(2.0791666666666666),\n",
      "                                        '702_2022-07-20': np.float64(2.6958333333333333),\n",
      "                                        '702_2023-04-13': np.float64(2.1191666666666666),\n",
      "                                        '702_2023-05-18': np.float64(1.6158333333333332),\n",
      "                                        '702_2023-10-09': np.float64(2.91),\n",
      "                                        '702_2024-02-09': np.float64(2.7266666666666666),\n",
      "                                        '702_2024-07-30': np.float64(3.2425),\n",
      "                                        '703_2021-07-29': np.float64(3.21),\n",
      "                                        '703_2021-12-08': np.float64(3.995833333333333),\n",
      "                                        '703_2022-04-11': np.float64(3.7133333333333334),\n",
      "                                        '707_2022-04-26': np.float64(2.9366666666666665),\n",
      "                                        '707_2022-08-08': np.float64(3.0841666666666665),\n",
      "                                        '707_2023-04-26': np.float64(2.618333333333333),\n",
      "                                        '709_2021-12-09': np.float64(2.6441666666666666),\n",
      "                                        '709_2022-02-22': np.float64(2.17),\n",
      "                                        '709_2022-06-21': np.float64(2.0475),\n",
      "                                        '709_2022-12-13': np.float64(1.9391666666666667),\n",
      "                                        '710_2021-08-24': np.float64(2.1858333333333335),\n",
      "                                        '710_2021-11-22': np.float64(2.005),\n",
      "                                        '710_2022-03-15': np.float64(1.98),\n",
      "                                        '710_2022-08-02': np.float64(2.129166666666667),\n",
      "                                        '710_2022-11-15': np.float64(1.8916666666666666),\n",
      "                                        '710_2023-03-03': np.float64(1.8966666666666667),\n",
      "                                        '710_2023-05-24': np.float64(1.735),\n",
      "                                        '710_2023-11-13': np.float64(1.83),\n",
      "                                        '710_2024-02-02': np.float64(1.92),\n",
      "                                        '710_2024-07-03': np.float64(1.9525),\n",
      "                                        '713_2021-08-23': np.float64(2.835),\n",
      "                                        '713_2022-04-21': np.float64(2.0775),\n",
      "                                        '713_2022-08-29': np.float64(2.3075),\n",
      "                                        '713_2022-12-07': np.float64(2.7933333333333334),\n",
      "                                        '713_2023-04-04': np.float64(2.345),\n",
      "                                        '713_2023-08-10': np.float64(2.473333333333333),\n",
      "                                        '713_2023-12-13': np.float64(2.5975),\n",
      "                                        '713_2024-03-19': np.float64(1.5775),\n",
      "                                        '715_2021-11-11': np.float64(1.2975),\n",
      "                                        '716_2022-04-07': np.float64(3.345833333333333),\n",
      "                                        '716_2022-07-26': np.float64(2.1733333333333333),\n",
      "                                        '716_2022-11-23': np.float64(3.1483333333333334),\n",
      "                                        '716_2023-02-14': np.float64(2.7175),\n",
      "                                        '716_2023-06-12': np.float64(2.8066666666666666),\n",
      "                                        '716_2023-11-13': np.float64(3.245833333333333),\n",
      "                                        '716_2024-03-18': np.float64(3.0616666666666665),\n",
      "                                        '716_2024-08-29': np.float64(2.4158333333333335),\n",
      "                                        '717_2022-04-06': np.float64(3.6133333333333333),\n",
      "                                        '717_2022-12-12': np.float64(3.4141666666666666),\n",
      "                                        '717_2023-04-06': np.float64(3.796666666666667),\n",
      "                                        '717_2023-08-15': np.float64(3.4691666666666667),\n",
      "                                        '717_2023-11-17': np.float64(3.131666666666667),\n",
      "                                        '717_2024-03-18': np.float64(3.535),\n",
      "                                        '717_2024-08-27': np.float64(3.33),\n",
      "                                        '718_2021-11-12': np.float64(2.5391666666666666),\n",
      "                                        '718_2022-04-12': np.float64(2.620833333333333),\n",
      "                                        '718_2022-08-31': np.float64(2.9658333333333333),\n",
      "                                        '718_2023-04-26': np.float64(2.2291666666666665),\n",
      "                                        '718_2023-08-17': np.float64(3.3741666666666665),\n",
      "                                        '718_2024-01-03': np.float64(3.098333333333333),\n",
      "                                        '720_2021-09-29': np.float64(3.3808333333333334),\n",
      "                                        '720_2022-04-20': np.float64(1.8775),\n",
      "                                        '720_2022-08-19': np.float64(2.1508333333333334),\n",
      "                                        '720_2023-04-19': np.float64(2.68),\n",
      "                                        '720_2023-08-29': np.float64(3.3958333333333335),\n",
      "                                        '720_2024-03-27': np.float64(2.078333333333333),\n",
      "                                        '721_2021-10-06': np.float64(2.7066666666666666),\n",
      "                                        '721_2022-04-19': np.float64(2.4033333333333333),\n",
      "                                        '721_2022-08-10': np.float64(2.4516666666666667),\n",
      "                                        '721_2023-04-27': np.float64(3.1175),\n",
      "                                        '723_2021-12-14': np.float64(2.88),\n",
      "                                        '723_2022-04-21': np.float64(1.4475),\n",
      "                                        '723_2022-08-30': np.float64(1.4991666666666668),\n",
      "                                        '728_2021-11-05': np.float64(2.53),\n",
      "                                        '728_2022-04-12': np.float64(2.3466666666666667),\n",
      "                                        '728_2022-07-26': np.float64(2.154166666666667),\n",
      "                                        '728_2022-11-02': np.float64(1.9116666666666666),\n",
      "                                        '728_2023-04-20': np.float64(2.3333333333333335),\n",
      "                                        '728_2023-05-18': np.float64(2.79),\n",
      "                                        '728_2023-09-14': np.float64(2.716666666666667),\n",
      "                                        '728_2024-01-19': np.float64(3.006666666666667),\n",
      "                                        '728_2024-07-29': np.float64(2.3341666666666665),\n",
      "                                        '729_2021-12-30': np.float64(2.4),\n",
      "                                        '729_2022-04-13': np.float64(3.1366666666666667),\n",
      "                                        '729_2022-07-11': np.float64(2.7391666666666667),\n",
      "                                        '729_2022-12-01': np.float64(2.5241666666666664),\n",
      "                                        '729_2023-02-06': np.float64(2.138333333333333),\n",
      "                                        '729_2023-05-08': np.float64(2.385),\n",
      "                                        '729_2023-11-08': np.float64(2.4766666666666666),\n",
      "                                        '729_2024-02-01': np.float64(1.6958333333333333),\n",
      "                                        '729_2024-07-08': np.float64(1.8608333333333333),\n",
      "                                        '729_2024-09-26': np.float64(2.901666666666667),\n",
      "                                        '72_2021-11-23': np.float64(3.0391666666666666),\n",
      "                                        '72_2022-03-16': np.float64(3.0441666666666665),\n",
      "                                        '732_2022-03-16': np.float64(3.4),\n",
      "                                        '732_2022-08-03': np.float64(2.1325),\n",
      "                                        '732_2022-12-14': np.float64(2.7258333333333336),\n",
      "                                        '732_2023-03-31': np.float64(1.7758333333333334),\n",
      "                                        '732_2023-08-11': np.float64(2.5341666666666667),\n",
      "                                        '732_2024-03-21': np.float64(2.4983333333333335),\n",
      "                                        '732_2024-08-05': np.float64(2.0575),\n",
      "                                        '733_2022-08-22': np.float64(2.8325),\n",
      "                                        '733_2023-04-27': np.float64(2.466666666666667),\n",
      "                                        '733_2023-09-06': np.float64(3.135),\n",
      "                                        '733_2024-04-01': np.float64(2.685),\n",
      "                                        '734_2022-07-19': np.float64(2.77),\n",
      "                                        '734_2023-03-09': np.float64(3.004166666666667),\n",
      "                                        '734_2023-12-08': np.float64(3.0933333333333333),\n",
      "                                        '734_2024-03-28': np.float64(3.2325),\n",
      "                                        '735_2022-02-10': np.float64(1.9033333333333333),\n",
      "                                        '735_2022-07-25': np.float64(2.1666666666666665),\n",
      "                                        '735_2022-11-22': np.float64(2.140833333333333),\n",
      "                                        '735_2023-02-20': np.float64(2.0366666666666666),\n",
      "                                        '735_2023-05-23': np.float64(2.3641666666666667),\n",
      "                                        '735_2024-01-23': np.float64(2.8666666666666667),\n",
      "                                        '736_2022-06-03': np.float64(2.828333333333333),\n",
      "                                        '737_2022-08-23': np.float64(2.9091666666666667),\n",
      "                                        '737_2023-06-12': np.float64(3.283333333333333),\n",
      "                                        '738_2022-01-27': np.float64(1.7675),\n",
      "                                        '738_2022-08-09': np.float64(2.3241666666666667),\n",
      "                                        '73_2021-04-29': np.float64(3.6641666666666666),\n",
      "                                        '73_2022-03-30': np.float64(3.285833333333333),\n",
      "                                        '73_2022-08-08': np.float64(3.215),\n",
      "                                        '73_2022-11-09': np.float64(2.5258333333333334),\n",
      "                                        '73_2023-03-03': np.float64(2.7441666666666666),\n",
      "                                        '73_2023-07-27': np.float64(2.941666666666667),\n",
      "                                        '73_2023-10-23': np.float64(2.1308333333333334),\n",
      "                                        '73_2024-01-19': np.float64(2.671666666666667),\n",
      "                                        '73_2024-09-30': np.float64(2.154166666666667),\n",
      "                                        '740_2022-03-29': np.float64(2.734166666666667),\n",
      "                                        '740_2022-06-10': np.float64(2.6866666666666665),\n",
      "                                        '740_2022-11-10': np.float64(1.7891666666666666),\n",
      "                                        '741_2022-03-23': np.float64(2.7191666666666667),\n",
      "                                        '741_2022-08-11': np.float64(2.9758333333333336),\n",
      "                                        '741_2022-12-15': np.float64(3.4858333333333333),\n",
      "                                        '741_2023-12-22': np.float64(2.674166666666667),\n",
      "                                        '741_2024-03-29': np.float64(2.9383333333333335),\n",
      "                                        '742_2022-03-24': np.float64(2.355),\n",
      "                                        '742_2022-08-30': np.float64(2.7891666666666666),\n",
      "                                        '742_2023-05-03': np.float64(3.453333333333333),\n",
      "                                        '742_2023-10-12': np.float64(2.7616666666666667),\n",
      "                                        '742_2024-02-28': np.float64(3.4575),\n",
      "                                        '742_2024-08-05': np.float64(4.193333333333333),\n",
      "                                        '744_2022-04-28': np.float64(1.9516666666666667),\n",
      "                                        '744_2022-08-22': np.float64(2.8366666666666664),\n",
      "                                        '744_2023-04-13': np.float64(2.4525),\n",
      "                                        '744_2023-06-12': np.float64(2.3491666666666666),\n",
      "                                        '744_2023-12-19': np.float64(2.6466666666666665),\n",
      "                                        '744_2024-03-28': np.float64(2.526666666666667),\n",
      "                                        '744_2024-08-29': np.float64(1.8383333333333334),\n",
      "                                        '745_2022-07-07': np.float64(1.9608333333333334),\n",
      "                                        '745_2023-01-30': np.float64(2.3825),\n",
      "                                        '745_2023-06-09': np.float64(2.2291666666666665),\n",
      "                                        '745_2023-12-27': np.float64(3.1883333333333335),\n",
      "                                        '745_2024-03-19': np.float64(3.5625),\n",
      "                                        '746_2022-08-31': np.float64(2.4775),\n",
      "                                        '746_2023-04-21': np.float64(1.8658333333333332),\n",
      "                                        '746_2023-08-14': np.float64(3.433333333333333),\n",
      "                                        '746_2023-09-18': np.float64(3.0966666666666667),\n",
      "                                        '746_2024-01-26': np.float64(2.835),\n",
      "                                        '746_2024-07-22': np.float64(3.5241666666666664),\n",
      "                                        '747_2022-08-01': np.float64(3.2741666666666664),\n",
      "                                        '747_2023-07-27': np.float64(2.7733333333333334),\n",
      "                                        '747_2023-12-05': np.float64(2.868333333333333),\n",
      "                                        '747_2024-03-12': np.float64(2.745833333333333),\n",
      "                                        '748_2023-04-11': np.float64(3.535),\n",
      "                                        '748_2023-08-29': np.float64(4.331666666666667),\n",
      "                                        '748_2023-12-19': np.float64(2.5083333333333333),\n",
      "                                        '748_2024-03-28': np.float64(3.4383333333333335),\n",
      "                                        '748_2024-08-12': np.float64(2.0166666666666666),\n",
      "                                        '749_2022-08-24': np.float64(3.6416666666666666),\n",
      "                                        '749_2022-12-20': np.float64(3.285833333333333),\n",
      "                                        '749_2023-07-17': np.float64(3.0233333333333334),\n",
      "                                        '749_2023-12-12': np.float64(2.265),\n",
      "                                        '749_2024-03-05': np.float64(2.615),\n",
      "                                        '749_2024-06-04': np.float64(2.1616666666666666),\n",
      "                                        '750_2022-07-15': np.float64(3.4075),\n",
      "                                        '750_2022-11-15': np.float64(3.0366666666666666),\n",
      "                                        '751_2022-07-25': np.float64(2.7483333333333335),\n",
      "                                        '751_2023-04-24': np.float64(2.1883333333333335),\n",
      "                                        '751_2023-08-11': np.float64(3.1066666666666665),\n",
      "                                        '751_2023-11-30': np.float64(3.4525),\n",
      "                                        '751_2024-03-20': np.float64(2.85),\n",
      "                                        '751_2024-07-23': np.float64(3.220833333333333),\n",
      "                                        '752_2022-07-19': np.float64(2.235),\n",
      "                                        '753_2022-08-18': np.float64(2.7758333333333334),\n",
      "                                        '753_2023-04-20': np.float64(2.484166666666667),\n",
      "                                        '754_2022-08-23': np.float64(2.0308333333333333),\n",
      "                                        '754_2022-12-20': np.float64(2.1958333333333333),\n",
      "                                        '754_2023-08-04': np.float64(3.1791666666666667),\n",
      "                                        '754_2023-12-19': np.float64(2.743333333333333),\n",
      "                                        '754_2024-03-18': np.float64(2.7308333333333334),\n",
      "                                        '754_2024-08-07': np.float64(3.160833333333333),\n",
      "                                        '755_2022-07-26': np.float64(2.8158333333333334),\n",
      "                                        '759_2023-01-18': np.float64(2.8508333333333336),\n",
      "                                        '759_2024-04-18': np.float64(3.0441666666666665),\n",
      "                                        '759_2024-07-08': np.float64(3.8583333333333334),\n",
      "                                        '760_2022-12-13': np.float64(3.3466666666666667),\n",
      "                                        '760_2023-04-20': np.float64(3.5433333333333334),\n",
      "                                        '760_2023-07-03': np.float64(3.506666666666667),\n",
      "                                        '763_2022-08-29': np.float64(2.3133333333333335),\n",
      "                                        '763_2022-12-08': np.float64(2.9466666666666668),\n",
      "                                        '763_2023-04-19': np.float64(2.2416666666666667),\n",
      "                                        '763_2023-07-31': np.float64(2.7325),\n",
      "                                        '763_2024-03-12': np.float64(2.6358333333333333),\n",
      "                                        '763_2024-07-11': np.float64(2.6683333333333334),\n",
      "                                        '764_2022-08-24': np.float64(3.0925),\n",
      "                                        '764_2022-12-14': np.float64(2.3666666666666667),\n",
      "                                        '764_2023-02-27': np.float64(2.9191666666666665),\n",
      "                                        '764_2023-07-18': np.float64(3.7483333333333335),\n",
      "                                        '764_2023-10-23': np.float64(3.1008333333333336),\n",
      "                                        '764_2024-03-20': np.float64(3.450833333333333),\n",
      "                                        '765_2022-08-31': np.float64(2.8975),\n",
      "                                        '765_2022-12-07': np.float64(1.6708333333333334),\n",
      "                                        '765_2023-08-02': np.float64(2.1283333333333334),\n",
      "                                        '765_2023-11-08': np.float64(3.1908333333333334),\n",
      "                                        '765_2024-02-08': np.float64(1.7266666666666666),\n",
      "                                        '766_2022-09-28': np.float64(3.2641666666666667),\n",
      "                                        '766_2023-04-24': np.float64(2.2908333333333335),\n",
      "                                        '766_2023-07-19': np.float64(3.005),\n",
      "                                        '766_2023-10-06': np.float64(4.1275),\n",
      "                                        '766_2024-06-06': np.float64(4.421666666666667),\n",
      "                                        '766_2024-09-27': np.float64(3.2325),\n",
      "                                        '767_2022-12-16': np.float64(1.4516666666666667),\n",
      "                                        '767_2023-06-15': np.float64(2.0975),\n",
      "                                        '767_2024-03-19': np.float64(2.71),\n",
      "                                        '768_2022-11-02': np.float64(2.2275),\n",
      "                                        '768_2023-04-13': np.float64(2.185),\n",
      "                                        '768_2023-07-19': np.float64(2.0441666666666665),\n",
      "                                        '768_2024-04-10': np.float64(2.6625),\n",
      "                                        '768_2024-07-29': np.float64(2.4091666666666667),\n",
      "                                        '769_2023-04-25': np.float64(4.320833333333334),\n",
      "                                        '769_2023-08-07': np.float64(3.6141666666666667),\n",
      "                                        '769_2023-11-13': np.float64(3.6341666666666668),\n",
      "                                        '769_2024-02-06': np.float64(3.6858333333333335),\n",
      "                                        '769_2024-06-06': np.float64(3.7608333333333333),\n",
      "                                        '771_2022-12-12': np.float64(3.125),\n",
      "                                        '771_2023-04-28': np.float64(3.5216666666666665),\n",
      "                                        '771_2024-01-10': np.float64(3.2075),\n",
      "                                        '771_2024-07-17': np.float64(3.950833333333333),\n",
      "                                        '774_2022-12-08': np.float64(2.470833333333333),\n",
      "                                        '774_2023-03-09': np.float64(2.45),\n",
      "                                        '774_2023-07-25': np.float64(2.5966666666666667),\n",
      "                                        '774_2023-11-28': np.float64(2.87),\n",
      "                                        '774_2024-03-22': np.float64(2.5008333333333335),\n",
      "                                        '775_2023-04-19': np.float64(3.5316666666666667),\n",
      "                                        '775_2023-12-22': np.float64(3.755),\n",
      "                                        '776_2023-02-03': np.float64(0.9808333333333333),\n",
      "                                        '776_2023-08-17': np.float64(2.855),\n",
      "                                        '776_2023-12-08': np.float64(2.4208333333333334),\n",
      "                                        '777_2022-12-09': np.float64(2.9883333333333333),\n",
      "                                        '777_2023-04-12': np.float64(3.1133333333333333),\n",
      "                                        '777_2023-07-31': np.float64(2.6691666666666665),\n",
      "                                        '777_2023-11-13': np.float64(2.8325),\n",
      "                                        '777_2024-03-13': np.float64(2.885),\n",
      "                                        '777_2024-07-24': np.float64(3.2016666666666667),\n",
      "                                        '778_2023-02-10': np.float64(2.0741666666666667),\n",
      "                                        '778_2024-03-13': np.float64(2.5533333333333332),\n",
      "                                        '778_2024-08-01': np.float64(3.0008333333333335),\n",
      "                                        '779_2023-04-25': np.float64(2.495),\n",
      "                                        '781_2023-12-18': np.float64(3.1125),\n",
      "                                        '781_2024-04-01': np.float64(3.1233333333333335),\n",
      "                                        '783_2023-02-16': np.float64(2.8291666666666666),\n",
      "                                        '783_2023-08-02': np.float64(3.4883333333333333),\n",
      "                                        '783_2024-08-26': np.float64(4.309166666666667),\n",
      "                                        '784_2023-02-24': np.float64(2.5325),\n",
      "                                        '784_2023-07-19': np.float64(2.665),\n",
      "                                        '784_2024-03-12': np.float64(3.185),\n",
      "                                        '786_2023-04-26': np.float64(2.0825),\n",
      "                                        '786_2023-10-20': np.float64(2.9808333333333334),\n",
      "                                        '787_2023-03-13': np.float64(1.8316666666666668),\n",
      "                                        '787_2023-09-14': np.float64(2.2133333333333334),\n",
      "                                        '788_2023-04-21': np.float64(2.36),\n",
      "                                        '788_2023-11-20': np.float64(2.296666666666667),\n",
      "                                        '788_2024-02-12': np.float64(3.299166666666667),\n",
      "                                        '788_2024-08-01': np.float64(1.7908333333333333),\n",
      "                                        '789_2023-04-19': np.float64(2.3266666666666667),\n",
      "                                        '789_2024-03-27': np.float64(3.029166666666667),\n",
      "                                        '790_2023-06-07': np.float64(3.8308333333333335),\n",
      "                                        '790_2024-01-31': np.float64(2.555),\n",
      "                                        '793_2023-07-17': np.float64(2.1866666666666665),\n",
      "                                        '795_2023-04-19': np.float64(2.7675),\n",
      "                                        '795_2023-09-11': np.float64(3.8383333333333334),\n",
      "                                        '795_2024-03-06': np.float64(2.7175),\n",
      "                                        '795_2024-08-20': np.float64(2.8491666666666666),\n",
      "                                        '797_2023-12-08': np.float64(3.155),\n",
      "                                        '799_2024-03-15': np.float64(2.799166666666667),\n",
      "                                        '79_2021-04-12': np.float64(3.0316666666666667),\n",
      "                                        '79_2021-11-02': np.float64(3.578333333333333),\n",
      "                                        '79_2022-02-01': np.float64(2.7425),\n",
      "                                        '79_2022-05-11': np.float64(2.1875),\n",
      "                                        '79_2022-09-26': np.float64(3.3141666666666665),\n",
      "                                        '79_2023-02-17': np.float64(3.1025),\n",
      "                                        '79_2023-08-02': np.float64(3.0483333333333333),\n",
      "                                        '79_2023-11-16': np.float64(3.1925),\n",
      "                                        '79_2024-02-14': np.float64(2.4966666666666666),\n",
      "                                        '800_2023-04-19': np.float64(2.5733333333333333),\n",
      "                                        '800_2023-12-15': np.float64(2.7725),\n",
      "                                        '800_2024-03-29': np.float64(1.8591666666666666),\n",
      "                                        '804_2023-11-10': np.float64(2.7666666666666666),\n",
      "                                        '804_2024-04-01': np.float64(2.3508333333333336),\n",
      "                                        '805_2023-05-22': np.float64(2.7408333333333332),\n",
      "                                        '805_2023-09-11': np.float64(2.629166666666667),\n",
      "                                        '805_2024-02-08': np.float64(3.2241666666666666),\n",
      "                                        '806_2023-06-27': np.float64(2.8333333333333335),\n",
      "                                        '806_2023-12-27': np.float64(3.225),\n",
      "                                        '808_2023-09-12': np.float64(2.2475),\n",
      "                                        '809_2023-07-11': np.float64(2.905),\n",
      "                                        '810_2023-07-31': np.float64(2.61),\n",
      "                                        '810_2023-12-27': np.float64(2.94),\n",
      "                                        '810_2024-03-19': np.float64(2.4208333333333334),\n",
      "                                        '813_2024-03-15': np.float64(3.4791666666666665),\n",
      "                                        '814_2023-09-19': np.float64(3.2591666666666668),\n",
      "                                        '815_2023-07-17': np.float64(2.8741666666666665),\n",
      "                                        '816_2023-08-30': np.float64(2.4783333333333335),\n",
      "                                        '816_2023-12-19': np.float64(1.7258333333333333),\n",
      "                                        '816_2024-04-02': np.float64(2.5183333333333335),\n",
      "                                        '816_2024-08-08': np.float64(2.1841666666666666),\n",
      "                                        '818_2023-08-29': np.float64(2.5058333333333334),\n",
      "                                        '818_2023-12-12': np.float64(1.6741666666666666),\n",
      "                                        '818_2024-03-27': np.float64(2.0258333333333334),\n",
      "                                        '818_2024-07-26': np.float64(1.99),\n",
      "                                        '819_2023-07-17': np.float64(2.973333333333333),\n",
      "                                        '819_2024-04-09': np.float64(3.4033333333333333),\n",
      "                                        '820_2024-03-29': np.float64(2.66),\n",
      "                                        '822_2024-04-01': np.float64(3.4766666666666666),\n",
      "                                        '823_2023-10-20': np.float64(3.495),\n",
      "                                        '823_2024-03-21': np.float64(1.9241666666666666),\n",
      "                                        '824_2024-04-02': np.float64(3.0941666666666667),\n",
      "                                        '825_2024-03-28': np.float64(3.2291666666666665),\n",
      "                                        '828_2023-09-18': np.float64(3.265),\n",
      "                                        '828_2024-04-09': np.float64(2.904166666666667),\n",
      "                                        '829_2023-11-17': np.float64(2.4583333333333335),\n",
      "                                        '835_2023-11-17': np.float64(4.348333333333334),\n",
      "                                        '835_2024-02-16': np.float64(3.5775),\n",
      "                                        '836_2023-10-20': np.float64(2.9725),\n",
      "                                        '836_2024-03-29': np.float64(3.7741666666666664),\n",
      "                                        '837_2024-03-15': np.float64(2.52),\n",
      "                                        '839_2023-12-20': np.float64(1.5091666666666668),\n",
      "                                        '839_2024-03-29': np.float64(1.6941666666666666),\n",
      "                                        '83_2021-05-24': np.float64(2.700833333333333),\n",
      "                                        '83_2021-12-15': np.float64(2.6283333333333334),\n",
      "                                        '83_2022-04-04': np.float64(2.44),\n",
      "                                        '83_2022-05-23': np.float64(2.683333333333333),\n",
      "                                        '83_2022-09-19': np.float64(3.4208333333333334),\n",
      "                                        '83_2023-01-17': np.float64(3.214166666666667),\n",
      "                                        '83_2023-07-19': np.float64(3.915),\n",
      "                                        '840_2023-11-17': np.float64(2.7975),\n",
      "                                        '840_2024-03-27': np.float64(3.3608333333333333),\n",
      "                                        '842_2024-02-21': np.float64(4.1225),\n",
      "                                        '843_2023-12-18': np.float64(2.058333333333333),\n",
      "                                        '843_2024-04-10': np.float64(2.783333333333333),\n",
      "                                        '844_2024-03-21': np.float64(2.325833333333333),\n",
      "                                        '844_2024-08-30': np.float64(2.3516666666666666),\n",
      "                                        '845_2023-12-19': np.float64(2.1891666666666665),\n",
      "                                        '845_2024-03-15': np.float64(2.078333333333333),\n",
      "                                        '846_2024-03-13': np.float64(3.194166666666667),\n",
      "                                        '847_2024-07-26': np.float64(3.6641666666666666),\n",
      "                                        '848_2024-03-27': np.float64(2.8783333333333334),\n",
      "                                        '849_2024-03-27': np.float64(2.975),\n",
      "                                        '851_2024-07-26': np.float64(2.755),\n",
      "                                        '852_2024-03-13': np.float64(2.796666666666667),\n",
      "                                        '854_2024-04-18': np.float64(2.0633333333333335),\n",
      "                                        '854_2024-08-06': np.float64(1.5866666666666667),\n",
      "                                        '858_2024-04-17': np.float64(2.545),\n",
      "                                        '858_2024-07-08': np.float64(2.775),\n",
      "                                        '861_2024-07-05': np.float64(3.0008333333333335),\n",
      "                                        '862_2024-04-05': np.float64(3.3425),\n",
      "                                        '863_2024-06-07': np.float64(2.953333333333333),\n",
      "                                        '865_2024-04-12': np.float64(2.8875),\n",
      "                                        '86_2021-05-24': np.float64(2.8991666666666664),\n",
      "                                        '86_2021-11-23': np.float64(2.3958333333333335),\n",
      "                                        '86_2022-02-10': np.float64(2.466666666666667),\n",
      "                                        '86_2022-05-25': np.float64(2.049166666666667),\n",
      "                                        '86_2022-09-20': np.float64(2.618333333333333),\n",
      "                                        '86_2023-01-12': np.float64(3.1158333333333332),\n",
      "                                        '86_2023-06-08': np.float64(2.2725),\n",
      "                                        '86_2023-11-13': np.float64(2.6675),\n",
      "                                        '86_2024-02-05': np.float64(2.2283333333333335),\n",
      "                                        '86_2024-08-12': np.float64(2.88),\n",
      "                                        '86_2024-09-18': np.float64(2.735),\n",
      "                                        '938652_2024-10-25': np.float64(1.6583333333333334),\n",
      "                                        '938667_2024-11-19': np.float64(1.7808333333333333),\n",
      "                                        '938672_2024-10-28': np.float64(3.205),\n",
      "                                        '938695_2024-10-28': np.float64(1.9183333333333332),\n",
      "                                        '938698_2024-10-30': np.float64(3.3025),\n",
      "                                        '938699_2024-10-28': np.float64(3.915),\n",
      "                                        '938700_2024-10-18': np.float64(2.5533333333333332),\n",
      "                                        '938702_2024-11-22': np.float64(2.2275),\n",
      "                                        '938703_2024-10-28': np.float64(1.6633333333333333),\n",
      "                                        '938710_2024-11-19': np.float64(3.1125),\n",
      "                                        '938743_2024-11-19': np.float64(4.070833333333334),\n",
      "                                        '938766_2024-10-25': np.float64(3.1225),\n",
      "                                        '938797_2024-11-19': np.float64(1.7666666666666666),\n",
      "                                        '938814_2024-11-19': np.float64(3.5441666666666665),\n",
      "                                        '938894_2024-11-01': np.float64(2.8325),\n",
      "                                        '938938_2024-11-20': np.float64(3.1841666666666666),\n",
      "                                        '939783_2024-11-19': np.float64(2.365),\n",
      "                                        '941934_2024-11-07': np.float64(3.6483333333333334),\n",
      "                                        '952421_2024-11-19': np.float64(1.8741666666666668),\n",
      "                                        '981476_2024-11-01': np.float64(2.816666666666667),\n",
      "                                        '983777_2024-11-22': np.float64(1.9025),\n",
      "                                        '997606_2024-10-25': np.float64(3.109166666666667)},\n",
      "                        'r': np.float64(0.1522980386280439),\n",
      "                        'r_folds': np.float64(0.1595273865276051),\n",
      "                        'r_p': np.float64(4.50509985439501e-09),\n",
      "                        'r_p_folds': np.float64(0.015924799505594344),\n",
      "                        'rho': np.float64(0.17064190807461596),\n",
      "                        'rho_folds': np.float64(0.17607644739206685),\n",
      "                        'rho_p': np.float64(4.6789154573228006e-11),\n",
      "                        'rho_p_folds': np.float64(0.009516120826243143),\n",
      "                        'se_R2_folds': np.float64(0.01724336462041402),\n",
      "                        'se_mae_folds': np.float64(0.06226245818565367),\n",
      "                        'se_mse_folds': np.float64(0.3225430389003626),\n",
      "                        'se_r_folds': np.float64(0.017205105571369086),\n",
      "                        'se_r_p_folds': np.float64(0.0071048636330497406),\n",
      "                        'se_rho_folds': np.float64(0.02137665932395974),\n",
      "                        'se_rho_p_folds': np.float64(0.004573644875801701),\n",
      "                        'se_train_mean_mae_folds': np.float64(0.06881004248493683),\n",
      "                        'test_size': 294,\n",
      "                        'train_mean_mae': 0.5004312697522936,\n",
      "                        'train_mean_mae_folds': np.float64(1.5141649201924878),\n",
      "                        'train_size': 1174,\n",
      "                        'trues': {'103_2021-04-21': 1,\n",
      "                                  '105_2021-04-29': 3,\n",
      "                                  '106_2021-04-28': 8,\n",
      "                                  '107_2021-04-12': 6,\n",
      "                                  '107_2021-04-20': 2,\n",
      "                                  '107_2021-06-01': 3,\n",
      "                                  '108_2021-04-30': 1,\n",
      "                                  '109_2021-02-23': 8,\n",
      "                                  '109_2021-04-19': 2,\n",
      "                                  '111_2021-02-03': 2,\n",
      "                                  '111_2021-11-10': 1,\n",
      "                                  '111_2022-02-11': 1,\n",
      "                                  '111_2022-06-08': 2,\n",
      "                                  '111_2022-09-20': 0,\n",
      "                                  '111_2023-01-17': 1,\n",
      "                                  '111_2023-05-03': 0,\n",
      "                                  '111_2023-09-21': 1,\n",
      "                                  '111_2024-01-11': 2,\n",
      "                                  '111_2024-06-27': 1,\n",
      "                                  '113_2021-04-19': 8,\n",
      "                                  '117_2021-02-08': 0,\n",
      "                                  '117_2021-05-11': 6,\n",
      "                                  '117_2021-06-01': 5,\n",
      "                                  '117_2021-12-13': 1,\n",
      "                                  '117_2022-03-24': 0,\n",
      "                                  '117_2022-06-28': 2,\n",
      "                                  '117_2022-12-07': 1,\n",
      "                                  '117_2023-03-13': 1,\n",
      "                                  '117_2023-05-11': 0,\n",
      "                                  '117_2023-10-11': 0,\n",
      "                                  '117_2024-03-27': 2,\n",
      "                                  '121_2021-04-27': 5,\n",
      "                                  '121_2021-06-09': 5,\n",
      "                                  '124_2021-04-27': 6,\n",
      "                                  '128_2021-04-28': 1,\n",
      "                                  '128_2021-06-09': 6,\n",
      "                                  '138_2021-04-21': 8,\n",
      "                                  '143_2021-04-19': 4,\n",
      "                                  '144_2021-02-10': 2,\n",
      "                                  '144_2021-04-19': 8,\n",
      "                                  '144_2021-11-01': 3,\n",
      "                                  '144_2022-01-17': 3,\n",
      "                                  '144_2022-05-09': 3,\n",
      "                                  '144_2022-09-05': 3,\n",
      "                                  '144_2023-01-10': 3,\n",
      "                                  '144_2023-05-02': 3,\n",
      "                                  '144_2023-10-06': 3,\n",
      "                                  '144_2024-02-08': 3,\n",
      "                                  '144_2024-07-17': 3,\n",
      "                                  '144_2024-10-07': 3,\n",
      "                                  '146_2021-04-23': 8,\n",
      "                                  '146_2021-06-04': 8,\n",
      "                                  '148_2021-04-20': 8,\n",
      "                                  '149_2021-05-07': 2,\n",
      "                                  '154_2021-04-27': 0,\n",
      "                                  '155_2021-04-20': 2,\n",
      "                                  '155_2021-06-02': 4,\n",
      "                                  '156_2021-05-05': 12,\n",
      "                                  '156_2021-06-03': 6,\n",
      "                                  '158_2021-04-26': 2,\n",
      "                                  '158_2021-11-08': 3,\n",
      "                                  '158_2022-02-03': 1,\n",
      "                                  '158_2022-06-13': 1,\n",
      "                                  '158_2022-12-02': 1,\n",
      "                                  '158_2023-03-09': 2,\n",
      "                                  '158_2023-05-08': 0,\n",
      "                                  '158_2023-09-21': 0,\n",
      "                                  '158_2024-01-11': 0,\n",
      "                                  '158_2024-07-17': 0,\n",
      "                                  '162_2021-04-26': 0,\n",
      "                                  '162_2021-12-21': 0,\n",
      "                                  '162_2022-03-28': 3,\n",
      "                                  '162_2022-07-19': 0,\n",
      "                                  '162_2022-12-01': 1,\n",
      "                                  '162_2023-02-28': 1,\n",
      "                                  '162_2023-05-08': 0,\n",
      "                                  '162_2024-02-01': 0,\n",
      "                                  '162_2024-06-24': 0,\n",
      "                                  '168_2021-02-22': 3,\n",
      "                                  '168_2021-12-27': 0,\n",
      "                                  '168_2022-01-31': 1,\n",
      "                                  '168_2022-08-03': 3,\n",
      "                                  '168_2022-12-02': 1,\n",
      "                                  '168_2023-03-10': 1,\n",
      "                                  '168_2023-06-21': 3,\n",
      "                                  '168_2024-02-05': 2,\n",
      "                                  '168_2024-08-01': 2,\n",
      "                                  '170_2021-03-08': 1,\n",
      "                                  '170_2022-01-20': 3,\n",
      "                                  '170_2022-05-23': 3,\n",
      "                                  '170_2022-12-08': 5,\n",
      "                                  '170_2023-03-30': 4,\n",
      "                                  '170_2023-07-31': 4,\n",
      "                                  '170_2024-01-23': 1,\n",
      "                                  '170_2024-08-14': 1,\n",
      "                                  '173_2021-09-21': 1,\n",
      "                                  '173_2022-03-07': 0,\n",
      "                                  '173_2022-05-25': 0,\n",
      "                                  '173_2022-11-10': 0,\n",
      "                                  '173_2023-04-11': 1,\n",
      "                                  '173_2023-06-12': 3,\n",
      "                                  '173_2023-11-13': 3,\n",
      "                                  '173_2024-02-20': 3,\n",
      "                                  '173_2024-08-01': 3,\n",
      "                                  '180_2021-04-28': 1,\n",
      "                                  '180_2021-12-02': 3,\n",
      "                                  '180_2022-02-16': 3,\n",
      "                                  '190_2021-06-28': 3,\n",
      "                                  '190_2021-12-17': 2,\n",
      "                                  '190_2022-03-28': 3,\n",
      "                                  '190_2022-07-18': 3,\n",
      "                                  '190_2022-12-02': 1,\n",
      "                                  '208_2021-06-03': 0,\n",
      "                                  '208_2021-12-09': 0,\n",
      "                                  '208_2022-03-18': 1,\n",
      "                                  '208_2022-09-27': 0,\n",
      "                                  '208_2023-02-08': 0,\n",
      "                                  '208_2023-07-19': 0,\n",
      "                                  '208_2023-12-19': 0,\n",
      "                                  '208_2024-03-22': 0,\n",
      "                                  '208_2024-07-08': 3,\n",
      "                                  '217_2021-05-24': 1,\n",
      "                                  '217_2021-12-01': 3,\n",
      "                                  '217_2022-02-15': 3,\n",
      "                                  '220_2021-02-11': 1,\n",
      "                                  '223_2021-01-29': 2,\n",
      "                                  '223_2022-03-28': 9,\n",
      "                                  '223_2022-07-29': 0,\n",
      "                                  '223_2022-12-02': 3,\n",
      "                                  '223_2023-03-10': 0,\n",
      "                                  '237_2021-02-26': 5,\n",
      "                                  '237_2021-11-30': 4,\n",
      "                                  '237_2022-03-15': 4,\n",
      "                                  '237_2022-06-15': 2,\n",
      "                                  '237_2022-11-09': 3,\n",
      "                                  '237_2023-02-01': 1,\n",
      "                                  '237_2023-05-12': 1,\n",
      "                                  '237_2023-10-13': 3,\n",
      "                                  '237_2024-01-10': 0,\n",
      "                                  '237_2024-05-22': 3,\n",
      "                                  '241_2021-02-08': 3,\n",
      "                                  '241_2021-11-01': 3,\n",
      "                                  '241_2022-01-31': 3,\n",
      "                                  '241_2022-05-09': 3,\n",
      "                                  '241_2022-10-04': 3,\n",
      "                                  '241_2023-02-21': 4,\n",
      "                                  '241_2023-06-12': 3,\n",
      "                                  '24_2021-02-09': 5,\n",
      "                                  '24_2022-04-06': 7,\n",
      "                                  '24_2022-08-16': 9,\n",
      "                                  '24_2023-01-27': 4,\n",
      "                                  '24_2023-07-19': 8,\n",
      "                                  '24_2024-03-13': 6,\n",
      "                                  '24_2024-08-29': 5,\n",
      "                                  '250_2021-02-01': 5,\n",
      "                                  '250_2022-03-25': 6,\n",
      "                                  '250_2022-08-10': 4,\n",
      "                                  '250_2022-12-02': 4,\n",
      "                                  '250_2023-04-20': 4,\n",
      "                                  '255_2021-02-24': 2,\n",
      "                                  '255_2021-12-29': 4,\n",
      "                                  '25_2021-02-05': 0,\n",
      "                                  '25_2021-07-01': 0,\n",
      "                                  '25_2021-12-28': 2,\n",
      "                                  '25_2023-04-04': 1,\n",
      "                                  '25_2023-05-02': 0,\n",
      "                                  '25_2023-09-18': 3,\n",
      "                                  '25_2023-10-30': 3,\n",
      "                                  '25_2024-01-12': 3,\n",
      "                                  '25_2024-06-28': 3,\n",
      "                                  '264_2021-06-10': 4,\n",
      "                                  '264_2022-04-06': 3,\n",
      "                                  '265_2021-04-27': 5,\n",
      "                                  '265_2021-11-15': 0,\n",
      "                                  '265_2022-02-07': 1,\n",
      "                                  '265_2022-05-09': 0,\n",
      "                                  '265_2022-09-05': 2,\n",
      "                                  '265_2023-01-09': 2,\n",
      "                                  '265_2023-05-02': 2,\n",
      "                                  '265_2023-10-05': 1,\n",
      "                                  '265_2024-01-30': 0,\n",
      "                                  '265_2024-06-24': 0,\n",
      "                                  '265_2024-09-26': 3,\n",
      "                                  '266_2021-04-26': 2,\n",
      "                                  '266_2021-11-08': 7,\n",
      "                                  '266_2022-05-16': 4,\n",
      "                                  '266_2022-09-08': 3,\n",
      "                                  '267_2021-06-21': 5,\n",
      "                                  '267_2021-11-22': 1,\n",
      "                                  '267_2022-02-14': 4,\n",
      "                                  '267_2022-05-25': 1,\n",
      "                                  '267_2022-09-13': 1,\n",
      "                                  '267_2023-01-13': 1,\n",
      "                                  '268_2021-02-09': 3,\n",
      "                                  '270_2021-05-04': 3,\n",
      "                                  '270_2021-12-01': 3,\n",
      "                                  '271_2021-03-24': 2,\n",
      "                                  '279_2021-02-09': 2,\n",
      "                                  '279_2021-12-09': 2,\n",
      "                                  '279_2022-03-09': 6,\n",
      "                                  '279_2022-06-09': 3,\n",
      "                                  '279_2022-10-04': 3,\n",
      "                                  '279_2023-01-19': 3,\n",
      "                                  '279_2023-06-26': 5,\n",
      "                                  '279_2023-11-09': 7,\n",
      "                                  '279_2024-02-27': 4,\n",
      "                                  '289_2021-05-18': 3,\n",
      "                                  '289_2021-12-01': 3,\n",
      "                                  '289_2022-03-22': 3,\n",
      "                                  '289_2022-06-24': 2,\n",
      "                                  '289_2022-11-21': 3,\n",
      "                                  '289_2023-03-03': 3,\n",
      "                                  '289_2023-06-23': 3,\n",
      "                                  '289_2023-11-16': 3,\n",
      "                                  '289_2024-02-08': 3,\n",
      "                                  '289_2024-07-08': 3,\n",
      "                                  '30_2021-05-07': 9,\n",
      "                                  '30_2021-12-02': 3,\n",
      "                                  '30_2022-03-14': 8,\n",
      "                                  '30_2022-06-08': 4,\n",
      "                                  '30_2022-10-10': 5,\n",
      "                                  '30_2023-10-09': 3,\n",
      "                                  '319_2021-02-10': 1,\n",
      "                                  '319_2021-11-02': 0,\n",
      "                                  '319_2022-05-25': 3,\n",
      "                                  '319_2022-11-10': 1,\n",
      "                                  '319_2023-01-27': 0,\n",
      "                                  '319_2023-12-19': 2,\n",
      "                                  '32_2021-05-12': 5,\n",
      "                                  '32_2021-11-15': 5,\n",
      "                                  '32_2022-02-10': 5,\n",
      "                                  '32_2022-05-16': 3,\n",
      "                                  '32_2022-09-13': 5,\n",
      "                                  '32_2023-01-13': 5,\n",
      "                                  '32_2023-05-03': 2,\n",
      "                                  '32_2023-09-20': 5,\n",
      "                                  '32_2024-01-08': 2,\n",
      "                                  '32_2024-06-07': 3,\n",
      "                                  '32_2024-09-20': 5,\n",
      "                                  '332_2021-02-09': 5,\n",
      "                                  '332_2021-11-19': 3,\n",
      "                                  '332_2022-02-10': 3,\n",
      "                                  '340_2021-01-26': 2,\n",
      "                                  '340_2022-06-06': 2,\n",
      "                                  '340_2023-01-13': 1,\n",
      "                                  '340_2023-11-09': 3,\n",
      "                                  '340_2024-03-18': 6,\n",
      "                                  '343_2021-01-26': 1,\n",
      "                                  '343_2021-11-08': 2,\n",
      "                                  '343_2022-04-08': 1,\n",
      "                                  '343_2022-08-01': 2,\n",
      "                                  '345_2021-04-26': 3,\n",
      "                                  '345_2021-11-09': 2,\n",
      "                                  '345_2022-02-07': 1,\n",
      "                                  '345_2022-05-09': 3,\n",
      "                                  '345_2022-09-06': 1,\n",
      "                                  '345_2023-01-17': 2,\n",
      "                                  '345_2023-05-08': 2,\n",
      "                                  '345_2023-09-27': 0,\n",
      "                                  '345_2024-03-28': 0,\n",
      "                                  '345_2024-08-01': 3,\n",
      "                                  '360_2021-06-21': 3,\n",
      "                                  '360_2021-12-13': 3,\n",
      "                                  '360_2022-02-18': 0,\n",
      "                                  '360_2022-06-06': 1,\n",
      "                                  '360_2022-09-30': 3,\n",
      "                                  '360_2023-02-21': 2,\n",
      "                                  '360_2023-06-07': 1,\n",
      "                                  '361_2021-02-08': 0,\n",
      "                                  '361_2021-11-02': 0,\n",
      "                                  '361_2022-02-10': 1,\n",
      "                                  '361_2022-05-16': 1,\n",
      "                                  '361_2022-09-06': 0,\n",
      "                                  '361_2023-01-09': 0,\n",
      "                                  '361_2023-05-12': 0,\n",
      "                                  '361_2023-09-13': 0,\n",
      "                                  '361_2024-01-08': 0,\n",
      "                                  '361_2024-06-11': 0,\n",
      "                                  '361_2024-09-23': 3,\n",
      "                                  '369_2021-02-08': 2,\n",
      "                                  '369_2021-12-07': 0,\n",
      "                                  '369_2022-01-25': 1,\n",
      "                                  '369_2022-06-14': 2,\n",
      "                                  '369_2022-10-10': 1,\n",
      "                                  '369_2023-01-23': 2,\n",
      "                                  '369_2023-05-16': 1,\n",
      "                                  '369_2023-10-13': 2,\n",
      "                                  '369_2024-02-06': 0,\n",
      "                                  '369_2024-07-11': 3,\n",
      "                                  '372_2021-03-02': 4,\n",
      "                                  '372_2021-12-02': 1,\n",
      "                                  '372_2022-03-09': 3,\n",
      "                                  '372_2022-06-15': 2,\n",
      "                                  '374_2021-07-01': 5,\n",
      "                                  '375_2021-05-10': 5,\n",
      "                                  '375_2022-02-16': 4,\n",
      "                                  '375_2022-06-07': 2,\n",
      "                                  '375_2023-04-20': 5,\n",
      "                                  '375_2023-05-08': 5,\n",
      "                                  '383_2021-01-27': 5,\n",
      "                                  '383_2022-05-23': 0,\n",
      "                                  '383_2022-11-09': 2,\n",
      "                                  '383_2023-01-24': 0,\n",
      "                                  '383_2023-12-13': 1,\n",
      "                                  '386_2021-04-09': 0,\n",
      "                                  '386_2021-11-02': 0,\n",
      "                                  '386_2022-02-03': 1,\n",
      "                                  '386_2022-05-25': 0,\n",
      "                                  '386_2022-09-14': 0,\n",
      "                                  '386_2023-01-27': 0,\n",
      "                                  '386_2023-06-07': 3,\n",
      "                                  '386_2023-12-06': 0,\n",
      "                                  '386_2024-03-19': 3,\n",
      "                                  '386_2024-08-07': 3,\n",
      "                                  '387_2021-05-11': 0,\n",
      "                                  '387_2021-11-15': 0,\n",
      "                                  '387_2022-02-10': 0,\n",
      "                                  '387_2022-06-13': 0,\n",
      "                                  '387_2022-12-02': 0,\n",
      "                                  '387_2023-03-20': 0,\n",
      "                                  '393_2021-04-28': 0,\n",
      "                                  '393_2021-12-20': 0,\n",
      "                                  '393_2022-03-21': 0,\n",
      "                                  '393_2022-07-18': 0,\n",
      "                                  '393_2024-08-12': 0,\n",
      "                                  '417_2021-06-03': 0,\n",
      "                                  '417_2021-12-08': 0,\n",
      "                                  '417_2022-02-18': 1,\n",
      "                                  '417_2022-06-21': 0,\n",
      "                                  '417_2022-11-18': 1,\n",
      "                                  '417_2023-02-06': 0,\n",
      "                                  '417_2023-07-19': 0,\n",
      "                                  '419_2021-05-17': 1,\n",
      "                                  '419_2022-03-25': 0,\n",
      "                                  '419_2022-07-18': 0,\n",
      "                                  '419_2022-12-08': 0,\n",
      "                                  '419_2023-02-28': 0,\n",
      "                                  '419_2023-05-16': 0,\n",
      "                                  '419_2024-02-21': 0,\n",
      "                                  '419_2024-07-29': 0,\n",
      "                                  '429_2021-05-10': 3,\n",
      "                                  '429_2022-01-13': 3,\n",
      "                                  '429_2022-06-17': 1,\n",
      "                                  '429_2022-12-01': 3,\n",
      "                                  '429_2023-02-23': 1,\n",
      "                                  '429_2023-06-07': 3,\n",
      "                                  '429_2023-11-30': 1,\n",
      "                                  '429_2024-03-21': 3,\n",
      "                                  '430_2021-06-29': 2,\n",
      "                                  '430_2021-12-15': 2,\n",
      "                                  '430_2022-03-16': 1,\n",
      "                                  '430_2022-06-27': 2,\n",
      "                                  '435_2021-02-19': 3,\n",
      "                                  '435_2022-03-14': 1,\n",
      "                                  '435_2022-06-13': 2,\n",
      "                                  '435_2022-11-01': 2,\n",
      "                                  '437_2021-05-10': 3,\n",
      "                                  '437_2021-11-09': 3,\n",
      "                                  '437_2022-02-07': 3,\n",
      "                                  '437_2022-05-16': 1,\n",
      "                                  '437_2022-09-06': 2,\n",
      "                                  '437_2023-02-17': 2,\n",
      "                                  '442_2021-08-31': 5,\n",
      "                                  '442_2021-11-22': 10,\n",
      "                                  '442_2022-03-29': 7,\n",
      "                                  '449_2021-02-03': 3,\n",
      "                                  '449_2021-12-09': 3,\n",
      "                                  '449_2022-09-20': 2,\n",
      "                                  '453_2021-05-10': 1,\n",
      "                                  '453_2022-02-03': 0,\n",
      "                                  '453_2022-07-06': 1,\n",
      "                                  '453_2022-12-07': 1,\n",
      "                                  '453_2023-01-27': 0,\n",
      "                                  '453_2023-07-24': 0,\n",
      "                                  '453_2023-12-19': 0,\n",
      "                                  '453_2024-03-05': 0,\n",
      "                                  '453_2024-07-29': 1,\n",
      "                                  '458_2021-04-28': 1,\n",
      "                                  '45_2021-02-05': 4,\n",
      "                                  '45_2021-09-20': 6,\n",
      "                                  '45_2021-11-16': 3,\n",
      "                                  '45_2022-02-09': 3,\n",
      "                                  '45_2022-06-13': 3,\n",
      "                                  '45_2022-09-06': 3,\n",
      "                                  '45_2023-01-09': 4,\n",
      "                                  '45_2023-05-02': 5,\n",
      "                                  '45_2023-09-13': 3,\n",
      "                                  '45_2024-01-08': 3,\n",
      "                                  '45_2024-07-01': 5,\n",
      "                                  '45_2024-09-27': 5,\n",
      "                                  '466_2021-02-08': 3,\n",
      "                                  '466_2021-12-21': 1,\n",
      "                                  '466_2022-01-13': 3,\n",
      "                                  '466_2022-06-02': 3,\n",
      "                                  '466_2022-12-09': 3,\n",
      "                                  '466_2023-03-02': 3,\n",
      "                                  '466_2023-07-26': 3,\n",
      "                                  '468_2021-05-10': 2,\n",
      "                                  '468_2022-03-23': 5,\n",
      "                                  '468_2022-07-11': 5,\n",
      "                                  '468_2022-12-01': 3,\n",
      "                                  '468_2023-02-06': 3,\n",
      "                                  '468_2023-05-18': 8,\n",
      "                                  '468_2023-10-31': 3,\n",
      "                                  '468_2024-01-25': 3,\n",
      "                                  '469_2021-05-04': 3,\n",
      "                                  '469_2021-12-06': 3,\n",
      "                                  '469_2022-03-15': 5,\n",
      "                                  '469_2022-07-15': 3,\n",
      "                                  '469_2022-12-01': 4,\n",
      "                                  '469_2023-02-23': 3,\n",
      "                                  '469_2023-05-15': 3,\n",
      "                                  '469_2023-10-23': 3,\n",
      "                                  '469_2024-02-23': 3,\n",
      "                                  '469_2024-07-02': 3,\n",
      "                                  '469_2024-09-27': 3,\n",
      "                                  '474_2021-05-10': 2,\n",
      "                                  '476_2021-04-28': 4,\n",
      "                                  '479_2021-04-29': 0,\n",
      "                                  '479_2021-11-23': 3,\n",
      "                                  '483_2021-02-22': 2,\n",
      "                                  '483_2022-03-28': 3,\n",
      "                                  '483_2022-08-04': 3,\n",
      "                                  '484_2021-03-10': 7,\n",
      "                                  '485_2021-04-29': 4,\n",
      "                                  '485_2021-11-15': 4,\n",
      "                                  '485_2022-02-07': 5,\n",
      "                                  '489_2021-05-13': 5,\n",
      "                                  '489_2021-12-02': 4,\n",
      "                                  '489_2022-02-01': 4,\n",
      "                                  '489_2022-11-03': 4,\n",
      "                                  '489_2024-03-19': 6,\n",
      "                                  '48_2021-06-21': 2,\n",
      "                                  '48_2021-11-19': 2,\n",
      "                                  '48_2022-02-10': 3,\n",
      "                                  '48_2022-05-27': 2,\n",
      "                                  '48_2022-09-14': 2,\n",
      "                                  '48_2023-01-10': 2,\n",
      "                                  '48_2023-05-03': 3,\n",
      "                                  '48_2023-10-02': 3,\n",
      "                                  '48_2024-01-30': 3,\n",
      "                                  '490_2021-05-10': 1,\n",
      "                                  '490_2022-03-29': 3,\n",
      "                                  '490_2023-04-27': 2,\n",
      "                                  '492_2021-03-08': 1,\n",
      "                                  '492_2021-11-02': 2,\n",
      "                                  '492_2022-02-03': 1,\n",
      "                                  '492_2022-05-09': 2,\n",
      "                                  '492_2022-09-06': 3,\n",
      "                                  '492_2023-01-10': 3,\n",
      "                                  '492_2023-05-03': 2,\n",
      "                                  '492_2023-09-21': 1,\n",
      "                                  '492_2024-01-11': 2,\n",
      "                                  '494_2021-06-03': 3,\n",
      "                                  '498_2021-04-13': 1,\n",
      "                                  '498_2021-11-08': 1,\n",
      "                                  '498_2022-01-31': 0,\n",
      "                                  '498_2022-06-13': 1,\n",
      "                                  '498_2022-11-10': 0,\n",
      "                                  '498_2023-02-07': 0,\n",
      "                                  '498_2023-05-24': 1,\n",
      "                                  '498_2023-10-13': 1,\n",
      "                                  '498_2024-03-01': 1,\n",
      "                                  '498_2024-08-05': 0,\n",
      "                                  '501_2021-02-02': 5,\n",
      "                                  '501_2022-01-07': 7,\n",
      "                                  '501_2022-05-09': 3,\n",
      "                                  '501_2022-11-16': 1,\n",
      "                                  '501_2023-02-02': 5,\n",
      "                                  '501_2023-05-11': 2,\n",
      "                                  '501_2023-10-30': 3,\n",
      "                                  '501_2024-01-12': 3,\n",
      "                                  '501_2024-06-07': 1,\n",
      "                                  '504_2021-03-08': 2,\n",
      "                                  '504_2021-11-02': 1,\n",
      "                                  '504_2022-02-03': 3,\n",
      "                                  '504_2022-05-18': 3,\n",
      "                                  '504_2022-09-08': 3,\n",
      "                                  '504_2023-01-27': 3,\n",
      "                                  '504_2023-08-02': 3,\n",
      "                                  '504_2023-11-15': 3,\n",
      "                                  '504_2024-02-12': 3,\n",
      "                                  '504_2024-09-27': 3,\n",
      "                                  '506_2021-02-25': 7,\n",
      "                                  '506_2022-07-19': 3,\n",
      "                                  '506_2022-12-13': 9,\n",
      "                                  '507_2021-02-09': 5,\n",
      "                                  '507_2022-07-13': 3,\n",
      "                                  '507_2022-12-06': 4,\n",
      "                                  '507_2023-03-20': 3,\n",
      "                                  '507_2023-07-31': 3,\n",
      "                                  '507_2023-11-27': 3,\n",
      "                                  '509_2021-08-25': 2,\n",
      "                                  '509_2022-03-22': 3,\n",
      "                                  '509_2022-08-03': 1,\n",
      "                                  '509_2023-04-27': 0,\n",
      "                                  '509_2023-08-28': 3,\n",
      "                                  '509_2023-11-17': 3,\n",
      "                                  '509_2024-02-16': 2,\n",
      "                                  '509_2024-08-16': 3,\n",
      "                                  '50_2021-01-29': 3,\n",
      "                                  '50_2022-01-19': 3,\n",
      "                                  '50_2022-05-19': 3,\n",
      "                                  '511_2021-02-25': 5,\n",
      "                                  '511_2021-12-27': 5,\n",
      "                                  '511_2022-03-25': 3,\n",
      "                                  '511_2022-07-14': 5,\n",
      "                                  '511_2022-12-07': 4,\n",
      "                                  '511_2023-03-10': 4,\n",
      "                                  '511_2023-06-26': 3,\n",
      "                                  '511_2023-12-18': 3,\n",
      "                                  '511_2024-03-25': 3,\n",
      "                                  '511_2024-08-26': 3,\n",
      "                                  '512_2021-02-03': 3,\n",
      "                                  '512_2022-03-22': 3,\n",
      "                                  '512_2022-07-19': 3,\n",
      "                                  '517_2021-05-17': 2,\n",
      "                                  '517_2021-12-21': 1,\n",
      "                                  '517_2022-04-11': 1,\n",
      "                                  '517_2022-08-16': 3,\n",
      "                                  '517_2022-11-22': 1,\n",
      "                                  '517_2023-04-10': 3,\n",
      "                                  '517_2023-08-14': 0,\n",
      "                                  '517_2024-03-28': 2,\n",
      "                                  '519_2021-06-14': 1,\n",
      "                                  '519_2021-12-09': 1,\n",
      "                                  '519_2022-02-18': 1,\n",
      "                                  '519_2022-06-21': 2,\n",
      "                                  '519_2022-11-18': 0,\n",
      "                                  '519_2023-02-10': 1,\n",
      "                                  '519_2023-05-19': 0,\n",
      "                                  '519_2023-11-13': 0,\n",
      "                                  '519_2024-02-12': 0,\n",
      "                                  '519_2024-06-05': 0,\n",
      "                                  '519_2024-09-18': 1,\n",
      "                                  '51_2021-05-04': 5,\n",
      "                                  '522_2021-06-18': 3,\n",
      "                                  '522_2021-12-10': 2,\n",
      "                                  '522_2022-03-18': 3,\n",
      "                                  '522_2022-07-13': 0,\n",
      "                                  '522_2022-12-01': 0,\n",
      "                                  '522_2023-02-21': 0,\n",
      "                                  '522_2023-10-05': 0,\n",
      "                                  '522_2024-02-01': 0,\n",
      "                                  '522_2024-08-13': 0,\n",
      "                                  '523_2021-05-10': 3,\n",
      "                                  '523_2021-12-22': 2,\n",
      "                                  '523_2022-03-29': 2,\n",
      "                                  '523_2022-07-13': 3,\n",
      "                                  '526_2021-05-24': 2,\n",
      "                                  '526_2022-03-18': 2,\n",
      "                                  '526_2022-06-23': 3,\n",
      "                                  '526_2023-01-13': 3,\n",
      "                                  '526_2023-05-10': 5,\n",
      "                                  '526_2023-09-19': 4,\n",
      "                                  '526_2024-03-19': 3,\n",
      "                                  '526_2024-08-08': 4,\n",
      "                                  '527_2021-02-05': 1,\n",
      "                                  '527_2021-07-01': 2,\n",
      "                                  '527_2021-12-22': 2,\n",
      "                                  '527_2022-04-19': 0,\n",
      "                                  '527_2022-07-19': 2,\n",
      "                                  '527_2023-03-09': 0,\n",
      "                                  '527_2023-05-02': 3,\n",
      "                                  '527_2023-09-08': 3,\n",
      "                                  '527_2024-03-13': 3,\n",
      "                                  '530_2021-05-13': 3,\n",
      "                                  '530_2021-11-24': 3,\n",
      "                                  '530_2022-02-14': 5,\n",
      "                                  '530_2022-06-07': 3,\n",
      "                                  '530_2023-01-09': 2,\n",
      "                                  '530_2023-05-02': 2,\n",
      "                                  '530_2023-09-20': 2,\n",
      "                                  '530_2024-01-11': 2,\n",
      "                                  '530_2024-06-10': 3,\n",
      "                                  '530_2024-09-17': 3,\n",
      "                                  '533_2021-05-07': 3,\n",
      "                                  '533_2021-12-02': 3,\n",
      "                                  '533_2022-07-14': 3,\n",
      "                                  '534_2021-02-26': 9,\n",
      "                                  '535_2021-07-16': 4,\n",
      "                                  '536_2021-05-05': 2,\n",
      "                                  '536_2022-02-14': 0,\n",
      "                                  '536_2022-05-24': 2,\n",
      "                                  '542_2021-02-25': 1,\n",
      "                                  '542_2021-09-21': 2,\n",
      "                                  '542_2022-03-22': 1,\n",
      "                                  '545_2021-06-02': 4,\n",
      "                                  '545_2022-03-07': 3,\n",
      "                                  '545_2022-06-08': 3,\n",
      "                                  '545_2023-04-06': 3,\n",
      "                                  '545_2023-05-15': 4,\n",
      "                                  '545_2023-09-18': 3,\n",
      "                                  '545_2024-02-08': 3,\n",
      "                                  '545_2024-07-24': 4,\n",
      "                                  '546_2021-07-20': 0,\n",
      "                                  '546_2022-03-15': 2,\n",
      "                                  '546_2022-05-31': 1,\n",
      "                                  '547_2021-02-24': 8,\n",
      "                                  '547_2021-12-06': 9,\n",
      "                                  '548_2021-06-11': 0,\n",
      "                                  '548_2021-12-09': 1,\n",
      "                                  '548_2022-03-16': 0,\n",
      "                                  '548_2022-08-03': 0,\n",
      "                                  '548_2023-04-07': 0,\n",
      "                                  '548_2023-05-03': 0,\n",
      "                                  '548_2023-09-07': 3,\n",
      "                                  '548_2024-01-12': 3,\n",
      "                                  '548_2024-07-30': 3,\n",
      "                                  '549_2021-07-13': 4,\n",
      "                                  '553_2021-07-13': 1,\n",
      "                                  '553_2022-08-03': 4,\n",
      "                                  '553_2023-03-01': 3,\n",
      "                                  '553_2023-05-10': 3,\n",
      "                                  '553_2023-06-02': 3,\n",
      "                                  '555_2021-05-05': 1,\n",
      "                                  '555_2021-11-30': 2,\n",
      "                                  '555_2022-03-16': 2,\n",
      "                                  '555_2022-07-13': 1,\n",
      "                                  '555_2023-04-03': 2,\n",
      "                                  '555_2023-05-03': 2,\n",
      "                                  '555_2023-10-09': 5,\n",
      "                                  '555_2024-03-01': 3,\n",
      "                                  '555_2024-06-28': 2,\n",
      "                                  '555_2024-09-27': 3,\n",
      "                                  '557_2021-05-24': 0,\n",
      "                                  '557_2022-02-14': 3,\n",
      "                                  '557_2022-05-31': 2,\n",
      "                                  '557_2023-04-19': 0,\n",
      "                                  '557_2023-05-15': 5,\n",
      "                                  '559_2021-01-22': 5,\n",
      "                                  '559_2021-09-13': 5,\n",
      "                                  '560_2021-06-03': 4,\n",
      "                                  '560_2022-03-14': 3,\n",
      "                                  '560_2022-08-29': 5,\n",
      "                                  '560_2023-04-12': 6,\n",
      "                                  '561_2021-07-20': 5,\n",
      "                                  '562_2021-06-09': 5,\n",
      "                                  '562_2021-12-14': 3,\n",
      "                                  '562_2022-03-14': 4,\n",
      "                                  '562_2022-05-31': 3,\n",
      "                                  '562_2023-03-13': 3,\n",
      "                                  '562_2023-05-04': 3,\n",
      "                                  '562_2023-09-05': 3,\n",
      "                                  '562_2024-03-20': 4,\n",
      "                                  '562_2024-08-07': 3,\n",
      "                                  '563_2021-06-07': 1,\n",
      "                                  '563_2021-12-14': 0,\n",
      "                                  '563_2022-03-18': 0,\n",
      "                                  '563_2022-06-22': 0,\n",
      "                                  '563_2022-11-10': 1,\n",
      "                                  '563_2023-04-19': 2,\n",
      "                                  '563_2023-06-12': 3,\n",
      "                                  '563_2023-11-13': 3,\n",
      "                                  '563_2024-04-02': 3,\n",
      "                                  '564_2021-05-21': 5,\n",
      "                                  '564_2022-03-29': 9,\n",
      "                                  '566_2021-06-17': 2,\n",
      "                                  '566_2021-12-14': 1,\n",
      "                                  '566_2022-03-16': 1,\n",
      "                                  '566_2022-06-22': 1,\n",
      "                                  '567_2022-03-07': 3,\n",
      "                                  '567_2022-06-15': 3,\n",
      "                                  '567_2022-11-14': 1,\n",
      "                                  '567_2023-04-25': 2,\n",
      "                                  '567_2023-12-12': 3,\n",
      "                                  '567_2024-02-20': 3,\n",
      "                                  '567_2024-07-23': 3,\n",
      "                                  '569_2021-05-24': 3,\n",
      "                                  '569_2022-03-07': 2,\n",
      "                                  '569_2022-06-22': 4,\n",
      "                                  '569_2023-04-13': 6,\n",
      "                                  '569_2023-05-08': 7,\n",
      "                                  '56_2021-04-29': 3,\n",
      "                                  '56_2021-11-15': 1,\n",
      "                                  '571_2021-03-08': 5,\n",
      "                                  '573_2021-09-13': 2,\n",
      "                                  '573_2022-03-22': 2,\n",
      "                                  '573_2023-03-14': 1,\n",
      "                                  '573_2023-05-04': 3,\n",
      "                                  '573_2023-12-13': 3,\n",
      "                                  '573_2024-03-22': 3,\n",
      "                                  '577_2021-02-24': 6,\n",
      "                                  '577_2022-03-18': 5,\n",
      "                                  '577_2022-08-02': 7,\n",
      "                                  '580_2021-08-25': 7,\n",
      "                                  '581_2021-06-01': 3,\n",
      "                                  '581_2022-02-15': 3,\n",
      "                                  '581_2022-08-03': 3,\n",
      "                                  '581_2023-04-11': 3,\n",
      "                                  '581_2023-06-22': 5,\n",
      "                                  '581_2023-10-12': 6,\n",
      "                                  '581_2024-03-01': 7,\n",
      "                                  '581_2024-07-31': 5,\n",
      "                                  '584_2021-07-01': 6,\n",
      "                                  '584_2022-04-19': 5,\n",
      "                                  '584_2022-08-02': 9,\n",
      "                                  '584_2023-04-13': 2,\n",
      "                                  '593_2021-06-02': 2,\n",
      "                                  '593_2021-12-23': 2,\n",
      "                                  '593_2022-07-18': 1,\n",
      "                                  '593_2023-04-14': 3,\n",
      "                                  '593_2023-05-24': 3,\n",
      "                                  '593_2023-11-10': 3,\n",
      "                                  '598_2021-06-01': 2,\n",
      "                                  '598_2021-12-21': 5,\n",
      "                                  '598_2022-04-19': 5,\n",
      "                                  '598_2022-07-20': 3,\n",
      "                                  '598_2023-04-07': 5,\n",
      "                                  '598_2023-05-08': 1,\n",
      "                                  '598_2023-09-14': 6,\n",
      "                                  '598_2024-01-12': 3,\n",
      "                                  '598_2024-09-27': 3,\n",
      "                                  '599_2021-06-17': 2,\n",
      "                                  '599_2021-12-23': 0,\n",
      "                                  '599_2022-03-30': 0,\n",
      "                                  '600_2021-03-08': 0,\n",
      "                                  '600_2021-11-02': 1,\n",
      "                                  '600_2022-02-07': 0,\n",
      "                                  '600_2022-05-16': 0,\n",
      "                                  '600_2022-09-07': 0,\n",
      "                                  '600_2023-01-10': 0,\n",
      "                                  '600_2023-05-08': 0,\n",
      "                                  '600_2023-09-21': 1,\n",
      "                                  '600_2024-01-11': 0,\n",
      "                                  '600_2024-07-17': 0,\n",
      "                                  '601_2021-07-13': 3,\n",
      "                                  '601_2022-03-29': 6,\n",
      "                                  '601_2022-07-13': 4,\n",
      "                                  '601_2023-04-28': 8,\n",
      "                                  '604_2021-06-17': 5,\n",
      "                                  '604_2021-12-23': 2,\n",
      "                                  '604_2022-04-26': 1,\n",
      "                                  '604_2022-08-29': 2,\n",
      "                                  '604_2023-02-23': 3,\n",
      "                                  '604_2023-06-09': 3,\n",
      "                                  '604_2023-11-07': 2,\n",
      "                                  '604_2024-03-05': 3,\n",
      "                                  '604_2024-08-12': 4,\n",
      "                                  '606_2021-01-28': 4,\n",
      "                                  '606_2021-07-01': 2,\n",
      "                                  '606_2021-12-22': 2,\n",
      "                                  '606_2022-03-30': 1,\n",
      "                                  '606_2022-07-18': 1,\n",
      "                                  '606_2022-11-15': 2,\n",
      "                                  '606_2023-04-11': 3,\n",
      "                                  '606_2023-05-03': 5,\n",
      "                                  '606_2023-10-25': 5,\n",
      "                                  '606_2024-01-12': 3,\n",
      "                                  '606_2024-06-28': 3,\n",
      "                                  '606_2024-09-27': 4,\n",
      "                                  '607_2021-07-13': 7,\n",
      "                                  '607_2021-12-28': 7,\n",
      "                                  '608_2021-09-21': 3,\n",
      "                                  '609_2021-06-17': 1,\n",
      "                                  '609_2021-12-29': 0,\n",
      "                                  '609_2022-04-19': 0,\n",
      "                                  '609_2022-07-19': 0,\n",
      "                                  '609_2023-05-02': 3,\n",
      "                                  '609_2023-09-18': 3,\n",
      "                                  '609_2024-03-13': 3,\n",
      "                                  '609_2024-08-26': 3,\n",
      "                                  '611_2021-05-05': 1,\n",
      "                                  '611_2021-12-13': 0,\n",
      "                                  '613_2021-06-29': 3,\n",
      "                                  '613_2022-03-14': 1,\n",
      "                                  '616_2021-03-11': 1,\n",
      "                                  '616_2021-12-22': 1,\n",
      "                                  '617_2021-02-05': 3,\n",
      "                                  '617_2021-07-09': 3,\n",
      "                                  '618_2021-07-01': 9,\n",
      "                                  '618_2021-12-28': 0,\n",
      "                                  '618_2022-04-19': 0,\n",
      "                                  '618_2022-08-02': 3,\n",
      "                                  '618_2023-04-06': 2,\n",
      "                                  '618_2023-05-03': 3,\n",
      "                                  '618_2023-10-09': 3,\n",
      "                                  '618_2024-01-12': 3,\n",
      "                                  '618_2024-08-06': 3,\n",
      "                                  '61_2021-05-11': 3,\n",
      "                                  '61_2021-12-27': 9,\n",
      "                                  '61_2022-03-18': 6,\n",
      "                                  '621_2021-12-13': 3,\n",
      "                                  '621_2022-03-30': 2,\n",
      "                                  '621_2022-07-18': 0,\n",
      "                                  '621_2023-04-21': 5,\n",
      "                                  '621_2023-05-08': 3,\n",
      "                                  '621_2023-09-06': 7,\n",
      "                                  '621_2024-02-16': 3,\n",
      "                                  '622_2021-06-17': 5,\n",
      "                                  '622_2021-12-13': 4,\n",
      "                                  '622_2022-03-18': 9,\n",
      "                                  '622_2022-06-27': 4,\n",
      "                                  '622_2022-11-18': 4,\n",
      "                                  '622_2023-02-21': 7,\n",
      "                                  '628_2021-02-01': 3,\n",
      "                                  '628_2021-12-02': 3,\n",
      "                                  '628_2022-04-11': 3,\n",
      "                                  '628_2022-08-18': 3,\n",
      "                                  '628_2022-11-15': 3,\n",
      "                                  '628_2023-03-02': 3,\n",
      "                                  '628_2023-08-04': 3,\n",
      "                                  '628_2024-03-27': 3,\n",
      "                                  '628_2024-09-27': 3,\n",
      "                                  '629_2021-02-05': 5,\n",
      "                                  '629_2021-07-09': 3,\n",
      "                                  '629_2022-03-18': 3,\n",
      "                                  '629_2022-06-28': 3,\n",
      "                                  '631_2021-07-01': 2,\n",
      "                                  '631_2021-12-17': 1,\n",
      "                                  '631_2022-03-15': 0,\n",
      "                                  '631_2022-07-06': 2,\n",
      "                                  '631_2022-12-02': 1,\n",
      "                                  '631_2023-03-13': 2,\n",
      "                                  '631_2023-08-14': 2,\n",
      "                                  '631_2023-11-13': 1,\n",
      "                                  '633_2021-05-07': 2,\n",
      "                                  '633_2021-12-21': 5,\n",
      "                                  '633_2022-06-14': 2,\n",
      "                                  '633_2022-12-01': 0,\n",
      "                                  '633_2023-03-09': 1,\n",
      "                                  '633_2023-07-13': 0,\n",
      "                                  '634_2021-05-24': 3,\n",
      "                                  '634_2022-01-12': 2,\n",
      "                                  '634_2022-06-08': 3,\n",
      "                                  '634_2022-10-10': 3,\n",
      "                                  '634_2023-01-27': 3,\n",
      "                                  '634_2023-05-31': 3,\n",
      "                                  '634_2023-11-20': 3,\n",
      "                                  '634_2024-03-18': 3,\n",
      "                                  '634_2024-06-25': 3,\n",
      "                                  '635_2021-02-05': 7,\n",
      "                                  '635_2021-07-12': 3,\n",
      "                                  '635_2022-03-07': 0,\n",
      "                                  '635_2022-11-08': 1,\n",
      "                                  '635_2023-04-28': 3,\n",
      "                                  '635_2023-06-22': 3,\n",
      "                                  '635_2024-03-14': 0,\n",
      "                                  '636_2021-02-05': 4,\n",
      "                                  '636_2021-09-20': 2,\n",
      "                                  '636_2022-05-25': 3,\n",
      "                                  '636_2022-12-12': 3,\n",
      "                                  '636_2023-06-27': 3,\n",
      "                                  '636_2023-12-18': 3,\n",
      "                                  '640_2021-08-02': 6,\n",
      "                                  '640_2021-12-10': 3,\n",
      "                                  '640_2022-03-18': 5,\n",
      "                                  '640_2022-07-07': 3,\n",
      "                                  '640_2022-12-05': 3,\n",
      "                                  '640_2023-03-09': 5,\n",
      "                                  '641_2021-05-21': 7,\n",
      "                                  '641_2022-03-24': 7,\n",
      "                                  '641_2022-07-27': 5,\n",
      "                                  '642_2021-02-09': 0,\n",
      "                                  '642_2021-11-23': 2,\n",
      "                                  '642_2022-05-31': 3,\n",
      "                                  '642_2022-11-14': 3,\n",
      "                                  '643_2021-05-13': 2,\n",
      "                                  '643_2021-12-17': 4,\n",
      "                                  '643_2023-04-19': 2,\n",
      "                                  '643_2023-12-21': 2,\n",
      "                                  '643_2024-04-01': 2,\n",
      "                                  '644_2021-05-10': 1,\n",
      "                                  '644_2022-03-18': 2,\n",
      "                                  '644_2022-09-14': 3,\n",
      "                                  '644_2023-01-18': 1,\n",
      "                                  '645_2021-05-10': 1,\n",
      "                                  '645_2021-12-27': 2,\n",
      "                                  '645_2022-04-06': 1,\n",
      "                                  '645_2022-08-05': 1,\n",
      "                                  '645_2022-12-06': 1,\n",
      "                                  '645_2023-04-04': 0,\n",
      "                                  '645_2023-08-22': 3,\n",
      "                                  '645_2023-12-12': 1,\n",
      "                                  '645_2024-03-27': 0,\n",
      "                                  '645_2024-08-26': 1,\n",
      "                                  '646_2021-02-03': 1,\n",
      "                                  '646_2022-03-31': 1,\n",
      "                                  '646_2022-07-27': 3,\n",
      "                                  '646_2022-12-13': 5,\n",
      "                                  '646_2023-04-07': 3,\n",
      "                                  '646_2023-08-22': 3,\n",
      "                                  '646_2024-03-27': 1,\n",
      "                                  '646_2024-08-27': 3,\n",
      "                                  '650_2021-05-11': 7,\n",
      "                                  '650_2021-12-06': 6,\n",
      "                                  '650_2022-03-29': 6,\n",
      "                                  '650_2022-07-29': 9,\n",
      "                                  '650_2022-12-02': 3,\n",
      "                                  '650_2023-03-10': 5,\n",
      "                                  '650_2023-08-04': 7,\n",
      "                                  '650_2023-12-13': 11,\n",
      "                                  '650_2024-03-28': 6,\n",
      "                                  '650_2024-08-26': 9,\n",
      "                                  '651_2021-05-13': 1,\n",
      "                                  '651_2021-12-08': 3,\n",
      "                                  '651_2022-04-05': 3,\n",
      "                                  '651_2022-07-21': 0,\n",
      "                                  '651_2022-12-19': 3,\n",
      "                                  '651_2024-08-01': 0,\n",
      "                                  '652_2021-08-24': 1,\n",
      "                                  '652_2021-12-15': 3,\n",
      "                                  '652_2022-07-11': 0,\n",
      "                                  '652_2022-12-19': 0,\n",
      "                                  '652_2023-01-27': 1,\n",
      "                                  '652_2023-07-31': 3,\n",
      "                                  '653_2021-05-11': 7,\n",
      "                                  '653_2022-01-11': 7,\n",
      "                                  '653_2022-07-11': 9,\n",
      "                                  '653_2022-12-06': 5,\n",
      "                                  '656_2021-06-29': 3,\n",
      "                                  '656_2021-12-23': 2,\n",
      "                                  '656_2022-04-04': 2,\n",
      "                                  '656_2022-07-21': 2,\n",
      "                                  '656_2023-08-23': 0,\n",
      "                                  '656_2023-12-04': 2,\n",
      "                                  '656_2024-02-16': 2,\n",
      "                                  '656_2024-07-08': 3,\n",
      "                                  '661_2021-06-23': 12,\n",
      "                                  '661_2021-12-01': 4,\n",
      "                                  '661_2022-02-16': 9,\n",
      "                                  '661_2022-06-22': 2,\n",
      "                                  '661_2022-11-22': 0,\n",
      "                                  '661_2023-03-27': 4,\n",
      "                                  '661_2023-05-15': 2,\n",
      "                                  '662_2021-06-18': 0,\n",
      "                                  '662_2021-12-08': 1,\n",
      "                                  '662_2022-02-28': 1,\n",
      "                                  '662_2022-06-13': 0,\n",
      "                                  '662_2022-09-30': 0,\n",
      "                                  '662_2023-02-13': 1,\n",
      "                                  '662_2023-05-19': 0,\n",
      "                                  '662_2023-10-09': 1,\n",
      "                                  '662_2024-03-18': 0,\n",
      "                                  '662_2024-07-29': 3,\n",
      "                                  '664_2021-05-13': 3,\n",
      "                                  '664_2021-12-28': 4,\n",
      "                                  '664_2022-04-19': 3,\n",
      "                                  '664_2022-08-29': 3,\n",
      "                                  '664_2023-04-27': 3,\n",
      "                                  '664_2024-03-22': 2,\n",
      "                                  '66_2021-01-26': 3,\n",
      "                                  '66_2021-09-20': 3,\n",
      "                                  '66_2022-02-11': 5,\n",
      "                                  '66_2022-05-26': 3,\n",
      "                                  '66_2022-10-03': 2,\n",
      "                                  '66_2023-01-18': 3,\n",
      "                                  '66_2023-05-10': 3,\n",
      "                                  '66_2023-09-11': 3,\n",
      "                                  '66_2024-01-11': 3,\n",
      "                                  '66_2024-06-07': 2,\n",
      "                                  '66_2024-09-27': 3,\n",
      "                                  '670_2022-04-19': 3,\n",
      "                                  '670_2022-08-02': 4,\n",
      "                                  '670_2023-04-07': 1,\n",
      "                                  '670_2023-05-18': 3,\n",
      "                                  '670_2023-10-13': 3,\n",
      "                                  '671_2021-12-02': 2,\n",
      "                                  '671_2022-04-14': 2,\n",
      "                                  '671_2022-12-15': 4,\n",
      "                                  '671_2023-04-12': 3,\n",
      "                                  '673_2021-03-24': 1,\n",
      "                                  '673_2021-12-09': 2,\n",
      "                                  '673_2022-01-07': 1,\n",
      "                                  '673_2022-06-09': 4,\n",
      "                                  '675_2021-08-11': 2,\n",
      "                                  '676_2021-08-03': 2,\n",
      "                                  '676_2021-12-14': 1,\n",
      "                                  '676_2022-04-04': 3,\n",
      "                                  '676_2022-07-15': 2,\n",
      "                                  '676_2022-11-30': 2,\n",
      "                                  '676_2023-06-13': 0,\n",
      "                                  '676_2023-09-21': 1,\n",
      "                                  '677_2021-03-03': 1,\n",
      "                                  '677_2021-12-06': 1,\n",
      "                                  '677_2022-03-14': 0,\n",
      "                                  '677_2022-12-12': 5,\n",
      "                                  '677_2023-04-06': 2,\n",
      "                                  '677_2023-11-15': 5,\n",
      "                                  '677_2024-03-27': 2,\n",
      "                                  '677_2024-08-02': 1,\n",
      "                                  '678_2022-03-30': 3,\n",
      "                                  '678_2022-08-18': 3,\n",
      "                                  '678_2022-12-08': 3,\n",
      "                                  '678_2023-03-01': 3,\n",
      "                                  '678_2023-06-07': 2,\n",
      "                                  '678_2024-03-18': 1,\n",
      "                                  '678_2024-06-25': 2,\n",
      "                                  '679_2021-06-07': 4,\n",
      "                                  '679_2021-11-15': 2,\n",
      "                                  '679_2022-02-07': 5,\n",
      "                                  '679_2022-05-10': 5,\n",
      "                                  '679_2022-09-08': 3,\n",
      "                                  '679_2023-02-09': 1,\n",
      "                                  '679_2023-05-25': 1,\n",
      "                                  '679_2023-11-22': 3,\n",
      "                                  '679_2024-02-16': 3,\n",
      "                                  '679_2024-08-12': 6,\n",
      "                                  '680_2021-07-09': 5,\n",
      "                                  '680_2021-10-08': 2,\n",
      "                                  '680_2022-06-13': 3,\n",
      "                                  '680_2022-10-04': 2,\n",
      "                                  '680_2023-06-01': 2,\n",
      "                                  '681_2021-12-10': 1,\n",
      "                                  '681_2022-03-22': 5,\n",
      "                                  '681_2022-08-29': 6,\n",
      "                                  '682_2021-08-04': 0,\n",
      "                                  '683_2021-07-08': 0,\n",
      "                                  '683_2021-12-01': 7,\n",
      "                                  '683_2022-01-25': 0,\n",
      "                                  '683_2022-05-19': 2,\n",
      "                                  '683_2022-11-02': 2,\n",
      "                                  '683_2023-02-09': 4,\n",
      "                                  '683_2023-05-12': 3,\n",
      "                                  '683_2023-10-24': 0,\n",
      "                                  '683_2024-02-21': 3,\n",
      "                                  '683_2024-07-11': 0,\n",
      "                                  '685_2021-07-19': 3,\n",
      "                                  '686_2021-03-04': 0,\n",
      "                                  '686_2021-10-28': 0,\n",
      "                                  '686_2022-03-25': 0,\n",
      "                                  '686_2022-06-17': 1,\n",
      "                                  '686_2022-11-18': 1,\n",
      "                                  '686_2023-02-24': 0,\n",
      "                                  '687_2021-12-10': 1,\n",
      "                                  '687_2022-04-04': 1,\n",
      "                                  '687_2022-08-08': 0,\n",
      "                                  '687_2022-12-08': 3,\n",
      "                                  '687_2023-03-13': 0,\n",
      "                                  '687_2023-05-30': 2,\n",
      "                                  '687_2024-02-21': 1,\n",
      "                                  '689_2021-04-28': 1,\n",
      "                                  '689_2022-06-10': 2,\n",
      "                                  '689_2022-12-06': 1,\n",
      "                                  '689_2023-02-27': 2,\n",
      "                                  '689_2023-05-08': 2,\n",
      "                                  '689_2023-10-09': 0,\n",
      "                                  '689_2024-02-12': 2,\n",
      "                                  '689_2024-07-02': 0,\n",
      "                                  '692_2022-03-28': 2,\n",
      "                                  '692_2023-04-24': 3,\n",
      "                                  '692_2023-09-01': 2,\n",
      "                                  '692_2023-11-13': 3,\n",
      "                                  '692_2024-02-09': 5,\n",
      "                                  '692_2024-07-30': 5,\n",
      "                                  '693_2021-03-05': 5,\n",
      "                                  '695_2021-06-02': 4,\n",
      "                                  '695_2022-03-29': 3,\n",
      "                                  '695_2023-04-04': 8,\n",
      "                                  '695_2023-05-04': 3,\n",
      "                                  '695_2023-12-08': 9,\n",
      "                                  '695_2024-03-14': 1,\n",
      "                                  '695_2024-07-25': 3,\n",
      "                                  '698_2021-06-18': 2,\n",
      "                                  '698_2022-03-18': 1,\n",
      "                                  '698_2022-06-27': 2,\n",
      "                                  '698_2022-12-05': 1,\n",
      "                                  '698_2023-02-28': 1,\n",
      "                                  '698_2023-07-05': 1,\n",
      "                                  '699_2022-12-05': 1,\n",
      "                                  '699_2023-04-19': 5,\n",
      "                                  '699_2023-08-17': 1,\n",
      "                                  '699_2023-12-13': 3,\n",
      "                                  '699_2024-03-27': 3,\n",
      "                                  '700_2021-11-04': 0,\n",
      "                                  '700_2022-05-24': 1,\n",
      "                                  '702_2021-07-08': 3,\n",
      "                                  '702_2021-12-10': 3,\n",
      "                                  '702_2022-04-19': 2,\n",
      "                                  '702_2022-07-20': 4,\n",
      "                                  '702_2023-04-13': 3,\n",
      "                                  '702_2023-05-18': 3,\n",
      "                                  '702_2023-10-09': 3,\n",
      "                                  '702_2024-02-09': 3,\n",
      "                                  '702_2024-07-30': 3,\n",
      "                                  '703_2021-07-29': 3,\n",
      "                                  '703_2021-12-08': 3,\n",
      "                                  '703_2022-04-11': 2,\n",
      "                                  '707_2022-04-26': 1,\n",
      "                                  '707_2022-08-08': 4,\n",
      "                                  '707_2023-04-26': 3,\n",
      "                                  '709_2021-12-09': 2,\n",
      "                                  '709_2022-02-22': 4,\n",
      "                                  '709_2022-06-21': 2,\n",
      "                                  '709_2022-12-13': 2,\n",
      "                                  '710_2021-08-24': 0,\n",
      "                                  '710_2021-11-22': 0,\n",
      "                                  '710_2022-03-15': 0,\n",
      "                                  '710_2022-08-02': 0,\n",
      "                                  '710_2022-11-15': 0,\n",
      "                                  '710_2023-03-03': 0,\n",
      "                                  '710_2023-05-24': 1,\n",
      "                                  '710_2023-11-13': 3,\n",
      "                                  '710_2024-02-02': 3,\n",
      "                                  '710_2024-07-03': 3,\n",
      "                                  '713_2021-08-23': 3,\n",
      "                                  '713_2022-04-21': 2,\n",
      "                                  '713_2022-08-29': 1,\n",
      "                                  '713_2022-12-07': 1,\n",
      "                                  '713_2023-04-04': 2,\n",
      "                                  '713_2023-08-10': 1,\n",
      "                                  '713_2023-12-13': 1,\n",
      "                                  '713_2024-03-19': 3,\n",
      "                                  '715_2021-11-11': 4,\n",
      "                                  '716_2022-04-07': 0,\n",
      "                                  '716_2022-07-26': 1,\n",
      "                                  '716_2022-11-23': 3,\n",
      "                                  '716_2023-02-14': 2,\n",
      "                                  '716_2023-06-12': 3,\n",
      "                                  '716_2023-11-13': 3,\n",
      "                                  '716_2024-03-18': 2,\n",
      "                                  '716_2024-08-29': 3,\n",
      "                                  '717_2022-04-06': 3,\n",
      "                                  '717_2022-12-12': 2,\n",
      "                                  '717_2023-04-06': 1,\n",
      "                                  '717_2023-08-15': 3,\n",
      "                                  '717_2023-11-17': 4,\n",
      "                                  '717_2024-03-18': 2,\n",
      "                                  '717_2024-08-27': 2,\n",
      "                                  '718_2021-11-12': 6,\n",
      "                                  '718_2022-04-12': 3,\n",
      "                                  '718_2022-08-31': 0,\n",
      "                                  '718_2023-04-26': 6,\n",
      "                                  '718_2023-08-17': 8,\n",
      "                                  '718_2024-01-03': 7,\n",
      "                                  '720_2021-09-29': 9,\n",
      "                                  '720_2022-04-20': 6,\n",
      "                                  '720_2022-08-19': 3,\n",
      "                                  '720_2023-04-19': 7,\n",
      "                                  '720_2023-08-29': 6,\n",
      "                                  '720_2024-03-27': 5,\n",
      "                                  '721_2021-10-06': 3,\n",
      "                                  '721_2022-04-19': 3,\n",
      "                                  '721_2022-08-10': 3,\n",
      "                                  '721_2023-04-27': 6,\n",
      "                                  '723_2021-12-14': 0,\n",
      "                                  '723_2022-04-21': 0,\n",
      "                                  '723_2022-08-30': 1,\n",
      "                                  '728_2021-11-05': 2,\n",
      "                                  '728_2022-04-12': 2,\n",
      "                                  '728_2022-07-26': 1,\n",
      "                                  '728_2022-11-02': 3,\n",
      "                                  '728_2023-04-20': 3,\n",
      "                                  '728_2023-05-18': 3,\n",
      "                                  '728_2023-09-14': 3,\n",
      "                                  '728_2024-01-19': 3,\n",
      "                                  '728_2024-07-29': 3,\n",
      "                                  '729_2021-12-30': 0,\n",
      "                                  '729_2022-04-13': 2,\n",
      "                                  '729_2022-07-11': 2,\n",
      "                                  '729_2022-12-01': 2,\n",
      "                                  '729_2023-02-06': 0,\n",
      "                                  '729_2023-05-08': 2,\n",
      "                                  '729_2023-11-08': 2,\n",
      "                                  '729_2024-02-01': 1,\n",
      "                                  '729_2024-07-08': 0,\n",
      "                                  '729_2024-09-26': 1,\n",
      "                                  '72_2021-11-23': 3,\n",
      "                                  '72_2022-03-16': 4,\n",
      "                                  '732_2022-03-16': 2,\n",
      "                                  '732_2022-08-03': 1,\n",
      "                                  '732_2022-12-14': 0,\n",
      "                                  '732_2023-03-31': 2,\n",
      "                                  '732_2023-08-11': 3,\n",
      "                                  '732_2024-03-21': 3,\n",
      "                                  '732_2024-08-05': 3,\n",
      "                                  '733_2022-08-22': 2,\n",
      "                                  '733_2023-04-27': 3,\n",
      "                                  '733_2023-09-06': 2,\n",
      "                                  '733_2024-04-01': 3,\n",
      "                                  '734_2022-07-19': 1,\n",
      "                                  '734_2023-03-09': 1,\n",
      "                                  '734_2023-12-08': 2,\n",
      "                                  '734_2024-03-28': 3,\n",
      "                                  '735_2022-02-10': 0,\n",
      "                                  '735_2022-07-25': 0,\n",
      "                                  '735_2022-11-22': 0,\n",
      "                                  '735_2023-02-20': 0,\n",
      "                                  '735_2023-05-23': 0,\n",
      "                                  '735_2024-01-23': 2,\n",
      "                                  '736_2022-06-03': 0,\n",
      "                                  '737_2022-08-23': 3,\n",
      "                                  '737_2023-06-12': 2,\n",
      "                                  '738_2022-01-27': 8,\n",
      "                                  '738_2022-08-09': 3,\n",
      "                                  '73_2021-04-29': 0,\n",
      "                                  '73_2022-03-30': 0,\n",
      "                                  '73_2022-08-08': 1,\n",
      "                                  '73_2022-11-09': 1,\n",
      "                                  '73_2023-03-03': 1,\n",
      "                                  '73_2023-07-27': 2,\n",
      "                                  '73_2023-10-23': 0,\n",
      "                                  '73_2024-01-19': 2,\n",
      "                                  '73_2024-09-30': 1,\n",
      "                                  '740_2022-03-29': 2,\n",
      "                                  '740_2022-06-10': 3,\n",
      "                                  '740_2022-11-10': 1,\n",
      "                                  '741_2022-03-23': 3,\n",
      "                                  '741_2022-08-11': 3,\n",
      "                                  '741_2022-12-15': 0,\n",
      "                                  '741_2023-12-22': 3,\n",
      "                                  '741_2024-03-29': 2,\n",
      "                                  '742_2022-03-24': 1,\n",
      "                                  '742_2022-08-30': 2,\n",
      "                                  '742_2023-05-03': 3,\n",
      "                                  '742_2023-10-12': 3,\n",
      "                                  '742_2024-02-28': 3,\n",
      "                                  '742_2024-08-05': 1,\n",
      "                                  '744_2022-04-28': 0,\n",
      "                                  '744_2022-08-22': 0,\n",
      "                                  '744_2023-04-13': 0,\n",
      "                                  '744_2023-06-12': 3,\n",
      "                                  '744_2023-12-19': 3,\n",
      "                                  '744_2024-03-28': 3,\n",
      "                                  '744_2024-08-29': 3,\n",
      "                                  '745_2022-07-07': 9,\n",
      "                                  '745_2023-01-30': 9,\n",
      "                                  '745_2023-06-09': 3,\n",
      "                                  '745_2023-12-27': 6,\n",
      "                                  '745_2024-03-19': 8,\n",
      "                                  '746_2022-08-31': 3,\n",
      "                                  '746_2023-04-21': 2,\n",
      "                                  '746_2023-08-14': 7,\n",
      "                                  '746_2023-09-18': 3,\n",
      "                                  '746_2024-01-26': 5,\n",
      "                                  '746_2024-07-22': 3,\n",
      "                                  '747_2022-08-01': 2,\n",
      "                                  '747_2023-07-27': 0,\n",
      "                                  '747_2023-12-05': 0,\n",
      "                                  '747_2024-03-12': 0,\n",
      "                                  '748_2023-04-11': 1,\n",
      "                                  '748_2023-08-29': 3,\n",
      "                                  '748_2023-12-19': 2,\n",
      "                                  '748_2024-03-28': 1,\n",
      "                                  '748_2024-08-12': 3,\n",
      "                                  '749_2022-08-24': 2,\n",
      "                                  '749_2022-12-20': 1,\n",
      "                                  '749_2023-07-17': 1,\n",
      "                                  '749_2023-12-12': 1,\n",
      "                                  '749_2024-03-05': 3,\n",
      "                                  '749_2024-06-04': 2,\n",
      "                                  '750_2022-07-15': 4,\n",
      "                                  '750_2022-11-15': 3,\n",
      "                                  '751_2022-07-25': 3,\n",
      "                                  '751_2023-04-24': 3,\n",
      "                                  '751_2023-08-11': 3,\n",
      "                                  '751_2023-11-30': 5,\n",
      "                                  '751_2024-03-20': 1,\n",
      "                                  '751_2024-07-23': 3,\n",
      "                                  '752_2022-07-19': 2,\n",
      "                                  '753_2022-08-18': 3,\n",
      "                                  '753_2023-04-20': 3,\n",
      "                                  '754_2022-08-23': 2,\n",
      "                                  '754_2022-12-20': 3,\n",
      "                                  '754_2023-08-04': 1,\n",
      "                                  '754_2023-12-19': 1,\n",
      "                                  '754_2024-03-18': 1,\n",
      "                                  '754_2024-08-07': 2,\n",
      "                                  '755_2022-07-26': 0,\n",
      "                                  '759_2023-01-18': 3,\n",
      "                                  '759_2024-04-18': 3,\n",
      "                                  '759_2024-07-08': 3,\n",
      "                                  '760_2022-12-13': 1,\n",
      "                                  '760_2023-04-20': 1,\n",
      "                                  '760_2023-07-03': 0,\n",
      "                                  '763_2022-08-29': 2,\n",
      "                                  '763_2022-12-08': 1,\n",
      "                                  '763_2023-04-19': 2,\n",
      "                                  '763_2023-07-31': 0,\n",
      "                                  '763_2024-03-12': 2,\n",
      "                                  '763_2024-07-11': 1,\n",
      "                                  '764_2022-08-24': 2,\n",
      "                                  '764_2022-12-14': 1,\n",
      "                                  '764_2023-02-27': 2,\n",
      "                                  '764_2023-07-18': 2,\n",
      "                                  '764_2023-10-23': 1,\n",
      "                                  '764_2024-03-20': 1,\n",
      "                                  '765_2022-08-31': 0,\n",
      "                                  '765_2022-12-07': 0,\n",
      "                                  '765_2023-08-02': 0,\n",
      "                                  '765_2023-11-08': 2,\n",
      "                                  '765_2024-02-08': 0,\n",
      "                                  '766_2022-09-28': 2,\n",
      "                                  '766_2023-04-24': 2,\n",
      "                                  '766_2023-07-19': 3,\n",
      "                                  '766_2023-10-06': 1,\n",
      "                                  '766_2024-06-06': 5,\n",
      "                                  '766_2024-09-27': 3,\n",
      "                                  '767_2022-12-16': 4,\n",
      "                                  '767_2023-06-15': 3,\n",
      "                                  '767_2024-03-19': 3,\n",
      "                                  '768_2022-11-02': 0,\n",
      "                                  '768_2023-04-13': 1,\n",
      "                                  '768_2023-07-19': 2,\n",
      "                                  '768_2024-04-10': 3,\n",
      "                                  '768_2024-07-29': 2,\n",
      "                                  '769_2023-04-25': 5,\n",
      "                                  '769_2023-08-07': 7,\n",
      "                                  '769_2023-11-13': 3,\n",
      "                                  '769_2024-02-06': 3,\n",
      "                                  '769_2024-06-06': 2,\n",
      "                                  '771_2022-12-12': 3,\n",
      "                                  '771_2023-04-28': 3,\n",
      "                                  '771_2024-01-10': 3,\n",
      "                                  '771_2024-07-17': 4,\n",
      "                                  '774_2022-12-08': 0,\n",
      "                                  '774_2023-03-09': 1,\n",
      "                                  '774_2023-07-25': 2,\n",
      "                                  '774_2023-11-28': 0,\n",
      "                                  '774_2024-03-22': 0,\n",
      "                                  '775_2023-04-19': 3,\n",
      "                                  '775_2023-12-22': 0,\n",
      "                                  '776_2023-02-03': 2,\n",
      "                                  '776_2023-08-17': 3,\n",
      "                                  '776_2023-12-08': 2,\n",
      "                                  '777_2022-12-09': 3,\n",
      "                                  '777_2023-04-12': 3,\n",
      "                                  '777_2023-07-31': 4,\n",
      "                                  '777_2023-11-13': 6,\n",
      "                                  '777_2024-03-13': 7,\n",
      "                                  '777_2024-07-24': 3,\n",
      "                                  '778_2023-02-10': 0,\n",
      "                                  '778_2024-03-13': 3,\n",
      "                                  '778_2024-08-01': 0,\n",
      "                                  '779_2023-04-25': 3,\n",
      "                                  '781_2023-12-18': 3,\n",
      "                                  '781_2024-04-01': 3,\n",
      "                                  '783_2023-02-16': 10,\n",
      "                                  '783_2023-08-02': 3,\n",
      "                                  '783_2024-08-26': 2,\n",
      "                                  '784_2023-02-24': 1,\n",
      "                                  '784_2023-07-19': 7,\n",
      "                                  '784_2024-03-12': 5,\n",
      "                                  '786_2023-04-26': 2,\n",
      "                                  '786_2023-10-20': 3,\n",
      "                                  '787_2023-03-13': 1,\n",
      "                                  '787_2023-09-14': 3,\n",
      "                                  '788_2023-04-21': 4,\n",
      "                                  '788_2023-11-20': 8,\n",
      "                                  '788_2024-02-12': 4,\n",
      "                                  '788_2024-08-01': 5,\n",
      "                                  '789_2023-04-19': 2,\n",
      "                                  '789_2024-03-27': 3,\n",
      "                                  '790_2023-06-07': 7,\n",
      "                                  '790_2024-01-31': 7,\n",
      "                                  '793_2023-07-17': 3,\n",
      "                                  '795_2023-04-19': 1,\n",
      "                                  '795_2023-09-11': 2,\n",
      "                                  '795_2024-03-06': 0,\n",
      "                                  '795_2024-08-20': 0,\n",
      "                                  '797_2023-12-08': 1,\n",
      "                                  '799_2024-03-15': 5,\n",
      "                                  '79_2021-04-12': 5,\n",
      "                                  '79_2021-11-02': 2,\n",
      "                                  '79_2022-02-01': 3,\n",
      "                                  '79_2022-05-11': 2,\n",
      "                                  '79_2022-09-26': 3,\n",
      "                                  '79_2023-02-17': 3,\n",
      "                                  '79_2023-08-02': 3,\n",
      "                                  '79_2023-11-16': 3,\n",
      "                                  '79_2024-02-14': 3,\n",
      "                                  '800_2023-04-19': 1,\n",
      "                                  '800_2023-12-15': 6,\n",
      "                                  '800_2024-03-29': 2,\n",
      "                                  '804_2023-11-10': 3,\n",
      "                                  '804_2024-04-01': 3,\n",
      "                                  '805_2023-05-22': 2,\n",
      "                                  '805_2023-09-11': 1,\n",
      "                                  '805_2024-02-08': 3,\n",
      "                                  '806_2023-06-27': 3,\n",
      "                                  '806_2023-12-27': 1,\n",
      "                                  '808_2023-09-12': 4,\n",
      "                                  '809_2023-07-11': 2,\n",
      "                                  '810_2023-07-31': 7,\n",
      "                                  '810_2023-12-27': 5,\n",
      "                                  '810_2024-03-19': 5,\n",
      "                                  '813_2024-03-15': 3,\n",
      "                                  '814_2023-09-19': 8,\n",
      "                                  '815_2023-07-17': 0,\n",
      "                                  '816_2023-08-30': 2,\n",
      "                                  '816_2023-12-19': 3,\n",
      "                                  '816_2024-04-02': 3,\n",
      "                                  '816_2024-08-08': 2,\n",
      "                                  '818_2023-08-29': 5,\n",
      "                                  '818_2023-12-12': 3,\n",
      "                                  '818_2024-03-27': 7,\n",
      "                                  '818_2024-07-26': 3,\n",
      "                                  '819_2023-07-17': 1,\n",
      "                                  '819_2024-04-09': 3,\n",
      "                                  '820_2024-03-29': 0,\n",
      "                                  '822_2024-04-01': 3,\n",
      "                                  '823_2023-10-20': 4,\n",
      "                                  '823_2024-03-21': 5,\n",
      "                                  '824_2024-04-02': 2,\n",
      "                                  '825_2024-03-28': 5,\n",
      "                                  '828_2023-09-18': 3,\n",
      "                                  '828_2024-04-09': 4,\n",
      "                                  '829_2023-11-17': 3,\n",
      "                                  '835_2023-11-17': 1,\n",
      "                                  '835_2024-02-16': 1,\n",
      "                                  '836_2023-10-20': 2,\n",
      "                                  '836_2024-03-29': 5,\n",
      "                                  '837_2024-03-15': 3,\n",
      "                                  '839_2023-12-20': 3,\n",
      "                                  '839_2024-03-29': 3,\n",
      "                                  '83_2021-05-24': 2,\n",
      "                                  '83_2021-12-15': 0,\n",
      "                                  '83_2022-04-04': 0,\n",
      "                                  '83_2022-05-23': 1,\n",
      "                                  '83_2022-09-19': 0,\n",
      "                                  '83_2023-01-17': 1,\n",
      "                                  '83_2023-07-19': 0,\n",
      "                                  '840_2023-11-17': 3,\n",
      "                                  '840_2024-03-27': 3,\n",
      "                                  '842_2024-02-21': 3,\n",
      "                                  '843_2023-12-18': 4,\n",
      "                                  '843_2024-04-10': 7,\n",
      "                                  '844_2024-03-21': 3,\n",
      "                                  '844_2024-08-30': 3,\n",
      "                                  '845_2023-12-19': 4,\n",
      "                                  '845_2024-03-15': 2,\n",
      "                                  '846_2024-03-13': 2,\n",
      "                                  '847_2024-07-26': 5,\n",
      "                                  '848_2024-03-27': 8,\n",
      "                                  '849_2024-03-27': 4,\n",
      "                                  '851_2024-07-26': 4,\n",
      "                                  '852_2024-03-13': 2,\n",
      "                                  '854_2024-04-18': 3,\n",
      "                                  '854_2024-08-06': 2,\n",
      "                                  '858_2024-04-17': 1,\n",
      "                                  '858_2024-07-08': 3,\n",
      "                                  '861_2024-07-05': 5,\n",
      "                                  '862_2024-04-05': 7,\n",
      "                                  '863_2024-06-07': 2,\n",
      "                                  '865_2024-04-12': 2,\n",
      "                                  '86_2021-05-24': 0,\n",
      "                                  '86_2021-11-23': 0,\n",
      "                                  '86_2022-02-10': 0,\n",
      "                                  '86_2022-05-25': 1,\n",
      "                                  '86_2022-09-20': 0,\n",
      "                                  '86_2023-01-12': 1,\n",
      "                                  '86_2023-06-08': 0,\n",
      "                                  '86_2023-11-13': 0,\n",
      "                                  '86_2024-02-05': 3,\n",
      "                                  '86_2024-08-12': 2,\n",
      "                                  '86_2024-09-18': 0,\n",
      "                                  '938652_2024-10-25': 3,\n",
      "                                  '938667_2024-11-19': 0,\n",
      "                                  '938672_2024-10-28': 3,\n",
      "                                  '938695_2024-10-28': 3,\n",
      "                                  '938698_2024-10-30': 2,\n",
      "                                  '938699_2024-10-28': 1,\n",
      "                                  '938700_2024-10-18': 4,\n",
      "                                  '938702_2024-11-22': 1,\n",
      "                                  '938703_2024-10-28': 0,\n",
      "                                  '938710_2024-11-19': 5,\n",
      "                                  '938743_2024-11-19': 5,\n",
      "                                  '938766_2024-10-25': 2,\n",
      "                                  '938797_2024-11-19': 0,\n",
      "                                  '938814_2024-11-19': 3,\n",
      "                                  '938894_2024-11-01': 3,\n",
      "                                  '938938_2024-11-20': 0,\n",
      "                                  '939783_2024-11-19': 1,\n",
      "                                  '941934_2024-11-07': 1,\n",
      "                                  '952421_2024-11-19': 5,\n",
      "                                  '981476_2024-11-01': 2,\n",
      "                                  '983777_2024-11-22': 2,\n",
      "                                  '997606_2024-10-25': 9},\n",
      "                        '{modelFS_desc}': 'None',\n",
      "                        '{model_desc}': 'ExtraTreesRegressor(n_estimators=1200, '\n",
      "                                        'n_jobs=12, random_state=42)'}}},\n",
      " 'controls': {}}\n",
      "-------\n",
      "Settings:\n",
      "\n",
      "Database - Audio_features\n",
      "Corpus - merged_data\n",
      "Group ID - message_id\n",
      "Feature table(s) - feat$librosa_n$merged_data$message_id\n",
      "Outcome table - merged_data\n",
      "Outcome(s) - CEL_Total\n",
      "-------\n",
      "Interface Runtime: 12.94 seconds\n",
      "DLATK exits with success! A good day indeed  ¯\\_(ツ)_/¯.\n"
     ]
    }
   ],
   "source": [
    "!python /home/karthik9/TheDlatk/dlatk/dlatkInterface.py -d Audio_features -t merged_data -c message_id \\\n",
    "-f 'feat$librosa_n$merged_data$message_id' \\\n",
    "    --outcome_table merged_data  --group_freq_thresh 1 \\\n",
    "    --outcomes CEL_Total  \\\n",
    "    --model extratrees --fold_column fold --nfold_test_regression \\\n",
    "    --output ~/probability.values --probability_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Warning: Cannot import langid (cannot use addLanguageFilterTable)\n",
      "TopicExtractor: gensim Mallet wrapper unavailable, using Mallet directly.\n",
      "\n",
      "-----\n",
      "DLATK Interface Initiated: 2025-03-18 13:17:06\n",
      "-----\n",
      "Loading Outcomes and Getting Groups for: {'CEL_Total'}\n",
      "    ***explicit fold labels specified, not splitting again***\n",
      "[number of groups: 1468 (5 Folds)]\n",
      "\n",
      "\n",
      "|COMBO: ()|\n",
      "===========\n",
      "\n",
      "= CEL_Total (w/ lang.)=\n",
      "-----------------------\n",
      "Fold 0 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1175    Test size: 293]\n",
      " X[0]: (N, features): (1175, 88)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1175, 88)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (293, 88)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 88), ('_n_samples', 1175), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: -0.0283 (MSE: 2.9409; MAE: 1.3586; mean train mae: 1.3558)\n",
      "Fold 1 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1175    Test size: 293]\n",
      " X[0]: (N, features): (1175, 88)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1175, 88)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (293, 88)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 88), ('_n_samples', 1175), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: 0.0719 (MSE: 4.2984; MAE: 1.6053; mean train mae: 1.6470)\n",
      "Fold 2 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1174    Test size: 294]\n",
      " X[0]: (N, features): (1174, 88)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1174, 88)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (294, 88)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 88), ('_n_samples', 1174), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: -0.0886 (MSE: 4.7526; MAE: 1.5927; mean train mae: 1.5240)\n",
      "Fold 3 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1174    Test size: 294]\n",
      " X[0]: (N, features): (1174, 88)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1174, 88)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (294, 88)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 88), ('_n_samples', 1174), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: -0.0043 (MSE: 4.9442; MAE: 1.7392; mean train mae: 1.7162)\n",
      "Fold 4 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1174    Test size: 294]\n",
      " X[0]: (N, features): (1174, 88)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1174, 88)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (294, 88)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 88), ('_n_samples', 1174), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: -0.0069 (MSE: 3.1957; MAE: 1.3557; mean train mae: 1.3278)\n",
      "*Overall R^2:          0.0006\n",
      "*Overall FOLDS R^2:    -0.0113 (+- 0.0230)\n",
      "*R (sqrt R^2):         0.0246\n",
      "*Pearson r:            0.1796 (p = 0.00000)\n",
      "*Folds Pearson r:      0.1842 (p = 0.12725)\n",
      "*Spearman rho:         0.1951 (p = 0.00000)\n",
      "*Mean Squared Error:   4.0269\n",
      "*Mean Absolute Error:  1.5304\n",
      "*Train_Mean MAE:       0.5441\n",
      "\n",
      "[TEST COMPLETE]\n",
      "\n",
      "{'CEL_Total': {(): {1: {'N': 1468,\n",
      "                        'R': np.float64(0.02456634489223223),\n",
      "                        'R2': 0.0006035053013641045,\n",
      "                        'R2_folds': np.float64(-0.011253257268785543),\n",
      "                        'mae': 1.5303712534059946,\n",
      "                        'mae_folds': np.float64(1.5303053756201002),\n",
      "                        'mse': 4.026896954473206,\n",
      "                        'mse_folds': np.float64(4.0263428708508435),\n",
      "                        'num_features': 88,\n",
      "                        'r': np.float64(0.17963275169875947),\n",
      "                        'r_folds': np.float64(0.18417030821187044),\n",
      "                        'r_p': np.float64(4.115929919164683e-12),\n",
      "                        'r_p_folds': np.float64(0.12724842744922432),\n",
      "                        'rho': np.float64(0.1950667981056881),\n",
      "                        'rho_folds': np.float64(0.19380102494148593),\n",
      "                        'rho_p': np.float64(4.6974932754641517e-14),\n",
      "                        'rho_p_folds': np.float64(0.14756176970497054),\n",
      "                        'se_R2_folds': np.float64(0.02302243380866783),\n",
      "                        'se_mae_folds': np.float64(0.0672860682170227),\n",
      "                        'se_mse_folds': np.float64(0.36398603425980075),\n",
      "                        'se_r_folds': np.float64(0.03756096819664266),\n",
      "                        'se_r_p_folds': np.float64(0.11334150003140431),\n",
      "                        'se_rho_folds': np.float64(0.04247000627739799),\n",
      "                        'se_rho_p_folds': np.float64(0.13179638008238692),\n",
      "                        'se_train_mean_mae_folds': np.float64(0.06881004248493683),\n",
      "                        'test_size': 294,\n",
      "                        'train_mean_mae': 0.5440530902053372,\n",
      "                        'train_mean_mae_folds': np.float64(1.5141649201924878),\n",
      "                        'train_size': 1174,\n",
      "                        '{modelFS_desc}': 'None',\n",
      "                        '{model_desc}': 'ExtraTreesRegressor(n_estimators=1200, '\n",
      "                                        'n_jobs=12, random_state=42)'}}}}\n",
      "-------\n",
      "Settings:\n",
      "\n",
      "Database - Audio_features\n",
      "Corpus - merged_data\n",
      "Group ID - message_id\n",
      "Feature table(s) - feat$opensmile_n$merged_data$message_id\n",
      "Outcome table - merged_data\n",
      "Outcome(s) - CEL_Total\n",
      "-------\n",
      "Interface Runtime: 22.62 seconds\n",
      "DLATK exits with success! A good day indeed  ¯\\_(ツ)_/¯.\n"
     ]
    }
   ],
   "source": [
    "!python /home/karthik9/TheDlatk/dlatk/dlatkInterface.py -d Audio_features -t merged_data -c message_id \\\n",
    "-f 'feat$opensmile_n$merged_data$message_id' \\\n",
    "    --outcome_table merged_data  --group_freq_thresh 10 \\\n",
    "    --outcomes CEL_Total  \\\n",
    "    --nfold_test_regression --model extratrees --fold_column fold \n",
    "    #--prediction_csv --output_name ./Klatch_opensmile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Warning: Cannot import langid (cannot use addLanguageFilterTable)\n",
      "TopicExtractor: gensim Mallet wrapper unavailable, using Mallet directly.\n",
      "\n",
      "-----\n",
      "DLATK Interface Initiated: 2025-03-18 13:17:36\n",
      "-----\n",
      "Loading Outcomes and Getting Groups for: {'CEL_Total'}\n",
      "    ***explicit fold labels specified, not splitting again***\n",
      "[number of groups: 1468 (5 Folds)]\n",
      "\n",
      "\n",
      "|COMBO: ()|\n",
      "===========\n",
      "\n",
      "= CEL_Total (w/ lang.)=\n",
      "-----------------------\n",
      "Fold 0 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1175    Test size: 293]\n",
      " X[0]: (N, features): (1175, 512)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1175, 512)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (293, 512)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 512), ('_n_samples', 1175), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: -0.0325 (MSE: 2.9528; MAE: 1.3947; mean train mae: 1.3558)\n",
      "Fold 1 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1175    Test size: 293]\n",
      " X[0]: (N, features): (1175, 512)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1175, 512)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (293, 512)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 512), ('_n_samples', 1175), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: -0.0258 (MSE: 4.7508; MAE: 1.6581; mean train mae: 1.6470)\n",
      "Fold 2 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1174    Test size: 294]\n",
      " X[0]: (N, features): (1174, 512)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1174, 512)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (294, 512)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 512), ('_n_samples', 1174), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: -0.0160 (MSE: 4.4356; MAE: 1.4962; mean train mae: 1.5240)\n",
      "Fold 3 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1174    Test size: 294]\n",
      " X[0]: (N, features): (1174, 512)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1174, 512)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (294, 512)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 512), ('_n_samples', 1174), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: -0.0057 (MSE: 4.9513; MAE: 1.7048; mean train mae: 1.7162)\n",
      "Fold 4 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1174    Test size: 294]\n",
      " X[0]: (N, features): (1174, 512)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1174, 512)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (294, 512)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 512), ('_n_samples', 1174), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: -0.0009 (MSE: 3.1766; MAE: 1.3229; mean train mae: 1.3278)\n",
      "/home/karthik9/TheDlatk/dlatk/dlatk/regressionPredictor.py:1398: RuntimeWarning: invalid value encountered in sqrt\n",
      "  reportStats['R'] = sqrt(reportStats['R2'])\n",
      "*Overall R^2:          -0.0060\n",
      "*Overall FOLDS R^2:    -0.0162 (+- 0.0053)\n",
      "*R (sqrt R^2):         nan\n",
      "*Pearson r:            0.1144 (p = 0.00001)\n",
      "*Folds Pearson r:      0.1270 (p = 0.05064)\n",
      "*Spearman rho:         0.1223 (p = 0.00000)\n",
      "*Mean Squared Error:   4.0537\n",
      "*Mean Absolute Error:  1.5153\n",
      "*Train_Mean MAE:       0.3562\n",
      "\n",
      "[TEST COMPLETE]\n",
      "\n",
      "{'CEL_Total': {(): {1: {'N': 1468,\n",
      "                        'R': np.float64(nan),\n",
      "                        'R2': -0.006046207431058548,\n",
      "                        'R2_folds': np.float64(-0.016188252900958888),\n",
      "                        'mae': 1.5153241371480473,\n",
      "                        'mae_folds': np.float64(1.5153391976813477),\n",
      "                        'mse': 4.053690832671057,\n",
      "                        'mse_folds': np.float64(4.053416152333421),\n",
      "                        'num_features': 512,\n",
      "                        'r': np.float64(0.11441971602935802),\n",
      "                        'r_folds': np.float64(0.12702754697073917),\n",
      "                        'r_p': np.float64(1.1095743950051768e-05),\n",
      "                        'r_p_folds': np.float64(0.05063814137780002),\n",
      "                        'rho': np.float64(0.12226088969538919),\n",
      "                        'rho_folds': np.float64(0.1361865263326875),\n",
      "                        'rho_p': np.float64(2.627119084482254e-06),\n",
      "                        'rho_p_folds': np.float64(0.03486915315314662),\n",
      "                        'se_R2_folds': np.float64(0.0052969972429093605),\n",
      "                        'se_mae_folds': np.float64(0.06580344998251662),\n",
      "                        'se_mse_folds': np.float64(0.36980505190991375),\n",
      "                        'se_r_folds': np.float64(0.012010698965687646),\n",
      "                        'se_r_p_folds': np.float64(0.02635829344731747),\n",
      "                        'se_rho_folds': np.float64(0.012377558826241445),\n",
      "                        'se_rho_p_folds': np.float64(0.01665543197300154),\n",
      "                        'se_train_mean_mae_folds': np.float64(0.06881004248493686),\n",
      "                        'test_size': 294,\n",
      "                        'train_mean_mae': 0.35621192927163076,\n",
      "                        'train_mean_mae_folds': np.float64(1.5141649201924878),\n",
      "                        'train_size': 1174,\n",
      "                        '{modelFS_desc}': 'None',\n",
      "                        '{model_desc}': 'ExtraTreesRegressor(n_estimators=1200, '\n",
      "                                        'n_jobs=12, random_state=42)'}}}}\n",
      "-------\n",
      "Settings:\n",
      "\n",
      "Database - Audio_features\n",
      "Corpus - merged_data\n",
      "Group ID - message_id\n",
      "Feature table(s) - feat$whisper_mean_n$merged_data$message_id\n",
      "Outcome table - merged_data\n",
      "Outcome(s) - CEL_Total\n",
      "-------\n",
      "Interface Runtime: 91.89 seconds\n",
      "DLATK exits with success! A good day indeed  ¯\\_(ツ)_/¯.\n"
     ]
    }
   ],
   "source": [
    "!python /home/karthik9/TheDlatk/dlatk/dlatkInterface.py -d Audio_features -t merged_data -c message_id \\\n",
    "-f 'feat$whisper_mean_n$merged_data$message_id' \\\n",
    "    --outcome_table merged_data  --group_freq_thresh 10 \\\n",
    "    --outcomes CEL_Total \\\n",
    "    --nfold_test_regression --model extratrees --fold_column fold \n",
    "    #--prediction_csv --output_name ./Klatch_whisper_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Warning: Cannot import langid (cannot use addLanguageFilterTable)\n",
      "TopicExtractor: gensim Mallet wrapper unavailable, using Mallet directly.\n",
      "\n",
      "-----\n",
      "DLATK Interface Initiated: 2025-03-18 13:19:18\n",
      "-----\n",
      "Loading Outcomes and Getting Groups for: {'CEL_Total'}\n",
      "    ***explicit fold labels specified, not splitting again***\n",
      "[number of groups: 1468 (5 Folds)]\n",
      "\n",
      "\n",
      "|COMBO: ()|\n",
      "===========\n",
      "\n",
      "= CEL_Total (w/ lang.)=\n",
      "-----------------------\n",
      "Fold 0 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1175    Test size: 293]\n",
      " X[0]: (N, features): (1175, 512)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1175, 512)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (293, 512)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 512), ('_n_samples', 1175), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: -0.0481 (MSE: 2.9976; MAE: 1.4014; mean train mae: 1.3558)\n",
      "Fold 1 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1175    Test size: 293]\n",
      " X[0]: (N, features): (1175, 512)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1175, 512)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (293, 512)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 512), ('_n_samples', 1175), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: -0.0574 (MSE: 4.8969; MAE: 1.6824; mean train mae: 1.6470)\n",
      "Fold 2 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1174    Test size: 294]\n",
      " X[0]: (N, features): (1174, 512)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1174, 512)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (294, 512)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 512), ('_n_samples', 1174), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: -0.0184 (MSE: 4.4461; MAE: 1.4984; mean train mae: 1.5240)\n",
      "Fold 3 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1174    Test size: 294]\n",
      " X[0]: (N, features): (1174, 512)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1174, 512)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (294, 512)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 512), ('_n_samples', 1174), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: -0.0084 (MSE: 4.9642; MAE: 1.6998; mean train mae: 1.7162)\n",
      "Fold 4 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1174    Test size: 294]\n",
      " X[0]: (N, features): (1174, 512)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1174, 512)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (294, 512)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 512), ('_n_samples', 1174), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: -0.0197 (MSE: 3.2362; MAE: 1.3445; mean train mae: 1.3278)\n",
      "/home/karthik9/TheDlatk/dlatk/dlatk/regressionPredictor.py:1398: RuntimeWarning: invalid value encountered in sqrt\n",
      "  reportStats['R'] = sqrt(reportStats['R2'])\n",
      "*Overall R^2:          -0.0196\n",
      "*Overall FOLDS R^2:    -0.0304 (+- 0.0085)\n",
      "*R (sqrt R^2):         nan\n",
      "*Pearson r:            0.0924 (p = 0.00039)\n",
      "*Folds Pearson r:      0.1077 (p = 0.12761)\n",
      "*Spearman rho:         0.1161 (p = 0.00001)\n",
      "*Mean Squared Error:   4.1084\n",
      "*Mean Absolute Error:  1.5253\n",
      "*Train_Mean MAE:       0.3608\n",
      "\n",
      "[TEST COMPLETE]\n",
      "\n",
      "{'CEL_Total': {(): {1: {'N': 1468,\n",
      "                        'R': np.float64(nan),\n",
      "                        'R2': -0.019624327731264435,\n",
      "                        'R2_folds': np.float64(-0.030388869800284636),\n",
      "                        'mae': 1.5252792915531337,\n",
      "                        'mae_folds': np.float64(1.5253019181506504),\n",
      "                        'mse': 4.108401542158644,\n",
      "                        'mse_folds': np.float64(4.108182270332384),\n",
      "                        'num_features': 512,\n",
      "                        'r': np.float64(0.09241620705979527),\n",
      "                        'r_folds': np.float64(0.1077388063236907),\n",
      "                        'r_p': np.float64(0.00039193884814357733),\n",
      "                        'r_p_folds': np.float64(0.1276086921001982),\n",
      "                        'rho': np.float64(0.1160556141281192),\n",
      "                        'rho_folds': np.float64(0.12936693618448442),\n",
      "                        'rho_p': np.float64(8.276854974588243e-06),\n",
      "                        'rho_p_folds': np.float64(0.051120470544618345),\n",
      "                        'se_R2_folds': np.float64(0.008454521443605279),\n",
      "                        'se_mae_folds': np.float64(0.06446478928335511),\n",
      "                        'se_mse_folds': np.float64(0.3721705930782002),\n",
      "                        'se_r_folds': np.float64(0.016383339311221396),\n",
      "                        'se_r_p_folds': np.float64(0.07807267423766541),\n",
      "                        'se_rho_folds': np.float64(0.01409620348624575),\n",
      "                        'se_rho_p_folds': np.float64(0.022695935457113053),\n",
      "                        'se_train_mean_mae_folds': np.float64(0.06881004248493688),\n",
      "                        'test_size': 294,\n",
      "                        'train_mean_mae': 0.36078020167447483,\n",
      "                        'train_mean_mae_folds': np.float64(1.5141649201924878),\n",
      "                        'train_size': 1174,\n",
      "                        '{modelFS_desc}': 'None',\n",
      "                        '{model_desc}': 'ExtraTreesRegressor(n_estimators=1200, '\n",
      "                                        'n_jobs=12, random_state=42)'}}}}\n",
      "-------\n",
      "Settings:\n",
      "\n",
      "Database - Audio_features\n",
      "Corpus - merged_data\n",
      "Group ID - message_id\n",
      "Feature table(s) - feat$whisper_median_n$merged_data$message_id\n",
      "Outcome table - merged_data\n",
      "Outcome(s) - CEL_Total\n",
      "-------\n",
      "Interface Runtime: 93.86 seconds\n",
      "DLATK exits with success! A good day indeed  ¯\\_(ツ)_/¯.\n"
     ]
    }
   ],
   "source": [
    "!python /home/karthik9/TheDlatk/dlatk/dlatkInterface.py -d Audio_features -t merged_data -c message_id \\\n",
    "-f 'feat$whisper_median_n$merged_data$message_id' \\\n",
    "    --outcome_table merged_data  --group_freq_thresh 10 \\\n",
    "    --outcomes CEL_Total \\\n",
    "    --nfold_test_regression --model extratrees --fold_column fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Warning: Cannot import langid (cannot use addLanguageFilterTable)\n",
      "TopicExtractor: gensim Mallet wrapper unavailable, using Mallet directly.\n",
      "\n",
      "-----\n",
      "DLATK Interface Initiated: 2025-03-18 13:20:58\n",
      "-----\n",
      "Loading Outcomes and Getting Groups for: {'CEL_Total'}\n",
      "    ***explicit fold labels specified, not splitting again***\n",
      "[number of groups: 1468 (5 Folds)]\n",
      "\n",
      "\n",
      "|COMBO: ()|\n",
      "===========\n",
      "\n",
      "= CEL_Total (w/ lang.)=\n",
      "-----------------------\n",
      "Fold 0 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      "   (feature group: 1): [Initial size: 1468]\n",
      "   (feature group: 2): [Initial size: 1468]\n",
      " [Train size: 1175    Test size: 293]\n",
      " X[0]: (N, features): (1175, 38)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      " X[1]: (N, features): (1175, 88)\n",
      "  [Applying StandardScaler to X[1]: StandardScaler()]\n",
      " X[2]: (N, features): (1175, 512)\n",
      "  [Applying StandardScaler to X[2]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1175, 638)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] applying *existing* standard scaler to X[1]: StandardScaler()\n",
      "[PREDICT] applying *existing* standard scaler to X[2]: StandardScaler()\n",
      "[PREDICT] combined X shape: (293, 638)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 638), ('_n_samples', 1175), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: 0.0152 (MSE: 2.8164; MAE: 1.3378; mean train mae: 1.3558)\n",
      "Fold 1 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      "   (feature group: 1): [Initial size: 1468]\n",
      "   (feature group: 2): [Initial size: 1468]\n",
      " [Train size: 1175    Test size: 293]\n",
      " X[0]: (N, features): (1175, 38)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      " X[1]: (N, features): (1175, 88)\n",
      "  [Applying StandardScaler to X[1]: StandardScaler()]\n",
      " X[2]: (N, features): (1175, 512)\n",
      "  [Applying StandardScaler to X[2]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1175, 638)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] applying *existing* standard scaler to X[1]: StandardScaler()\n",
      "[PREDICT] applying *existing* standard scaler to X[2]: StandardScaler()\n",
      "[PREDICT] combined X shape: (293, 638)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 638), ('_n_samples', 1175), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: 0.0689 (MSE: 4.3119; MAE: 1.5896; mean train mae: 1.6470)\n",
      "Fold 2 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      "   (feature group: 1): [Initial size: 1468]\n",
      "   (feature group: 2): [Initial size: 1468]\n",
      " [Train size: 1174    Test size: 294]\n",
      " X[0]: (N, features): (1174, 38)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      " X[1]: (N, features): (1174, 88)\n",
      "  [Applying StandardScaler to X[1]: StandardScaler()]\n",
      " X[2]: (N, features): (1174, 512)\n",
      "  [Applying StandardScaler to X[2]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1174, 638)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] applying *existing* standard scaler to X[1]: StandardScaler()\n",
      "[PREDICT] applying *existing* standard scaler to X[2]: StandardScaler()\n",
      "[PREDICT] combined X shape: (294, 638)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 638), ('_n_samples', 1174), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: -0.0437 (MSE: 4.5563; MAE: 1.5116; mean train mae: 1.5240)\n",
      "Fold 3 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      "   (feature group: 1): [Initial size: 1468]\n",
      "   (feature group: 2): [Initial size: 1468]\n",
      " [Train size: 1174    Test size: 294]\n",
      " X[0]: (N, features): (1174, 38)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      " X[1]: (N, features): (1174, 88)\n",
      "  [Applying StandardScaler to X[1]: StandardScaler()]\n",
      " X[2]: (N, features): (1174, 512)\n",
      "  [Applying StandardScaler to X[2]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1174, 638)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] applying *existing* standard scaler to X[1]: StandardScaler()\n",
      "[PREDICT] applying *existing* standard scaler to X[2]: StandardScaler()\n",
      "[PREDICT] combined X shape: (294, 638)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 638), ('_n_samples', 1174), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: 0.0498 (MSE: 4.6778; MAE: 1.6330; mean train mae: 1.7162)\n",
      "Fold 4 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      "   (feature group: 1): [Initial size: 1468]\n",
      "   (feature group: 2): [Initial size: 1468]\n",
      " [Train size: 1174    Test size: 294]\n",
      " X[0]: (N, features): (1174, 38)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      " X[1]: (N, features): (1174, 88)\n",
      "  [Applying StandardScaler to X[1]: StandardScaler()]\n",
      " X[2]: (N, features): (1174, 512)\n",
      "  [Applying StandardScaler to X[2]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1174, 638)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] applying *existing* standard scaler to X[1]: StandardScaler()\n",
      "[PREDICT] applying *existing* standard scaler to X[2]: StandardScaler()\n",
      "[PREDICT] combined X shape: (294, 638)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 638), ('_n_samples', 1174), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: 0.0332 (MSE: 3.0685; MAE: 1.3040; mean train mae: 1.3278)\n",
      "*Overall R^2:          0.0354\n",
      "*Overall FOLDS R^2:    0.0247 (+- 0.0172)\n",
      "*R (sqrt R^2):         0.1882\n",
      "*Pearson r:            0.2137 (p = 0.00000)\n",
      "*Folds Pearson r:      0.2245 (p = 0.00851)\n",
      "*Spearman rho:         0.2422 (p = 0.00000)\n",
      "*Mean Squared Error:   3.8866\n",
      "*Mean Absolute Error:  1.4752\n",
      "*Train_Mean MAE:       0.4802\n",
      "\n",
      "[TEST COMPLETE]\n",
      "\n",
      "{'CEL_Total': {(): {1: {'N': 1468,\n",
      "                        'R': np.float64(0.1882009142047099),\n",
      "                        'R2': 0.03541958410748858,\n",
      "                        'R2_folds': np.float64(0.024698221813306564),\n",
      "                        'mae': 1.475204927338783,\n",
      "                        'mae_folds': np.float64(1.4751892708164038),\n",
      "                        'mse': 3.886611529764608,\n",
      "                        'mse_folds': np.float64(3.8861727862860165),\n",
      "                        'num_features': 638,\n",
      "                        'r': np.float64(0.2136533548128213),\n",
      "                        'r_folds': np.float64(0.22452632256505106),\n",
      "                        'r_p': np.float64(1.2870232676251117e-16),\n",
      "                        'r_p_folds': np.float64(0.00850963255852072),\n",
      "                        'rho': np.float64(0.24215211934524364),\n",
      "                        'rho_folds': np.float64(0.24837718094257202),\n",
      "                        'rho_p': np.float64(4.941255507473191e-21),\n",
      "                        'rho_p_folds': np.float64(0.0020880932053849283),\n",
      "                        'se_R2_folds': np.float64(0.017231136408896473),\n",
      "                        'se_mae_folds': np.float64(0.05916298342706999),\n",
      "                        'se_mse_folds': np.float64(0.3504276546437266),\n",
      "                        'se_r_folds': np.float64(0.024164766079782754),\n",
      "                        'se_r_p_folds': np.float64(0.0075947499966880026),\n",
      "                        'se_rho_folds': np.float64(0.024812764051561853),\n",
      "                        'se_rho_p_folds': np.float64(0.001858058045544049),\n",
      "                        'se_train_mean_mae_folds': np.float64(0.0688100424849369),\n",
      "                        'test_size': 294,\n",
      "                        'train_mean_mae': 0.48024178385020305,\n",
      "                        'train_mean_mae_folds': np.float64(1.5141649201924878),\n",
      "                        'train_size': 1174,\n",
      "                        '{modelFS_desc}': 'None',\n",
      "                        '{model_desc}': 'ExtraTreesRegressor(n_estimators=1200, '\n",
      "                                        'n_jobs=12, random_state=42)'}}}}\n",
      "-------\n",
      "Settings:\n",
      "\n",
      "Database - Audio_features\n",
      "Corpus - merged_data\n",
      "Group ID - message_id\n",
      "Feature table(s) - ['feat$librosa_n$merged_data$message_id', 'feat$opensmile_n$merged_data$message_id', 'feat$whisper_mean_n$merged_data$message_id']\n",
      "Outcome table - merged_data\n",
      "Outcome(s) - CEL_Total\n",
      "-------\n",
      "Interface Runtime: 103.68 seconds\n",
      "DLATK exits with success! A good day indeed  ¯\\_(ツ)_/¯.\n"
     ]
    }
   ],
   "source": [
    "!python /home/karthik9/TheDlatk/dlatk/dlatkInterface.py -d Audio_features -t merged_data -c message_id \\\n",
    "-f 'feat$librosa_n$merged_data$message_id' 'feat$opensmile_n$merged_data$message_id' 'feat$whisper_mean_n$merged_data$message_id' \\\n",
    "    --outcome_table merged_data  --group_freq_thresh 10 \\\n",
    "    --outcomes CEL_Total \\\n",
    "    --nfold_test_regression --model extratrees --fold_column fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Warning: Cannot import langid (cannot use addLanguageFilterTable)\n",
      "TopicExtractor: gensim Mallet wrapper unavailable, using Mallet directly.\n",
      "\n",
      "-----\n",
      "DLATK Interface Initiated: 2025-03-18 13:22:50\n",
      "-----\n",
      "Loading Outcomes and Getting Groups for: {'CEL_Total'}\n",
      "    ***explicit fold labels specified, not splitting again***\n",
      "[number of groups: 1468 (5 Folds)]\n",
      "\n",
      "\n",
      "|COMBO: ()|\n",
      "===========\n",
      "\n",
      "= CEL_Total (w/ lang.)=\n",
      "-----------------------\n",
      "Fold 0 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1175    Test size: 293]\n",
      " X[0]: (N, features): (1175, 103)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1175, 103)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (293, 103)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 103), ('_n_samples', 1175), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: 0.0630 (MSE: 2.6798; MAE: 1.2924; mean train mae: 1.3558)\n",
      "Fold 1 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1175    Test size: 293]\n",
      " X[0]: (N, features): (1175, 103)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1175, 103)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (293, 103)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 103), ('_n_samples', 1175), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: 0.0728 (MSE: 4.2940; MAE: 1.5750; mean train mae: 1.6470)\n",
      "Fold 2 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1174    Test size: 294]\n",
      " X[0]: (N, features): (1174, 103)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1174, 103)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (294, 103)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 103), ('_n_samples', 1174), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: 0.0492 (MSE: 4.1508; MAE: 1.4710; mean train mae: 1.5240)\n",
      "Fold 3 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1174    Test size: 294]\n",
      " X[0]: (N, features): (1174, 103)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1174, 103)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (294, 103)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 103), ('_n_samples', 1174), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: 0.0696 (MSE: 4.5804; MAE: 1.6309; mean train mae: 1.7162)\n",
      "Fold 4 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1174    Test size: 294]\n",
      " X[0]: (N, features): (1174, 103)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1174, 103)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (294, 103)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 103), ('_n_samples', 1174), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: 0.0185 (MSE: 3.1152; MAE: 1.3304; mean train mae: 1.3278)\n",
      "*Overall R^2:          0.0657\n",
      "*Overall FOLDS R^2:    0.0546 (+- 0.0089)\n",
      "*R (sqrt R^2):         0.2564\n",
      "*Pearson r:            0.2615 (p = 0.00000)\n",
      "*Folds Pearson r:      0.2674 (p = 0.00000)\n",
      "*Spearman rho:         0.2681 (p = 0.00000)\n",
      "*Mean Squared Error:   3.7644\n",
      "*Mean Absolute Error:  1.4600\n",
      "*Train_Mean MAE:       0.4546\n",
      "\n",
      "[TEST COMPLETE]\n",
      "\n",
      "{'CEL_Total': {(): {1: {'N': 1468,\n",
      "                        'R': np.float64(0.25641419653097175),\n",
      "                        'R2': 0.06574824018262382,\n",
      "                        'R2_folds': np.float64(0.0546161687774291),\n",
      "                        'mae': 1.4599738873751136,\n",
      "                        'mae_folds': np.float64(1.4599381312251865),\n",
      "                        'mse': 3.7644074061459283,\n",
      "                        'mse_folds': np.float64(3.7640298297078596),\n",
      "                        'num_features': 103,\n",
      "                        'r': np.float64(0.2615268359564572),\n",
      "                        'r_folds': np.float64(0.26742748225689084),\n",
      "                        'r_p': np.float64(2.2070917953986356e-24),\n",
      "                        'r_p_folds': np.float64(4.77937112852904e-06),\n",
      "                        'rho': np.float64(0.2680717401705081),\n",
      "                        'rho_folds': np.float64(0.2673938922109145),\n",
      "                        'rho_p': np.float64(1.4016919478476215e-25),\n",
      "                        'rho_p_folds': np.float64(7.180365113516339e-06),\n",
      "                        'se_R2_folds': np.float64(0.008858819430339324),\n",
      "                        'se_mae_folds': np.float64(0.05914199213423783),\n",
      "                        'se_mse_folds': np.float64(0.3282406600822644),\n",
      "                        'se_r_folds': np.float64(0.004230022456981176),\n",
      "                        'se_r_p_folds': np.float64(2.0589275541363445e-06),\n",
      "                        'se_rho_folds': np.float64(0.006138213181494961),\n",
      "                        'se_rho_p_folds': np.float64(4.515515383878978e-06),\n",
      "                        'se_train_mean_mae_folds': np.float64(0.06881004248493687),\n",
      "                        'test_size': 294,\n",
      "                        'train_mean_mae': 0.4546038621070268,\n",
      "                        'train_mean_mae_folds': np.float64(1.5141649201924878),\n",
      "                        'train_size': 1174,\n",
      "                        '{modelFS_desc}': 'None',\n",
      "                        '{model_desc}': 'ExtraTreesRegressor(n_estimators=1200, '\n",
      "                                        'n_jobs=12, random_state=42)'}}}}\n",
      "-------\n",
      "Settings:\n",
      "\n",
      "Database - Audio_features\n",
      "Corpus - merged_data\n",
      "Group ID - message_id\n",
      "Feature table(s) - feat$cat_LIWC2022_lw$merged_data$message_id$1gra\n",
      "Outcome table - merged_data\n",
      "Outcome(s) - CEL_Total\n",
      "-------\n",
      "Interface Runtime: 21.54 seconds\n",
      "DLATK exits with success! A good day indeed  ¯\\_(ツ)_/¯.\n"
     ]
    }
   ],
   "source": [
    "!python /home/karthik9/TheDlatk/dlatk/dlatkInterface.py -d Audio_features -t merged_data -c message_id \\\n",
    "-f  'feat$cat_LIWC2022_lw$merged_data$message_id$1gra'  \\\n",
    "    --outcome_table merged_data  --group_freq_thresh 100 \\\n",
    "    --outcomes CEL_Total \\\n",
    "    --nfold_test_regression --model extratrees --fold_column fold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Warning: Cannot import langid (cannot use addLanguageFilterTable)\n",
      "TopicExtractor: gensim Mallet wrapper unavailable, using Mallet directly.\n",
      "\n",
      "-----\n",
      "DLATK Interface Initiated: 2025-03-18 13:23:19\n",
      "-----\n",
      "Loading Outcomes and Getting Groups for: {'CEL_Total'}\n",
      "    ***explicit fold labels specified, not splitting again***\n",
      "[number of groups: 1468 (5 Folds)]\n",
      "\n",
      "\n",
      "|COMBO: ()|\n",
      "===========\n",
      "\n",
      "= CEL_Total (w/ lang.)=\n",
      "-----------------------\n",
      "Fold 0 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1175    Test size: 293]\n",
      " X[0]: (N, features): (1175, 101)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1175, 101)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (293, 101)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 101), ('_n_samples', 1175), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: 0.0035 (MSE: 2.8499; MAE: 1.3488; mean train mae: 1.3558)\n",
      "Fold 1 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1175    Test size: 293]\n",
      " X[0]: (N, features): (1175, 101)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1175, 101)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (293, 101)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 101), ('_n_samples', 1175), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: 0.0300 (MSE: 4.4922; MAE: 1.6148; mean train mae: 1.6470)\n",
      "Fold 2 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1174    Test size: 294]\n",
      " X[0]: (N, features): (1174, 101)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1174, 101)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (294, 101)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 101), ('_n_samples', 1174), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: -0.0341 (MSE: 4.5144; MAE: 1.5164; mean train mae: 1.5240)\n",
      "Fold 3 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1174    Test size: 294]\n",
      " X[0]: (N, features): (1174, 101)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1174, 101)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (294, 101)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 101), ('_n_samples', 1174), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: 0.0156 (MSE: 4.8465; MAE: 1.6739; mean train mae: 1.7162)\n",
      "Fold 4 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1174    Test size: 294]\n",
      " X[0]: (N, features): (1174, 101)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1174, 101)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (294, 101)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 101), ('_n_samples', 1174), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: 0.0537 (MSE: 3.0032; MAE: 1.2779; mean train mae: 1.3278)\n",
      "*Overall R^2:          0.0218\n",
      "*Overall FOLDS R^2:    0.0137 (+- 0.0131)\n",
      "*R (sqrt R^2):         0.1475\n",
      "*Pearson r:            0.1736 (p = 0.00000)\n",
      "*Folds Pearson r:      0.1861 (p = 0.00914)\n",
      "*Spearman rho:         0.2052 (p = 0.00000)\n",
      "*Mean Squared Error:   3.9416\n",
      "*Mean Absolute Error:  1.4864\n",
      "*Train_Mean MAE:       0.4108\n",
      "\n",
      "[TEST COMPLETE]\n",
      "\n",
      "{'CEL_Total': {(): {1: {'N': 1468,\n",
      "                        'R': np.float64(0.14754817260956496),\n",
      "                        'R2': 0.021770463240421978,\n",
      "                        'R2_folds': np.float64(0.013748024229022859),\n",
      "                        'mae': 1.4863692098092642,\n",
      "                        'mae_folds': np.float64(1.4863629820528896),\n",
      "                        'mse': 3.9416083238722375,\n",
      "                        'mse_folds': np.float64(3.9412402260157),\n",
      "                        'num_features': 101,\n",
      "                        'r': np.float64(0.17358937347035153),\n",
      "                        'r_folds': np.float64(0.18607674088079595),\n",
      "                        'r_p': np.float64(2.138785440616423e-11),\n",
      "                        'r_p_folds': np.float64(0.009143537539692279),\n",
      "                        'rho': np.float64(0.2051922064735047),\n",
      "                        'rho_folds': np.float64(0.2133421063015472),\n",
      "                        'rho_p': np.float64(2.0256307699337822e-15),\n",
      "                        'rho_p_folds': np.float64(0.0041936319206048985),\n",
      "                        'se_R2_folds': np.float64(0.01305004322853149),\n",
      "                        'se_mae_folds': np.float64(0.06780628740691153),\n",
      "                        'se_mse_folds': np.float64(0.37536523703917),\n",
      "                        'se_r_folds': np.float64(0.023518778249916886),\n",
      "                        'se_r_p_folds': np.float64(0.0059378452482165755),\n",
      "                        'se_rho_folds': np.float64(0.023926448207990395),\n",
      "                        'se_rho_p_folds': np.float64(0.0032888969813630476),\n",
      "                        'se_train_mean_mae_folds': np.float64(0.06881004248493686),\n",
      "                        'test_size': 294,\n",
      "                        'train_mean_mae': 0.4107841892557422,\n",
      "                        'train_mean_mae_folds': np.float64(1.5141649201924878),\n",
      "                        'train_size': 1174,\n",
      "                        '{modelFS_desc}': 'None',\n",
      "                        '{model_desc}': 'ExtraTreesRegressor(n_estimators=1200, '\n",
      "                                        'n_jobs=12, random_state=42)'}}}}\n",
      "-------\n",
      "Settings:\n",
      "\n",
      "Database - Audio_features\n",
      "Corpus - merged_data\n",
      "Group ID - message_id\n",
      "Feature table(s) - feat$cat_klaatch_senten2_lda_cp_w$merged_data$message_id$1gra\n",
      "Outcome table - merged_data\n",
      "Outcome(s) - CEL_Total\n",
      "-------\n",
      "Interface Runtime: 21.67 seconds\n",
      "DLATK exits with success! A good day indeed  ¯\\_(ツ)_/¯.\n"
     ]
    }
   ],
   "source": [
    "!python /home/karthik9/TheDlatk/dlatk/dlatkInterface.py -d Audio_features -t merged_data -c message_id \\\n",
    "-f  'feat$cat_klaatch_senten2_lda_cp_w$merged_data$message_id$1gra'  \\\n",
    "    --outcome_table merged_data  --group_freq_thresh 10 \\\n",
    "    --outcomes CEL_Total \\\n",
    "    --nfold_test_regression --model extratrees --fold_column fold \n",
    "    #--prediction_csv --output_name ./Klatch_ldasenten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Warning: Cannot import langid (cannot use addLanguageFilterTable)\n",
      "TopicExtractor: gensim Mallet wrapper unavailable, using Mallet directly.\n",
      "\n",
      "-----\n",
      "DLATK Interface Initiated: 2025-03-18 13:23:47\n",
      "-----\n",
      "Loading Outcomes and Getting Groups for: {'CEL_Total'}\n",
      "    ***explicit fold labels specified, not splitting again***\n",
      "[number of groups: 1468 (5 Folds)]\n",
      "\n",
      "\n",
      "|COMBO: ()|\n",
      "===========\n",
      "\n",
      "= CEL_Total (w/ lang.)=\n",
      "-----------------------\n",
      "Fold 0 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1175    Test size: 293]\n",
      " X[0]: (N, features): (1175, 2865)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1175, 2865)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (293, 2865)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 2865), ('_n_samples', 1175), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: 0.0487 (MSE: 2.7206; MAE: 1.2939; mean train mae: 1.3558)\n",
      "Fold 1 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1175    Test size: 293]\n",
      " X[0]: (N, features): (1175, 2865)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1175, 2865)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (293, 2865)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 2865), ('_n_samples', 1175), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: 0.1064 (MSE: 4.1386; MAE: 1.5326; mean train mae: 1.6470)\n",
      "Fold 2 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1174    Test size: 294]\n",
      " X[0]: (N, features): (1174, 2865)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1174, 2865)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (294, 2865)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 2865), ('_n_samples', 1174), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: -0.0371 (MSE: 4.5276; MAE: 1.5155; mean train mae: 1.5240)\n",
      "Fold 3 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1174    Test size: 294]\n",
      " X[0]: (N, features): (1174, 2865)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1174, 2865)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (294, 2865)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 2865), ('_n_samples', 1174), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: 0.0585 (MSE: 4.6352; MAE: 1.5981; mean train mae: 1.7162)\n",
      "Fold 4 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1174    Test size: 294]\n",
      " X[0]: (N, features): (1174, 2865)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1174, 2865)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (294, 2865)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 2865), ('_n_samples', 1174), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: 0.0874 (MSE: 2.8964; MAE: 1.2532; mean train mae: 1.3278)\n",
      "*Overall R^2:          0.0608\n",
      "*Overall FOLDS R^2:    0.0528 (+- 0.0221)\n",
      "*R (sqrt R^2):         0.2467\n",
      "*Pearson r:            0.2478 (p = 0.00000)\n",
      "*Folds Pearson r:      0.2521 (p = 0.02024)\n",
      "*Spearman rho:         0.2887 (p = 0.00000)\n",
      "*Mean Squared Error:   3.7842\n",
      "*Mean Absolute Error:  1.4387\n",
      "*Train_Mean MAE:       0.3943\n",
      "\n",
      "[TEST COMPLETE]\n",
      "\n",
      "{'CEL_Total': {(): {1: {'N': 1468,\n",
      "                        'R': np.float64(0.2466621030000421),\n",
      "                        'R2': 0.06084219305640337,\n",
      "                        'R2_folds': np.float64(0.05276704374488872),\n",
      "                        'mae': 1.4387000454132604,\n",
      "                        'mae_folds': np.float64(1.4386654574230147),\n",
      "                        'mse': 3.784175482515894,\n",
      "                        'mse_folds': np.float64(3.783693084975647),\n",
      "                        'num_features': 2865,\n",
      "                        'r': np.float64(0.24775128167674454),\n",
      "                        'r_folds': np.float64(0.25210640539063744),\n",
      "                        'r_p': np.float64(5.69063626140541e-22),\n",
      "                        'r_p_folds': np.float64(0.020241925769435527),\n",
      "                        'rho': np.float64(0.2887388147181691),\n",
      "                        'rho_folds': np.float64(0.28618507451594594),\n",
      "                        'rho_p': np.float64(1.3909615399082685e-29),\n",
      "                        'rho_p_folds': np.float64(0.018911547125299556),\n",
      "                        'se_R2_folds': np.float64(0.022085122181285808),\n",
      "                        'se_mae_folds': np.float64(0.06181374604104782),\n",
      "                        'se_mse_folds': np.float64(0.3645211031969331),\n",
      "                        'se_r_folds': np.float64(0.03916843846251013),\n",
      "                        'se_r_p_folds': np.float64(0.018098552218593408),\n",
      "                        'se_rho_folds': np.float64(0.04454475577032522),\n",
      "                        'se_rho_p_folds': np.float64(0.01691486343532946),\n",
      "                        'se_train_mean_mae_folds': np.float64(0.06881004248493686),\n",
      "                        'test_size': 294,\n",
      "                        'train_mean_mae': 0.39432349090621105,\n",
      "                        'train_mean_mae_folds': np.float64(1.5141649201924878),\n",
      "                        'train_size': 1174,\n",
      "                        '{modelFS_desc}': 'None',\n",
      "                        '{model_desc}': 'ExtraTreesRegressor(n_estimators=1200, '\n",
      "                                        'n_jobs=12, random_state=42)'}}}}\n",
      "-------\n",
      "Settings:\n",
      "\n",
      "Database - Audio_features\n",
      "Corpus - merged_data\n",
      "Group ID - message_id\n",
      "Feature table(s) - feat$1to3gram$merged_data$message_id$0_05$pmi3_0\n",
      "Outcome table - merged_data\n",
      "Outcome(s) - CEL_Total\n",
      "-------\n",
      "Interface Runtime: 412.60 seconds\n",
      "DLATK exits with success! A good day indeed  ¯\\_(ツ)_/¯.\n"
     ]
    }
   ],
   "source": [
    "!python /home/karthik9/TheDlatk/dlatk/dlatkInterface.py -d Audio_features -t merged_data -c message_id \\\n",
    "-f  'feat$1to3gram$merged_data$message_id$0_05$pmi3_0'\\\n",
    "    --outcome_table merged_data  --group_freq_thresh 100 \\\n",
    "    --outcomes CEL_Total \\\n",
    "    --nfold_test_regression --model extratrees --fold_column fold \n",
    "    #--prediction_csv --output_name ./Klatch_1to3grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Warning: Cannot import langid (cannot use addLanguageFilterTable)\n",
      "TopicExtractor: gensim Mallet wrapper unavailable, using Mallet directly.\n",
      "\n",
      "-----\n",
      "DLATK Interface Initiated: 2025-03-18 13:30:47\n",
      "-----\n",
      "Loading Outcomes and Getting Groups for: {'CEL_Total'}\n",
      "    ***explicit fold labels specified, not splitting again***\n",
      "[number of groups: 1468 (5 Folds)]\n",
      "\n",
      "\n",
      "|COMBO: ()|\n",
      "===========\n",
      "\n",
      "= CEL_Total (w/ lang.)=\n",
      "-----------------------\n",
      "Fold 0 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      "   (feature group: 1): [Initial size: 1468]\n",
      "   (feature group: 2): [Initial size: 1468]\n",
      " [Train size: 1175    Test size: 293]\n",
      " X[0]: (N, features): (1175, 101)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      " X[1]: (N, features): (1175, 103)\n",
      "  [Applying StandardScaler to X[1]: StandardScaler()]\n",
      " X[2]: (N, features): (1175, 2865)\n",
      "  [Applying StandardScaler to X[2]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1175, 3069)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] applying *existing* standard scaler to X[1]: StandardScaler()\n",
      "[PREDICT] applying *existing* standard scaler to X[2]: StandardScaler()\n",
      "[PREDICT] combined X shape: (293, 3069)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 3069), ('_n_samples', 1175), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: 0.0734 (MSE: 2.6499; MAE: 1.2813; mean train mae: 1.3558)\n",
      "Fold 1 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      "   (feature group: 1): [Initial size: 1468]\n",
      "   (feature group: 2): [Initial size: 1468]\n",
      " [Train size: 1175    Test size: 293]\n",
      " X[0]: (N, features): (1175, 101)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      " X[1]: (N, features): (1175, 103)\n",
      "  [Applying StandardScaler to X[1]: StandardScaler()]\n",
      " X[2]: (N, features): (1175, 2865)\n",
      "  [Applying StandardScaler to X[2]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1175, 3069)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] applying *existing* standard scaler to X[1]: StandardScaler()\n",
      "[PREDICT] applying *existing* standard scaler to X[2]: StandardScaler()\n",
      "[PREDICT] combined X shape: (293, 3069)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 3069), ('_n_samples', 1175), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: 0.1141 (MSE: 4.1029; MAE: 1.5287; mean train mae: 1.6470)\n",
      "Fold 2 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      "   (feature group: 1): [Initial size: 1468]\n",
      "   (feature group: 2): [Initial size: 1468]\n",
      " [Train size: 1174    Test size: 294]\n",
      " X[0]: (N, features): (1174, 101)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      " X[1]: (N, features): (1174, 103)\n",
      "  [Applying StandardScaler to X[1]: StandardScaler()]\n",
      " X[2]: (N, features): (1174, 2865)\n",
      "  [Applying StandardScaler to X[2]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1174, 3069)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] applying *existing* standard scaler to X[1]: StandardScaler()\n",
      "[PREDICT] applying *existing* standard scaler to X[2]: StandardScaler()\n",
      "[PREDICT] combined X shape: (294, 3069)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 3069), ('_n_samples', 1174), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: -0.0075 (MSE: 4.3986; MAE: 1.4892; mean train mae: 1.5240)\n",
      "Fold 3 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      "   (feature group: 1): [Initial size: 1468]\n",
      "   (feature group: 2): [Initial size: 1468]\n",
      " [Train size: 1174    Test size: 294]\n",
      " X[0]: (N, features): (1174, 101)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      " X[1]: (N, features): (1174, 103)\n",
      "  [Applying StandardScaler to X[1]: StandardScaler()]\n",
      " X[2]: (N, features): (1174, 2865)\n",
      "  [Applying StandardScaler to X[2]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1174, 3069)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] applying *existing* standard scaler to X[1]: StandardScaler()\n",
      "[PREDICT] applying *existing* standard scaler to X[2]: StandardScaler()\n",
      "[PREDICT] combined X shape: (294, 3069)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 3069), ('_n_samples', 1174), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: 0.0712 (MSE: 4.5726; MAE: 1.5974; mean train mae: 1.7162)\n",
      "Fold 4 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      "   (feature group: 1): [Initial size: 1468]\n",
      "   (feature group: 2): [Initial size: 1468]\n",
      " [Train size: 1174    Test size: 294]\n",
      " X[0]: (N, features): (1174, 101)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      " X[1]: (N, features): (1174, 103)\n",
      "  [Applying StandardScaler to X[1]: StandardScaler()]\n",
      " X[2]: (N, features): (1174, 2865)\n",
      "  [Applying StandardScaler to X[2]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1174, 3069)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] applying *existing* standard scaler to X[1]: StandardScaler()\n",
      "[PREDICT] applying *existing* standard scaler to X[2]: StandardScaler()\n",
      "[PREDICT] combined X shape: (294, 3069)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 3069), ('_n_samples', 1174), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: 0.0878 (MSE: 2.8951; MAE: 1.2547; mean train mae: 1.3278)\n",
      "*Overall R^2:          0.0757\n",
      "*Overall FOLDS R^2:    0.0678 (+- 0.0182)\n",
      "*R (sqrt R^2):         0.2751\n",
      "*Pearson r:            0.2778 (p = 0.00000)\n",
      "*Folds Pearson r:      0.2818 (p = 0.00170)\n",
      "*Spearman rho:         0.3034 (p = 0.00000)\n",
      "*Mean Squared Error:   3.7243\n",
      "*Mean Absolute Error:  1.4303\n",
      "*Train_Mean MAE:       0.3923\n",
      "\n",
      "[TEST COMPLETE]\n",
      "\n",
      "{'CEL_Total': {(): {1: {'N': 1468,\n",
      "                        'R': np.float64(0.2751471015837863),\n",
      "                        'R2': 0.07570592750995842,\n",
      "                        'R2_folds': np.float64(0.06779254496826818),\n",
      "                        'mae': 1.4303116485013625,\n",
      "                        'mae_folds': np.float64(1.4302772650584694),\n",
      "                        'mse': 3.7242846110543444,\n",
      "                        'mse_folds': np.float64(3.7238113034179348),\n",
      "                        'num_features': 3069,\n",
      "                        'r': np.float64(0.2778401466299223),\n",
      "                        'r_folds': np.float64(0.2817602562974345),\n",
      "                        'r_p': np.float64(1.9818517640899465e-27),\n",
      "                        'r_p_folds': np.float64(0.0016955291351778029),\n",
      "                        'rho': np.float64(0.3034414525955966),\n",
      "                        'rho_folds': np.float64(0.2992501679129661),\n",
      "                        'rho_p': np.float64(1.2130659459991878e-32),\n",
      "                        'rho_p_folds': np.float64(0.0010415912498971498),\n",
      "                        'se_R2_folds': np.float64(0.018176469604593994),\n",
      "                        'se_mae_folds': np.float64(0.061361495756758644),\n",
      "                        'se_mse_folds': np.float64(0.3554952026581365),\n",
      "                        'se_r_folds': np.float64(0.03189265874278864),\n",
      "                        'se_r_p_folds': np.float64(0.0015161776040085425),\n",
      "                        'se_rho_folds': np.float64(0.033958755378344495),\n",
      "                        'se_rho_p_folds': np.float64(0.0009315044158223345),\n",
      "                        'se_train_mean_mae_folds': np.float64(0.06881004248493686),\n",
      "                        'test_size': 294,\n",
      "                        'train_mean_mae': 0.3922991004585873,\n",
      "                        'train_mean_mae_folds': np.float64(1.5141649201924878),\n",
      "                        'train_size': 1174,\n",
      "                        '{modelFS_desc}': 'None',\n",
      "                        '{model_desc}': 'ExtraTreesRegressor(n_estimators=1200, '\n",
      "                                        'n_jobs=12, random_state=42)'}}}}\n",
      "-------\n",
      "Settings:\n",
      "\n",
      "Database - Audio_features\n",
      "Corpus - merged_data\n",
      "Group ID - message_id\n",
      "Feature table(s) - ['feat$cat_klaatch_senten2_lda_cp_w$merged_data$message_id$1gra', 'feat$cat_LIWC2022_lw$merged_data$message_id$1gra', 'feat$1to3gram$merged_data$message_id$0_05$pmi3_0']\n",
      "Outcome table - merged_data\n",
      "Outcome(s) - CEL_Total\n",
      "-------\n",
      "Interface Runtime: 408.29 seconds\n",
      "DLATK exits with success! A good day indeed  ¯\\_(ツ)_/¯.\n"
     ]
    }
   ],
   "source": [
    "!python /home/karthik9/TheDlatk/dlatk/dlatkInterface.py -d Audio_features -t merged_data -c message_id \\\n",
    "-f  'feat$cat_klaatch_senten2_lda_cp_w$merged_data$message_id$1gra' 'feat$cat_LIWC2022_lw$merged_data$message_id$1gra'  'feat$1to3gram$merged_data$message_id$0_05$pmi3_0' \\\n",
    "    --outcome_table merged_data  --group_freq_thresh 0 \\\n",
    "    --outcomes CEL_Total \\\n",
    "    --nfold_test_regression --model extratrees --fold_column fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Warning: Cannot import langid (cannot use addLanguageFilterTable)\n",
      "TopicExtractor: gensim Mallet wrapper unavailable, using Mallet directly.\n",
      "\n",
      "-----\n",
      "DLATK Interface Initiated: 2025-03-18 13:37:43\n",
      "-----\n",
      "Loading Outcomes and Getting Groups for: {'CEL_Total'}\n",
      "    ***explicit fold labels specified, not splitting again***\n",
      "[number of groups: 1468 (5 Folds)]\n",
      "\n",
      "\n",
      "|COMBO: ()|\n",
      "===========\n",
      "\n",
      "= CEL_Total (w/ lang.)=\n",
      "-----------------------\n",
      "Fold 0 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      "   (feature group: 1): [Initial size: 1468]\n",
      "   (feature group: 2): [Initial size: 1468]\n",
      "   (feature group: 3): [Initial size: 1468]\n",
      "   (feature group: 4): [Initial size: 1468]\n",
      "   (feature group: 5): [Initial size: 1468]\n",
      " [Train size: 1175    Test size: 293]\n",
      " X[0]: (N, features): (1175, 38)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      " X[1]: (N, features): (1175, 88)\n",
      "  [Applying StandardScaler to X[1]: StandardScaler()]\n",
      " X[2]: (N, features): (1175, 512)\n",
      "  [Applying StandardScaler to X[2]: StandardScaler()]\n",
      " X[3]: (N, features): (1175, 101)\n",
      "  [Applying StandardScaler to X[3]: StandardScaler()]\n",
      " X[4]: (N, features): (1175, 103)\n",
      "  [Applying StandardScaler to X[4]: StandardScaler()]\n",
      " X[5]: (N, features): (1175, 2865)\n",
      "  [Applying StandardScaler to X[5]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1175, 3707)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] applying *existing* standard scaler to X[1]: StandardScaler()\n",
      "[PREDICT] applying *existing* standard scaler to X[2]: StandardScaler()\n",
      "[PREDICT] applying *existing* standard scaler to X[3]: StandardScaler()\n",
      "[PREDICT] applying *existing* standard scaler to X[4]: StandardScaler()\n",
      "[PREDICT] applying *existing* standard scaler to X[5]: StandardScaler()\n",
      "[PREDICT] combined X shape: (293, 3707)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 3707), ('_n_samples', 1175), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: 0.0855 (MSE: 2.6155; MAE: 1.2777; mean train mae: 1.3558)\n",
      "Fold 1 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      "   (feature group: 1): [Initial size: 1468]\n",
      "   (feature group: 2): [Initial size: 1468]\n",
      "   (feature group: 3): [Initial size: 1468]\n",
      "   (feature group: 4): [Initial size: 1468]\n",
      "   (feature group: 5): [Initial size: 1468]\n",
      " [Train size: 1175    Test size: 293]\n",
      " X[0]: (N, features): (1175, 38)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      " X[1]: (N, features): (1175, 88)\n",
      "  [Applying StandardScaler to X[1]: StandardScaler()]\n",
      " X[2]: (N, features): (1175, 512)\n",
      "  [Applying StandardScaler to X[2]: StandardScaler()]\n",
      " X[3]: (N, features): (1175, 101)\n",
      "  [Applying StandardScaler to X[3]: StandardScaler()]\n",
      " X[4]: (N, features): (1175, 103)\n",
      "  [Applying StandardScaler to X[4]: StandardScaler()]\n",
      " X[5]: (N, features): (1175, 2865)\n",
      "  [Applying StandardScaler to X[5]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1175, 3707)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] applying *existing* standard scaler to X[1]: StandardScaler()\n",
      "[PREDICT] applying *existing* standard scaler to X[2]: StandardScaler()\n",
      "[PREDICT] applying *existing* standard scaler to X[3]: StandardScaler()\n",
      "[PREDICT] applying *existing* standard scaler to X[4]: StandardScaler()\n",
      "[PREDICT] applying *existing* standard scaler to X[5]: StandardScaler()\n",
      "[PREDICT] combined X shape: (293, 3707)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 3707), ('_n_samples', 1175), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: 0.1531 (MSE: 3.9221; MAE: 1.4907; mean train mae: 1.6470)\n",
      "Fold 2 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      "   (feature group: 1): [Initial size: 1468]\n",
      "   (feature group: 2): [Initial size: 1468]\n",
      "   (feature group: 3): [Initial size: 1468]\n",
      "   (feature group: 4): [Initial size: 1468]\n",
      "   (feature group: 5): [Initial size: 1468]\n",
      " [Train size: 1174    Test size: 294]\n",
      " X[0]: (N, features): (1174, 38)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      " X[1]: (N, features): (1174, 88)\n",
      "  [Applying StandardScaler to X[1]: StandardScaler()]\n",
      " X[2]: (N, features): (1174, 512)\n",
      "  [Applying StandardScaler to X[2]: StandardScaler()]\n",
      " X[3]: (N, features): (1174, 101)\n",
      "  [Applying StandardScaler to X[3]: StandardScaler()]\n",
      " X[4]: (N, features): (1174, 103)\n",
      "  [Applying StandardScaler to X[4]: StandardScaler()]\n",
      " X[5]: (N, features): (1174, 2865)\n",
      "  [Applying StandardScaler to X[5]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1174, 3707)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] applying *existing* standard scaler to X[1]: StandardScaler()\n",
      "[PREDICT] applying *existing* standard scaler to X[2]: StandardScaler()\n",
      "[PREDICT] applying *existing* standard scaler to X[3]: StandardScaler()\n",
      "[PREDICT] applying *existing* standard scaler to X[4]: StandardScaler()\n",
      "[PREDICT] applying *existing* standard scaler to X[5]: StandardScaler()\n",
      "[PREDICT] combined X shape: (294, 3707)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 3707), ('_n_samples', 1174), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: 0.0189 (MSE: 4.2833; MAE: 1.4654; mean train mae: 1.5240)\n",
      "Fold 3 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      "   (feature group: 1): [Initial size: 1468]\n",
      "   (feature group: 2): [Initial size: 1468]\n",
      "   (feature group: 3): [Initial size: 1468]\n",
      "   (feature group: 4): [Initial size: 1468]\n",
      "   (feature group: 5): [Initial size: 1468]\n",
      " [Train size: 1174    Test size: 294]\n",
      " X[0]: (N, features): (1174, 38)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      " X[1]: (N, features): (1174, 88)\n",
      "  [Applying StandardScaler to X[1]: StandardScaler()]\n",
      " X[2]: (N, features): (1174, 512)\n",
      "  [Applying StandardScaler to X[2]: StandardScaler()]\n",
      " X[3]: (N, features): (1174, 101)\n",
      "  [Applying StandardScaler to X[3]: StandardScaler()]\n",
      " X[4]: (N, features): (1174, 103)\n",
      "  [Applying StandardScaler to X[4]: StandardScaler()]\n",
      " X[5]: (N, features): (1174, 2865)\n",
      "  [Applying StandardScaler to X[5]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1174, 3707)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] applying *existing* standard scaler to X[1]: StandardScaler()\n",
      "[PREDICT] applying *existing* standard scaler to X[2]: StandardScaler()\n",
      "[PREDICT] applying *existing* standard scaler to X[3]: StandardScaler()\n",
      "[PREDICT] applying *existing* standard scaler to X[4]: StandardScaler()\n",
      "[PREDICT] applying *existing* standard scaler to X[5]: StandardScaler()\n",
      "[PREDICT] combined X shape: (294, 3707)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 3707), ('_n_samples', 1174), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: 0.1045 (MSE: 4.4088; MAE: 1.5747; mean train mae: 1.7162)\n",
      "Fold 4 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      "   (feature group: 1): [Initial size: 1468]\n",
      "   (feature group: 2): [Initial size: 1468]\n",
      "   (feature group: 3): [Initial size: 1468]\n",
      "   (feature group: 4): [Initial size: 1468]\n",
      "   (feature group: 5): [Initial size: 1468]\n",
      " [Train size: 1174    Test size: 294]\n",
      " X[0]: (N, features): (1174, 38)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      " X[1]: (N, features): (1174, 88)\n",
      "  [Applying StandardScaler to X[1]: StandardScaler()]\n",
      " X[2]: (N, features): (1174, 512)\n",
      "  [Applying StandardScaler to X[2]: StandardScaler()]\n",
      " X[3]: (N, features): (1174, 101)\n",
      "  [Applying StandardScaler to X[3]: StandardScaler()]\n",
      " X[4]: (N, features): (1174, 103)\n",
      "  [Applying StandardScaler to X[4]: StandardScaler()]\n",
      " X[5]: (N, features): (1174, 2865)\n",
      "  [Applying StandardScaler to X[5]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1174, 3707)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] applying *existing* standard scaler to X[1]: StandardScaler()\n",
      "[PREDICT] applying *existing* standard scaler to X[2]: StandardScaler()\n",
      "[PREDICT] applying *existing* standard scaler to X[3]: StandardScaler()\n",
      "[PREDICT] applying *existing* standard scaler to X[4]: StandardScaler()\n",
      "[PREDICT] applying *existing* standard scaler to X[5]: StandardScaler()\n",
      "[PREDICT] combined X shape: (294, 3707)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 3707), ('_n_samples', 1174), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: 0.0881 (MSE: 2.8940; MAE: 1.2721; mean train mae: 1.3278)\n",
      "*Overall R^2:          0.1003\n",
      "*Overall FOLDS R^2:    0.0900 (+- 0.0193)\n",
      "*R (sqrt R^2):         0.3167\n",
      "*Pearson r:            0.3222 (p = 0.00000)\n",
      "*Folds Pearson r:      0.3258 (p = 0.00005)\n",
      "*Spearman rho:         0.3502 (p = 0.00000)\n",
      "*Mean Squared Error:   3.6252\n",
      "*Mean Absolute Error:  1.4162\n",
      "*Train_Mean MAE:       0.4402\n",
      "\n",
      "[TEST COMPLETE]\n",
      "\n",
      "{'CEL_Total': {(): {1: {'N': 1468,\n",
      "                        'R': np.float64(0.3166857956350102),\n",
      "                        'R2': 0.10028989315697945,\n",
      "                        'R2_folds': np.float64(0.09000945505561816),\n",
      "                        'mae': 1.4161625794732062,\n",
      "                        'mae_folds': np.float64(1.416119076640895),\n",
      "                        'mse': 3.6252277333106266,\n",
      "                        'mse_folds': np.float64(3.624742788933454),\n",
      "                        'num_features': 3707,\n",
      "                        'r': np.float64(0.3222494287030252),\n",
      "                        'r_folds': np.float64(0.32583903970533623),\n",
      "                        'r_p': np.float64(8.035904371010379e-37),\n",
      "                        'r_p_folds': np.float64(4.9744367564995764e-05),\n",
      "                        'rho': np.float64(0.35016620497745554),\n",
      "                        'rho_folds': np.float64(0.35043852980383267),\n",
      "                        'rho_p': np.float64(1.3500693417719653e-43),\n",
      "                        'rho_p_folds': np.float64(4.021909595544067e-06),\n",
      "                        'se_R2_folds': np.float64(0.019262372977727937),\n",
      "                        'se_mae_folds': np.float64(0.05405287563603027),\n",
      "                        'se_mse_folds': np.float64(0.32798705072435824),\n",
      "                        'se_r_folds': np.float64(0.03146661460634014),\n",
      "                        'se_r_p_folds': np.float64(4.4478685882249417e-05),\n",
      "                        'se_rho_folds': np.float64(0.03331144332021883),\n",
      "                        'se_rho_p_folds': np.float64(3.5555312881388627e-06),\n",
      "                        'se_train_mean_mae_folds': np.float64(0.06881004248493688),\n",
      "                        'test_size': 294,\n",
      "                        'train_mean_mae': 0.4402225590063034,\n",
      "                        'train_mean_mae_folds': np.float64(1.5141649201924878),\n",
      "                        'train_size': 1174,\n",
      "                        '{modelFS_desc}': 'None',\n",
      "                        '{model_desc}': 'ExtraTreesRegressor(n_estimators=1200, '\n",
      "                                        'n_jobs=12, random_state=42)'}}}}\n",
      "-------\n",
      "Settings:\n",
      "\n",
      "Database - Audio_features\n",
      "Corpus - merged_data\n",
      "Group ID - message_id\n",
      "Feature table(s) - ['feat$librosa_n$merged_data$message_id', 'feat$opensmile_n$merged_data$message_id', 'feat$whisper_mean_n$merged_data$message_id', 'feat$cat_klaatch_senten2_lda_cp_w$merged_data$message_id$1gra', 'feat$cat_LIWC2022_lw$merged_data$message_id$1gra', 'feat$1to3gram$merged_data$message_id$0_05$pmi3_0']\n",
      "Outcome table - merged_data\n",
      "Outcome(s) - CEL_Total\n",
      "-------\n",
      "Interface Runtime: 528.57 seconds\n",
      "DLATK exits with success! A good day indeed  ¯\\_(ツ)_/¯.\n"
     ]
    }
   ],
   "source": [
    "!python /home/karthik9/TheDlatk/dlatk/dlatkInterface.py -d Audio_features -t merged_data -c message_id \\\n",
    "-f 'feat$librosa_n$merged_data$message_id' 'feat$opensmile_n$merged_data$message_id' 'feat$whisper_mean_n$merged_data$message_id'  'feat$cat_klaatch_senten2_lda_cp_w$merged_data$message_id$1gra' 'feat$cat_LIWC2022_lw$merged_data$message_id$1gra'  'feat$1to3gram$merged_data$message_id$0_05$pmi3_0' \\\n",
    "    --outcome_table merged_data  --group_freq_thresh 100 \\\n",
    "    --outcomes CEL_Total \\\n",
    "    --nfold_test_regression --model extratrees --fold_column fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "/data/anaconda2/envs/dlatk/lib/python3.5/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n",
      "\n",
      "-----\n",
      "DLATK Interface Initiated: 2025-02-06 18:45:19\n",
      "-----\n",
      "Loading Outcomes and Getting Groups for: {'CEL_Total', 'CELVAL1', 'CELVAL2', 'CELVAL3'}\n",
      "    ***explicit fold labels specified, not splitting again***\n",
      "[number of groups: 1354 (5 Folds)]\n",
      "\n",
      "\n",
      "|COMBO: ()|\n",
      "===========\n",
      "\n",
      "= CELVAL1 (w/ lang.)=\n",
      "---------------------\n",
      "Fold 0 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('warm_start', False), ('min_impurity_split', 1e-07), ('bootstrap', False), ('max_depth', None), ('n_outputs_', 1), ('random_state', 42), ('min_samples_split', 2), ('min_samples_leaf', 1), ('max_leaf_nodes', None), ('oob_score', False), ('class_weight', None), ('n_jobs', 12), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_features_', 1024), ('verbose', 0), ('n_estimators', 1200), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_weight_fraction_leaf', 0.0)]\n",
      "  *FOLD R^2: 0.0317 (MSE: 0.6772; MAE: 0.5768; mean train mae: 0.6021)\n",
      "Fold 1 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('warm_start', False), ('min_impurity_split', 1e-07), ('bootstrap', False), ('max_depth', None), ('n_outputs_', 1), ('random_state', 42), ('min_samples_split', 2), ('min_samples_leaf', 1), ('max_leaf_nodes', None), ('oob_score', False), ('class_weight', None), ('n_jobs', 12), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_features_', 1024), ('verbose', 0), ('n_estimators', 1200), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_weight_fraction_leaf', 0.0)]\n",
      "  *FOLD R^2: -0.0834 (MSE: 0.7316; MAE: 0.6404; mean train mae: 0.6184)\n",
      "Fold 2 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('warm_start', False), ('min_impurity_split', 1e-07), ('bootstrap', False), ('max_depth', None), ('n_outputs_', 1), ('random_state', 42), ('min_samples_split', 2), ('min_samples_leaf', 1), ('max_leaf_nodes', None), ('oob_score', False), ('class_weight', None), ('n_jobs', 12), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_features_', 1024), ('verbose', 0), ('n_estimators', 1200), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_weight_fraction_leaf', 0.0)]\n",
      "  *FOLD R^2: -0.0577 (MSE: 0.4388; MAE: 0.4911; mean train mae: 0.4947)\n",
      "Fold 3 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('warm_start', False), ('min_impurity_split', 1e-07), ('bootstrap', False), ('max_depth', None), ('n_outputs_', 1), ('random_state', 42), ('min_samples_split', 2), ('min_samples_leaf', 1), ('max_leaf_nodes', None), ('oob_score', False), ('class_weight', None), ('n_jobs', 12), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_features_', 1024), ('verbose', 0), ('n_estimators', 1200), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_weight_fraction_leaf', 0.0)]\n",
      "  *FOLD R^2: -0.0252 (MSE: 0.5114; MAE: 0.5335; mean train mae: 0.5390)\n",
      "Fold 4 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1084    Test size: 270]\n",
      " X[0]: (N, features): (1084, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1084, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (270, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('warm_start', False), ('min_impurity_split', 1e-07), ('bootstrap', False), ('max_depth', None), ('n_outputs_', 1), ('random_state', 42), ('min_samples_split', 2), ('min_samples_leaf', 1), ('max_leaf_nodes', None), ('oob_score', False), ('class_weight', None), ('n_jobs', 12), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_features_', 1024), ('verbose', 0), ('n_estimators', 1200), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_weight_fraction_leaf', 0.0)]\n",
      "  *FOLD R^2: -0.0919 (MSE: 0.6206; MAE: 0.5667; mean train mae: 0.5454)\n",
      "/home/karthik9/TheDlatk/dlatk/dlatk/regressionPredictor.py:1398: RuntimeWarning: invalid value encountered in sqrt\n",
      "  reportStats['R'] = sqrt(reportStats['R2'])\n",
      "*Overall R^2:          -0.0388\n",
      "*Overall FOLDS R^2:    -0.0453 (+- 0.0201)\n",
      "*R (sqrt R^2):         nan\n",
      "*Pearson r:            0.0906 (p = 0.00085)\n",
      "*Folds Pearson r:      0.0959 (p = 0.33319)\n",
      "*Spearman rho:         0.0907 (p = 0.00083)\n",
      "*Mean Squared Error:   0.5959\n",
      "*Mean Absolute Error:  0.5617\n",
      "*Train_Mean MAE:       0.1726\n",
      "\n",
      "= CELVAL2 (w/ lang.)=\n",
      "---------------------\n",
      "Fold 0 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('warm_start', False), ('min_impurity_split', 1e-07), ('bootstrap', False), ('max_depth', None), ('n_outputs_', 1), ('random_state', 42), ('min_samples_split', 2), ('min_samples_leaf', 1), ('max_leaf_nodes', None), ('oob_score', False), ('class_weight', None), ('n_jobs', 12), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_features_', 1024), ('verbose', 0), ('n_estimators', 1200), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_weight_fraction_leaf', 0.0)]\n",
      "  *FOLD R^2: -0.0092 (MSE: 0.6214; MAE: 0.5650; mean train mae: 0.5735)\n",
      "Fold 1 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('warm_start', False), ('min_impurity_split', 1e-07), ('bootstrap', False), ('max_depth', None), ('n_outputs_', 1), ('random_state', 42), ('min_samples_split', 2), ('min_samples_leaf', 1), ('max_leaf_nodes', None), ('oob_score', False), ('class_weight', None), ('n_jobs', 12), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_features_', 1024), ('verbose', 0), ('n_estimators', 1200), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_weight_fraction_leaf', 0.0)]\n",
      "  *FOLD R^2: 0.0063 (MSE: 0.6012; MAE: 0.6078; mean train mae: 0.6141)\n",
      "Fold 2 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('warm_start', False), ('min_impurity_split', 1e-07), ('bootstrap', False), ('max_depth', None), ('n_outputs_', 1), ('random_state', 42), ('min_samples_split', 2), ('min_samples_leaf', 1), ('max_leaf_nodes', None), ('oob_score', False), ('class_weight', None), ('n_jobs', 12), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_features_', 1024), ('verbose', 0), ('n_estimators', 1200), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_weight_fraction_leaf', 0.0)]\n",
      "  *FOLD R^2: -0.0047 (MSE: 0.7049; MAE: 0.6045; mean train mae: 0.6139)\n",
      "Fold 3 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('warm_start', False), ('min_impurity_split', 1e-07), ('bootstrap', False), ('max_depth', None), ('n_outputs_', 1), ('random_state', 42), ('min_samples_split', 2), ('min_samples_leaf', 1), ('max_leaf_nodes', None), ('oob_score', False), ('class_weight', None), ('n_jobs', 12), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_features_', 1024), ('verbose', 0), ('n_estimators', 1200), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_weight_fraction_leaf', 0.0)]\n",
      "  *FOLD R^2: 0.0237 (MSE: 0.6610; MAE: 0.5703; mean train mae: 0.5873)\n",
      "Fold 4 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1084    Test size: 270]\n",
      " X[0]: (N, features): (1084, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1084, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (270, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('warm_start', False), ('min_impurity_split', 1e-07), ('bootstrap', False), ('max_depth', None), ('n_outputs_', 1), ('random_state', 42), ('min_samples_split', 2), ('min_samples_leaf', 1), ('max_leaf_nodes', None), ('oob_score', False), ('class_weight', None), ('n_jobs', 12), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_features_', 1024), ('verbose', 0), ('n_estimators', 1200), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_weight_fraction_leaf', 0.0)]\n",
      "  *FOLD R^2: -0.1028 (MSE: 0.7930; MAE: 0.6417; mean train mae: 0.6018)\n",
      "/home/karthik9/TheDlatk/dlatk/dlatk/regressionPredictor.py:1398: RuntimeWarning: invalid value encountered in sqrt\n",
      "  reportStats['R'] = sqrt(reportStats['R2'])\n",
      "*Overall R^2:          -0.0138\n",
      "*Overall FOLDS R^2:    -0.0173 (+- 0.0198)\n",
      "*R (sqrt R^2):         nan\n",
      "*Pearson r:            0.1344 (p = 0.00000)\n",
      "*Folds Pearson r:      0.1406 (p = 0.17571)\n",
      "*Spearman rho:         0.1444 (p = 0.00000)\n",
      "*Mean Squared Error:   0.6762\n",
      "*Mean Absolute Error:  0.5978\n",
      "*Train_Mean MAE:       0.1823\n",
      "\n",
      "= CELVAL3 (w/ lang.)=\n",
      "---------------------\n",
      "Fold 0 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('warm_start', False), ('min_impurity_split', 1e-07), ('bootstrap', False), ('max_depth', None), ('n_outputs_', 1), ('random_state', 42), ('min_samples_split', 2), ('min_samples_leaf', 1), ('max_leaf_nodes', None), ('oob_score', False), ('class_weight', None), ('n_jobs', 12), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_features_', 1024), ('verbose', 0), ('n_estimators', 1200), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_weight_fraction_leaf', 0.0)]\n",
      "  *FOLD R^2: 0.0747 (MSE: 0.7425; MAE: 0.6318; mean train mae: 0.6112)\n",
      "Fold 1 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('warm_start', False), ('min_impurity_split', 1e-07), ('bootstrap', False), ('max_depth', None), ('n_outputs_', 1), ('random_state', 42), ('min_samples_split', 2), ('min_samples_leaf', 1), ('max_leaf_nodes', None), ('oob_score', False), ('class_weight', None), ('n_jobs', 12), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_features_', 1024), ('verbose', 0), ('n_estimators', 1200), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_weight_fraction_leaf', 0.0)]\n",
      "  *FOLD R^2: 0.0446 (MSE: 0.7323; MAE: 0.6373; mean train mae: 0.5992)\n",
      "Fold 2 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('warm_start', False), ('min_impurity_split', 1e-07), ('bootstrap', False), ('max_depth', None), ('n_outputs_', 1), ('random_state', 42), ('min_samples_split', 2), ('min_samples_leaf', 1), ('max_leaf_nodes', None), ('oob_score', False), ('class_weight', None), ('n_jobs', 12), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_features_', 1024), ('verbose', 0), ('n_estimators', 1200), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_weight_fraction_leaf', 0.0)]\n",
      "  *FOLD R^2: 0.0213 (MSE: 0.7908; MAE: 0.6235; mean train mae: 0.5911)\n",
      "Fold 3 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('warm_start', False), ('min_impurity_split', 1e-07), ('bootstrap', False), ('max_depth', None), ('n_outputs_', 1), ('random_state', 42), ('min_samples_split', 2), ('min_samples_leaf', 1), ('max_leaf_nodes', None), ('oob_score', False), ('class_weight', None), ('n_jobs', 12), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_features_', 1024), ('verbose', 0), ('n_estimators', 1200), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_weight_fraction_leaf', 0.0)]\n",
      "  *FOLD R^2: -0.0934 (MSE: 0.6506; MAE: 0.5876; mean train mae: 0.4987)\n",
      "Fold 4 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1084    Test size: 270]\n",
      " X[0]: (N, features): (1084, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1084, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (270, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('warm_start', False), ('min_impurity_split', 1e-07), ('bootstrap', False), ('max_depth', None), ('n_outputs_', 1), ('random_state', 42), ('min_samples_split', 2), ('min_samples_leaf', 1), ('max_leaf_nodes', None), ('oob_score', False), ('class_weight', None), ('n_jobs', 12), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_features_', 1024), ('verbose', 0), ('n_estimators', 1200), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_weight_fraction_leaf', 0.0)]\n",
      "  *FOLD R^2: -0.0555 (MSE: 0.8873; MAE: 0.6831; mean train mae: 0.6132)\n",
      "*Overall R^2:          0.0111\n",
      "*Overall FOLDS R^2:    -0.0017 (+- 0.0282)\n",
      "*R (sqrt R^2):         0.1056\n",
      "*Pearson r:            0.1752 (p = 0.00000)\n",
      "*Folds Pearson r:      0.1768 (p = 0.11515)\n",
      "*Spearman rho:         0.1791 (p = 0.00000)\n",
      "*Mean Squared Error:   0.7606\n",
      "*Mean Absolute Error:  0.6326\n",
      "*Train_Mean MAE:       0.2027\n",
      "\n",
      "= CEL_Total (w/ lang.)=\n",
      "-----------------------\n",
      "Fold 0 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('warm_start', False), ('min_impurity_split', 1e-07), ('bootstrap', False), ('max_depth', None), ('n_outputs_', 1), ('random_state', 42), ('min_samples_split', 2), ('min_samples_leaf', 1), ('max_leaf_nodes', None), ('oob_score', False), ('class_weight', None), ('n_jobs', 12), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_features_', 1024), ('verbose', 0), ('n_estimators', 1200), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_weight_fraction_leaf', 0.0)]\n",
      "  *FOLD R^2: 0.0806 (MSE: 3.7297; MAE: 1.4236; mean train mae: 1.5187)\n",
      "Fold 1 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('warm_start', False), ('min_impurity_split', 1e-07), ('bootstrap', False), ('max_depth', None), ('n_outputs_', 1), ('random_state', 42), ('min_samples_split', 2), ('min_samples_leaf', 1), ('max_leaf_nodes', None), ('oob_score', False), ('class_weight', None), ('n_jobs', 12), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_features_', 1024), ('verbose', 0), ('n_estimators', 1200), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_weight_fraction_leaf', 0.0)]\n",
      "  *FOLD R^2: 0.0139 (MSE: 3.6895; MAE: 1.5337; mean train mae: 1.5526)\n",
      "Fold 2 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('warm_start', False), ('min_impurity_split', 1e-07), ('bootstrap', False), ('max_depth', None), ('n_outputs_', 1), ('random_state', 42), ('min_samples_split', 2), ('min_samples_leaf', 1), ('max_leaf_nodes', None), ('oob_score', False), ('class_weight', None), ('n_jobs', 12), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_features_', 1024), ('verbose', 0), ('n_estimators', 1200), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_weight_fraction_leaf', 0.0)]\n",
      "  *FOLD R^2: 0.0284 (MSE: 3.5626; MAE: 1.4491; mean train mae: 1.4633)\n",
      "Fold 3 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('warm_start', False), ('min_impurity_split', 1e-07), ('bootstrap', False), ('max_depth', None), ('n_outputs_', 1), ('random_state', 42), ('min_samples_split', 2), ('min_samples_leaf', 1), ('max_leaf_nodes', None), ('oob_score', False), ('class_weight', None), ('n_jobs', 12), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_features_', 1024), ('verbose', 0), ('n_estimators', 1200), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_weight_fraction_leaf', 0.0)]\n",
      "  *FOLD R^2: -0.0125 (MSE: 3.5983; MAE: 1.4589; mean train mae: 1.4227)\n",
      "Fold 4 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1084    Test size: 270]\n",
      " X[0]: (N, features): (1084, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1084, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (270, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('warm_start', False), ('min_impurity_split', 1e-07), ('bootstrap', False), ('max_depth', None), ('n_outputs_', 1), ('random_state', 42), ('min_samples_split', 2), ('min_samples_leaf', 1), ('max_leaf_nodes', None), ('oob_score', False), ('class_weight', None), ('n_jobs', 12), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_features_', 1024), ('verbose', 0), ('n_estimators', 1200), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_weight_fraction_leaf', 0.0)]\n",
      "  *FOLD R^2: -0.0683 (MSE: 4.4566; MAE: 1.5806; mean train mae: 1.4868)\n",
      "*Overall R^2:          0.0130\n",
      "*Overall FOLDS R^2:    0.0084 (+- 0.0219)\n",
      "*R (sqrt R^2):         0.1138\n",
      "*Pearson r:            0.1920 (p = 0.00000)\n",
      "*Folds Pearson r:      0.1911 (p = 0.10053)\n",
      "*Spearman rho:         0.1864 (p = 0.00000)\n",
      "*Mean Squared Error:   3.8069\n",
      "*Mean Absolute Error:  1.4891\n",
      "*Train_Mean MAE:       0.4977\n",
      "\n",
      "[TEST COMPLETE]\n",
      "\n",
      "{'CELVAL1': {(): {1: {'N': 1354,\n",
      "                      'R': nan,\n",
      "                      'R2': -0.03877651600486498,\n",
      "                      'R2_folds': -0.045284123297962518,\n",
      "                      'mae': 0.56169128508124078,\n",
      "                      'mae_folds': 0.5616950116167827,\n",
      "                      'mse': 0.59590903700968323,\n",
      "                      'mse_folds': 0.59592727619091002,\n",
      "                      'num_features': 1024,\n",
      "                      'r': 0.090555536180329202,\n",
      "                      'r_folds': 0.095913840859948848,\n",
      "                      'r_p': 0.00085015585577193965,\n",
      "                      'r_p_folds': 0.33319426311210859,\n",
      "                      'rho': 0.09070247105354573,\n",
      "                      'rho_folds': 0.091749778285107844,\n",
      "                      'rho_p': 0.00083368470553715312,\n",
      "                      'rho_p_folds': 0.20244080120878269,\n",
      "                      'se_R2_folds': 0.020109339106523155,\n",
      "                      'se_mae_folds': 0.022115137427925324,\n",
      "                      'se_mse_folds': 0.047940114968422418,\n",
      "                      'se_r_folds': 0.042037036994597522,\n",
      "                      'se_r_p_folds': 0.17406409848858839,\n",
      "                      'se_rho_folds': 0.050683653279906572,\n",
      "                      'se_rho_p_folds': 0.11374852570168446,\n",
      "                      'se_train_mean_mae_folds': 0.020099823370732458,\n",
      "                      'test_size': 270,\n",
      "                      'train_mean_mae': 0.1725893444810751,\n",
      "                      'train_mean_mae_folds': 0.55992981093245831,\n",
      "                      'train_size': 1084,\n",
      "                      '{modelFS_desc}': 'None',\n",
      "                      '{model_desc}': 'ExtraTreesRegressor(bootstrap=False, '\n",
      "                                      \"criterion='mse', max_depth=None,      \"\n",
      "                                      \"max_features='auto', \"\n",
      "                                      'max_leaf_nodes=None,      '\n",
      "                                      'min_impurity_split=1e-07, '\n",
      "                                      'min_samples_leaf=1,      '\n",
      "                                      'min_samples_split=2, '\n",
      "                                      'min_weight_fraction_leaf=0.0,      '\n",
      "                                      'n_estimators=1200, n_jobs=12, '\n",
      "                                      'oob_score=False, random_state=42,      '\n",
      "                                      'verbose=0, warm_start=False)'}}},\n",
      " 'CELVAL2': {(): {1: {'N': 1354,\n",
      "                      'R': nan,\n",
      "                      'R2': -0.013808050390300863,\n",
      "                      'R2_folds': -0.017321819797554604,\n",
      "                      'mae': 0.59782496307237809,\n",
      "                      'mae_folds': 0.59785731857318569,\n",
      "                      'mse': 0.67623166235844423,\n",
      "                      'mse_folds': 0.676317860678329,\n",
      "                      'num_features': 1024,\n",
      "                      'r': 0.13435067288276839,\n",
      "                      'r_folds': 0.14055830928884455,\n",
      "                      'r_p': 6.9911056480509433e-07,\n",
      "                      'r_p_folds': 0.17570844760614215,\n",
      "                      'rho': 0.14441682593568256,\n",
      "                      'rho_folds': 0.14417196701460946,\n",
      "                      'rho_p': 9.4412969459142236e-08,\n",
      "                      'rho_p_folds': 0.076954730500838175,\n",
      "                      'se_R2_folds': 0.019769516715076041,\n",
      "                      'se_mae_folds': 0.012490857041535252,\n",
      "                      'se_mse_folds': 0.030550935451979278,\n",
      "                      'se_r_folds': 0.032241694632344269,\n",
      "                      'se_r_p_folds': 0.14672942265685898,\n",
      "                      'se_rho_folds': 0.044731262178986139,\n",
      "                      'se_rho_p_folds': 0.067158212337071435,\n",
      "                      'se_train_mean_mae_folds': 0.0070485642108612618,\n",
      "                      'test_size': 270,\n",
      "                      'train_mean_mae': 0.18227236330234398,\n",
      "                      'train_mean_mae_folds': 0.59809211046865773,\n",
      "                      'train_size': 1084,\n",
      "                      '{modelFS_desc}': 'None',\n",
      "                      '{model_desc}': 'ExtraTreesRegressor(bootstrap=False, '\n",
      "                                      \"criterion='mse', max_depth=None,      \"\n",
      "                                      \"max_features='auto', \"\n",
      "                                      'max_leaf_nodes=None,      '\n",
      "                                      'min_impurity_split=1e-07, '\n",
      "                                      'min_samples_leaf=1,      '\n",
      "                                      'min_samples_split=2, '\n",
      "                                      'min_weight_fraction_leaf=0.0,      '\n",
      "                                      'n_estimators=1200, n_jobs=12, '\n",
      "                                      'oob_score=False, random_state=42,      '\n",
      "                                      'verbose=0, warm_start=False)'}}},\n",
      " 'CELVAL3': {(): {1: {'N': 1354,\n",
      "                      'R': 0.10559207958742579,\n",
      "                      'R2': 0.011149687271597264,\n",
      "                      'R2_folds': -0.0016641439403803026,\n",
      "                      'mae': 0.63263970950270798,\n",
      "                      'mae_folds': 0.63267698282538387,\n",
      "                      'mse': 0.7606071193377647,\n",
      "                      'mse_folds': 0.76070061131041877,\n",
      "                      'num_features': 1024,\n",
      "                      'r': 0.17520610047079138,\n",
      "                      'r_folds': 0.17682598211429332,\n",
      "                      'r_p': 8.5080868820097467e-11,\n",
      "                      'r_p_folds': 0.11514604101581227,\n",
      "                      'rho': 0.17908192126009959,\n",
      "                      'rho_folds': 0.18222406894307555,\n",
      "                      'rho_p': 3.1954749955873209e-11,\n",
      "                      'rho_p_folds': 0.16283806939710727,\n",
      "                      'se_R2_folds': 0.0281615312708322,\n",
      "                      'se_mae_folds': 0.013689059200008857,\n",
      "                      'se_mse_folds': 0.034753314539292736,\n",
      "                      'se_r_folds': 0.038827026739731492,\n",
      "                      'se_r_p_folds': 0.09719776624904819,\n",
      "                      'se_rho_folds': 0.049290951718803516,\n",
      "                      'se_rho_p_folds': 0.14477332574932109,\n",
      "                      'se_train_mean_mae_folds': 0.019128562080640201,\n",
      "                      'test_size': 270,\n",
      "                      'train_mean_mae': 0.20267989897359032,\n",
      "                      'train_mean_mae_folds': 0.58268000713248136,\n",
      "                      'train_size': 1084,\n",
      "                      '{modelFS_desc}': 'None',\n",
      "                      '{model_desc}': 'ExtraTreesRegressor(bootstrap=False, '\n",
      "                                      \"criterion='mse', max_depth=None,      \"\n",
      "                                      \"max_features='auto', \"\n",
      "                                      'max_leaf_nodes=None,      '\n",
      "                                      'min_impurity_split=1e-07, '\n",
      "                                      'min_samples_leaf=1,      '\n",
      "                                      'min_samples_split=2, '\n",
      "                                      'min_weight_fraction_leaf=0.0,      '\n",
      "                                      'n_estimators=1200, n_jobs=12, '\n",
      "                                      'oob_score=False, random_state=42,      '\n",
      "                                      'verbose=0, warm_start=False)'}}},\n",
      " 'CEL_Total': {(): {1: {'N': 1354,\n",
      "                        'R': 0.1138305776064002,\n",
      "                        'R2': 0.012957400398206698,\n",
      "                        'R2_folds': 0.0084169807970476233,\n",
      "                        'mae': 1.4891125061546036,\n",
      "                        'mae_folds': 1.489180037355929,\n",
      "                        'mse': 3.806896885770557,\n",
      "                        'mse_folds': 3.8073764082463972,\n",
      "                        'num_features': 1024,\n",
      "                        'r': 0.19202454096083177,\n",
      "                        'r_folds': 0.19109267064256807,\n",
      "                        'r_p': 1.03505188195668e-12,\n",
      "                        'r_p_folds': 0.10052767245218357,\n",
      "                        'rho': 0.18636157674584006,\n",
      "                        'rho_folds': 0.18947579500417028,\n",
      "                        'rho_p': 4.7853931124663447e-12,\n",
      "                        'rho_p_folds': 0.10537692754375094,\n",
      "                        'se_R2_folds': 0.021880704991407509,\n",
      "                        'se_mae_folds': 0.026201316168297389,\n",
      "                        'se_mse_folds': 0.14765703080612624,\n",
      "                        'se_r_folds': 0.036425855549797943,\n",
      "                        'se_r_p_folds': 0.089474088017628683,\n",
      "                        'se_rho_folds': 0.055741222397297188,\n",
      "                        'se_rho_p_folds': 0.093977670783324488,\n",
      "                        'se_train_mean_mae_folds': 0.019988829500618786,\n",
      "                        'test_size': 270,\n",
      "                        'train_mean_mae': 0.49773004944774019,\n",
      "                        'train_mean_mae_folds': 1.4888360464398736,\n",
      "                        'train_size': 1084,\n",
      "                        '{modelFS_desc}': 'None',\n",
      "                        '{model_desc}': 'ExtraTreesRegressor(bootstrap=False, '\n",
      "                                        \"criterion='mse', max_depth=None,      \"\n",
      "                                        \"max_features='auto', \"\n",
      "                                        'max_leaf_nodes=None,      '\n",
      "                                        'min_impurity_split=1e-07, '\n",
      "                                        'min_samples_leaf=1,      '\n",
      "                                        'min_samples_split=2, '\n",
      "                                        'min_weight_fraction_leaf=0.0,      '\n",
      "                                        'n_estimators=1200, n_jobs=12, '\n",
      "                                        'oob_score=False, '\n",
      "                                        'random_state=42,      verbose=0, '\n",
      "                                        'warm_start=False)'}}}}\n",
      "-------\n",
      "Settings:\n",
      "\n",
      "Database - Audio_features\n",
      "Corpus - merged_data\n",
      "Group ID - message_id\n",
      "Feature table(s) - feat$trill_mean$merged_data$message_id\n",
      "Outcome table - merged_data\n",
      "Outcome(s) - CEL_Total CELVAL1 CELVAL2 CELVAL3\n",
      "-------\n",
      "Interface Runtime: 505.71 seconds\n",
      "DLATK exits with success! A good day indeed  ¯\\_(ツ)_/¯.\n"
     ]
    }
   ],
   "source": [
    "!python /home/karthik9/TheDlatk/dlatk/dlatkInterface.py -d Audio_features -t merged_data -c message_id \\\n",
    "-f 'feat$trill_mean$merged_data$message_id ' \\\n",
    "    --outcome_table merged_data  --group_freq_thresh 10 \\\n",
    "    --outcomes CEL_Total CELVAL1 CELVAL2 CELVAL3 \\\n",
    "    --nfold_test_regression --model extratrees --fold_column fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "/data/anaconda2/envs/dlatk/lib/python3.5/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n",
      "\n",
      "-----\n",
      "DLATK Interface Initiated: 2025-02-06 19:00:40\n",
      "-----\n",
      "Loading Outcomes and Getting Groups for: {'CELVAL1', 'CELVAL3', 'CEL_Total', 'CELVAL2'}\n",
      "    ***explicit fold labels specified, not splitting again***\n",
      "[number of groups: 1354 (5 Folds)]\n",
      "\n",
      "\n",
      "|COMBO: ()|\n",
      "===========\n",
      "\n",
      "= CELVAL1 (w/ lang.)=\n",
      "---------------------\n",
      "Fold 0 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('n_estimators', 1200), ('min_samples_leaf', 1), ('oob_score', False), ('max_leaf_nodes', None), ('n_features_', 1024), ('class_weight', None), ('min_samples_split', 2), ('bootstrap', False), ('min_impurity_split', 1e-07), ('warm_start', False), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('verbose', 0), ('random_state', 42), ('n_jobs', 12), ('max_depth', None), ('min_weight_fraction_leaf', 0.0), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_outputs_', 1)]\n",
      "  *FOLD R^2: 0.0508 (MSE: 0.6638; MAE: 0.5556; mean train mae: 0.6021)\n",
      "Fold 1 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('n_estimators', 1200), ('min_samples_leaf', 1), ('oob_score', False), ('max_leaf_nodes', None), ('n_features_', 1024), ('class_weight', None), ('min_samples_split', 2), ('bootstrap', False), ('min_impurity_split', 1e-07), ('warm_start', False), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('verbose', 0), ('random_state', 42), ('n_jobs', 12), ('max_depth', None), ('min_weight_fraction_leaf', 0.0), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_outputs_', 1)]\n",
      "  *FOLD R^2: -0.0465 (MSE: 0.7067; MAE: 0.6239; mean train mae: 0.6184)\n",
      "Fold 2 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('n_estimators', 1200), ('min_samples_leaf', 1), ('oob_score', False), ('max_leaf_nodes', None), ('n_features_', 1024), ('class_weight', None), ('min_samples_split', 2), ('bootstrap', False), ('min_impurity_split', 1e-07), ('warm_start', False), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('verbose', 0), ('random_state', 42), ('n_jobs', 12), ('max_depth', None), ('min_weight_fraction_leaf', 0.0), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_outputs_', 1)]\n",
      "  *FOLD R^2: -0.0233 (MSE: 0.4245; MAE: 0.4883; mean train mae: 0.4947)\n",
      "Fold 3 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('n_estimators', 1200), ('min_samples_leaf', 1), ('oob_score', False), ('max_leaf_nodes', None), ('n_features_', 1024), ('class_weight', None), ('min_samples_split', 2), ('bootstrap', False), ('min_impurity_split', 1e-07), ('warm_start', False), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('verbose', 0), ('random_state', 42), ('n_jobs', 12), ('max_depth', None), ('min_weight_fraction_leaf', 0.0), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_outputs_', 1)]\n",
      "  *FOLD R^2: -0.0031 (MSE: 0.5004; MAE: 0.5180; mean train mae: 0.5390)\n",
      "Fold 4 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1084    Test size: 270]\n",
      " X[0]: (N, features): (1084, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1084, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (270, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('n_estimators', 1200), ('min_samples_leaf', 1), ('oob_score', False), ('max_leaf_nodes', None), ('n_features_', 1024), ('class_weight', None), ('min_samples_split', 2), ('bootstrap', False), ('min_impurity_split', 1e-07), ('warm_start', False), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('verbose', 0), ('random_state', 42), ('n_jobs', 12), ('max_depth', None), ('min_weight_fraction_leaf', 0.0), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_outputs_', 1)]\n",
      "  *FOLD R^2: -0.0436 (MSE: 0.5932; MAE: 0.5356; mean train mae: 0.5454)\n",
      "/home/karthik9/TheDlatk/dlatk/dlatk/regressionPredictor.py:1398: RuntimeWarning: invalid value encountered in sqrt\n",
      "  reportStats['R'] = sqrt(reportStats['R2'])\n",
      "*Overall R^2:          -0.0071\n",
      "*Overall FOLDS R^2:    -0.0131 (+- 0.0159)\n",
      "*R (sqrt R^2):         nan\n",
      "*Pearson r:            0.1039 (p = 0.00013)\n",
      "*Folds Pearson r:      0.1081 (p = 0.36366)\n",
      "*Spearman rho:         0.1341 (p = 0.00000)\n",
      "*Mean Squared Error:   0.5777\n",
      "*Mean Absolute Error:  0.5443\n",
      "*Train_Mean MAE:       0.1398\n",
      "\n",
      "= CELVAL2 (w/ lang.)=\n",
      "---------------------\n",
      "Fold 0 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('n_estimators', 1200), ('min_samples_leaf', 1), ('oob_score', False), ('max_leaf_nodes', None), ('n_features_', 1024), ('class_weight', None), ('min_samples_split', 2), ('bootstrap', False), ('min_impurity_split', 1e-07), ('warm_start', False), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('verbose', 0), ('random_state', 42), ('n_jobs', 12), ('max_depth', None), ('min_weight_fraction_leaf', 0.0), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_outputs_', 1)]\n",
      "  *FOLD R^2: 0.0580 (MSE: 0.5800; MAE: 0.5416; mean train mae: 0.5735)\n",
      "Fold 1 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('n_estimators', 1200), ('min_samples_leaf', 1), ('oob_score', False), ('max_leaf_nodes', None), ('n_features_', 1024), ('class_weight', None), ('min_samples_split', 2), ('bootstrap', False), ('min_impurity_split', 1e-07), ('warm_start', False), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('verbose', 0), ('random_state', 42), ('n_jobs', 12), ('max_depth', None), ('min_weight_fraction_leaf', 0.0), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_outputs_', 1)]\n",
      "  *FOLD R^2: -0.0058 (MSE: 0.6085; MAE: 0.6001; mean train mae: 0.6141)\n",
      "Fold 2 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('n_estimators', 1200), ('min_samples_leaf', 1), ('oob_score', False), ('max_leaf_nodes', None), ('n_features_', 1024), ('class_weight', None), ('min_samples_split', 2), ('bootstrap', False), ('min_impurity_split', 1e-07), ('warm_start', False), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('verbose', 0), ('random_state', 42), ('n_jobs', 12), ('max_depth', None), ('min_weight_fraction_leaf', 0.0), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_outputs_', 1)]\n",
      "  *FOLD R^2: 0.0008 (MSE: 0.7011; MAE: 0.6108; mean train mae: 0.6139)\n",
      "Fold 3 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('n_estimators', 1200), ('min_samples_leaf', 1), ('oob_score', False), ('max_leaf_nodes', None), ('n_features_', 1024), ('class_weight', None), ('min_samples_split', 2), ('bootstrap', False), ('min_impurity_split', 1e-07), ('warm_start', False), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('verbose', 0), ('random_state', 42), ('n_jobs', 12), ('max_depth', None), ('min_weight_fraction_leaf', 0.0), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_outputs_', 1)]\n",
      "  *FOLD R^2: 0.0442 (MSE: 0.6472; MAE: 0.5658; mean train mae: 0.5873)\n",
      "Fold 4 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1084    Test size: 270]\n",
      " X[0]: (N, features): (1084, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1084, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (270, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('n_estimators', 1200), ('min_samples_leaf', 1), ('oob_score', False), ('max_leaf_nodes', None), ('n_features_', 1024), ('class_weight', None), ('min_samples_split', 2), ('bootstrap', False), ('min_impurity_split', 1e-07), ('warm_start', False), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('verbose', 0), ('random_state', 42), ('n_jobs', 12), ('max_depth', None), ('min_weight_fraction_leaf', 0.0), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_outputs_', 1)]\n",
      "  *FOLD R^2: -0.0491 (MSE: 0.7544; MAE: 0.6163; mean train mae: 0.6018)\n",
      "*Overall R^2:          0.0132\n",
      "*Overall FOLDS R^2:    0.0096 (+- 0.0171)\n",
      "*R (sqrt R^2):         0.1150\n",
      "*Pearson r:            0.1479 (p = 0.00000)\n",
      "*Folds Pearson r:      0.1575 (p = 0.14814)\n",
      "*Spearman rho:         0.1402 (p = 0.00000)\n",
      "*Mean Squared Error:   0.6582\n",
      "*Mean Absolute Error:  0.5869\n",
      "*Train_Mean MAE:       0.1380\n",
      "\n",
      "= CELVAL3 (w/ lang.)=\n",
      "---------------------\n",
      "Fold 0 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('n_estimators', 1200), ('min_samples_leaf', 1), ('oob_score', False), ('max_leaf_nodes', None), ('n_features_', 1024), ('class_weight', None), ('min_samples_split', 2), ('bootstrap', False), ('min_impurity_split', 1e-07), ('warm_start', False), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('verbose', 0), ('random_state', 42), ('n_jobs', 12), ('max_depth', None), ('min_weight_fraction_leaf', 0.0), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_outputs_', 1)]\n",
      "  *FOLD R^2: 0.1004 (MSE: 0.7219; MAE: 0.6084; mean train mae: 0.6112)\n",
      "Fold 1 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('n_estimators', 1200), ('min_samples_leaf', 1), ('oob_score', False), ('max_leaf_nodes', None), ('n_features_', 1024), ('class_weight', None), ('min_samples_split', 2), ('bootstrap', False), ('min_impurity_split', 1e-07), ('warm_start', False), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('verbose', 0), ('random_state', 42), ('n_jobs', 12), ('max_depth', None), ('min_weight_fraction_leaf', 0.0), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_outputs_', 1)]\n",
      "  *FOLD R^2: 0.0487 (MSE: 0.7292; MAE: 0.6245; mean train mae: 0.5992)\n",
      "Fold 2 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('n_estimators', 1200), ('min_samples_leaf', 1), ('oob_score', False), ('max_leaf_nodes', None), ('n_features_', 1024), ('class_weight', None), ('min_samples_split', 2), ('bootstrap', False), ('min_impurity_split', 1e-07), ('warm_start', False), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('verbose', 0), ('random_state', 42), ('n_jobs', 12), ('max_depth', None), ('min_weight_fraction_leaf', 0.0), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_outputs_', 1)]\n",
      "  *FOLD R^2: 0.0346 (MSE: 0.7800; MAE: 0.6100; mean train mae: 0.5911)\n",
      "Fold 3 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('n_estimators', 1200), ('min_samples_leaf', 1), ('oob_score', False), ('max_leaf_nodes', None), ('n_features_', 1024), ('class_weight', None), ('min_samples_split', 2), ('bootstrap', False), ('min_impurity_split', 1e-07), ('warm_start', False), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('verbose', 0), ('random_state', 42), ('n_jobs', 12), ('max_depth', None), ('min_weight_fraction_leaf', 0.0), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_outputs_', 1)]\n",
      "  *FOLD R^2: -0.0700 (MSE: 0.6366; MAE: 0.5644; mean train mae: 0.4987)\n",
      "Fold 4 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1084    Test size: 270]\n",
      " X[0]: (N, features): (1084, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1084, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (270, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('n_estimators', 1200), ('min_samples_leaf', 1), ('oob_score', False), ('max_leaf_nodes', None), ('n_features_', 1024), ('class_weight', None), ('min_samples_split', 2), ('bootstrap', False), ('min_impurity_split', 1e-07), ('warm_start', False), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('verbose', 0), ('random_state', 42), ('n_jobs', 12), ('max_depth', None), ('min_weight_fraction_leaf', 0.0), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_outputs_', 1)]\n",
      "  *FOLD R^2: -0.0579 (MSE: 0.8893; MAE: 0.6652; mean train mae: 0.6132)\n",
      "*Overall R^2:          0.0233\n",
      "*Overall FOLDS R^2:    0.0112 (+- 0.0292)\n",
      "*R (sqrt R^2):         0.1525\n",
      "*Pearson r:            0.1723 (p = 0.00000)\n",
      "*Folds Pearson r:      0.1859 (p = 0.14674)\n",
      "*Spearman rho:         0.1971 (p = 0.00000)\n",
      "*Mean Squared Error:   0.7513\n",
      "*Mean Absolute Error:  0.6144\n",
      "*Train_Mean MAE:       0.1691\n",
      "\n",
      "= CEL_Total (w/ lang.)=\n",
      "-----------------------\n",
      "Fold 0 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('n_estimators', 1200), ('min_samples_leaf', 1), ('oob_score', False), ('max_leaf_nodes', None), ('n_features_', 1024), ('class_weight', None), ('min_samples_split', 2), ('bootstrap', False), ('min_impurity_split', 1e-07), ('warm_start', False), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('verbose', 0), ('random_state', 42), ('n_jobs', 12), ('max_depth', None), ('min_weight_fraction_leaf', 0.0), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_outputs_', 1)]\n",
      "  *FOLD R^2: 0.1124 (MSE: 3.6005; MAE: 1.3863; mean train mae: 1.5187)\n",
      "Fold 1 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('n_estimators', 1200), ('min_samples_leaf', 1), ('oob_score', False), ('max_leaf_nodes', None), ('n_features_', 1024), ('class_weight', None), ('min_samples_split', 2), ('bootstrap', False), ('min_impurity_split', 1e-07), ('warm_start', False), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('verbose', 0), ('random_state', 42), ('n_jobs', 12), ('max_depth', None), ('min_weight_fraction_leaf', 0.0), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_outputs_', 1)]\n",
      "  *FOLD R^2: 0.0217 (MSE: 3.6605; MAE: 1.5161; mean train mae: 1.5526)\n",
      "Fold 2 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('n_estimators', 1200), ('min_samples_leaf', 1), ('oob_score', False), ('max_leaf_nodes', None), ('n_features_', 1024), ('class_weight', None), ('min_samples_split', 2), ('bootstrap', False), ('min_impurity_split', 1e-07), ('warm_start', False), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('verbose', 0), ('random_state', 42), ('n_jobs', 12), ('max_depth', None), ('min_weight_fraction_leaf', 0.0), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_outputs_', 1)]\n",
      "  *FOLD R^2: 0.0530 (MSE: 3.4726; MAE: 1.4246; mean train mae: 1.4633)\n",
      "Fold 3 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('n_estimators', 1200), ('min_samples_leaf', 1), ('oob_score', False), ('max_leaf_nodes', None), ('n_features_', 1024), ('class_weight', None), ('min_samples_split', 2), ('bootstrap', False), ('min_impurity_split', 1e-07), ('warm_start', False), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('verbose', 0), ('random_state', 42), ('n_jobs', 12), ('max_depth', None), ('min_weight_fraction_leaf', 0.0), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_outputs_', 1)]\n",
      "  *FOLD R^2: 0.0170 (MSE: 3.4934; MAE: 1.3938; mean train mae: 1.4227)\n",
      "Fold 4 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1084    Test size: 270]\n",
      " X[0]: (N, features): (1084, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1084, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (270, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('n_estimators', 1200), ('min_samples_leaf', 1), ('oob_score', False), ('max_leaf_nodes', None), ('n_features_', 1024), ('class_weight', None), ('min_samples_split', 2), ('bootstrap', False), ('min_impurity_split', 1e-07), ('warm_start', False), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('verbose', 0), ('random_state', 42), ('n_jobs', 12), ('max_depth', None), ('min_weight_fraction_leaf', 0.0), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_outputs_', 1)]\n",
      "  *FOLD R^2: -0.0563 (MSE: 4.4066; MAE: 1.5184; mean train mae: 1.4868)\n",
      "*Overall R^2:          0.0339\n",
      "*Overall FOLDS R^2:    0.0296 (+- 0.0245)\n",
      "*R (sqrt R^2):         0.1840\n",
      "*Pearson r:            0.1996 (p = 0.00000)\n",
      "*Folds Pearson r:      0.2056 (p = 0.18309)\n",
      "*Spearman rho:         0.2103 (p = 0.00000)\n",
      "*Mean Squared Error:   3.7262\n",
      "*Mean Absolute Error:  1.4478\n",
      "*Train_Mean MAE:       0.4004\n",
      "\n",
      "[TEST COMPLETE]\n",
      "\n",
      "{'CELVAL1': {(): {1: {'N': 1354,\n",
      "                      'R': nan,\n",
      "                      'R2': -0.0070653621220593266,\n",
      "                      'R2_folds': -0.013133571427495183,\n",
      "                      'mae': 0.5442848350566224,\n",
      "                      'mae_folds': 0.54427842239533508,\n",
      "                      'mse': 0.57771747907434756,\n",
      "                      'mse_folds': 0.57772887837114484,\n",
      "                      'num_features': 1024,\n",
      "                      'r': 0.10392915570424198,\n",
      "                      'r_folds': 0.10809969403399231,\n",
      "                      'r_p': 0.00012757132424697615,\n",
      "                      'r_p_folds': 0.36365523716202758,\n",
      "                      'rho': 0.1341053364483753,\n",
      "                      'rho_folds': 0.1425717961575344,\n",
      "                      'rho_p': 7.3278327574555967e-07,\n",
      "                      'rho_p_folds': 0.35398649602874444,\n",
      "                      'se_R2_folds': 0.01590926585788096,\n",
      "                      'se_mae_folds': 0.020363037253283547,\n",
      "                      'se_mse_folds': 0.046365263482440605,\n",
      "                      'se_r_folds': 0.043426912591033727,\n",
      "                      'se_r_p_folds': 0.18364857400841458,\n",
      "                      'se_rho_folds': 0.057793708457407555,\n",
      "                      'se_rho_p_folds': 0.18208728896514376,\n",
      "                      'se_train_mean_mae_folds': 0.020099823370732468,\n",
      "                      'test_size': 270,\n",
      "                      'train_mean_mae': 0.13975048855007355,\n",
      "                      'train_mean_mae_folds': 0.55992981093245831,\n",
      "                      'train_size': 1084,\n",
      "                      '{modelFS_desc}': 'None',\n",
      "                      '{model_desc}': 'ExtraTreesRegressor(bootstrap=False, '\n",
      "                                      \"criterion='mse', max_depth=None,      \"\n",
      "                                      \"max_features='auto', \"\n",
      "                                      'max_leaf_nodes=None,      '\n",
      "                                      'min_impurity_split=1e-07, '\n",
      "                                      'min_samples_leaf=1,      '\n",
      "                                      'min_samples_split=2, '\n",
      "                                      'min_weight_fraction_leaf=0.0,      '\n",
      "                                      'n_estimators=1200, n_jobs=12, '\n",
      "                                      'oob_score=False, random_state=42,      '\n",
      "                                      'verbose=0, warm_start=False)'}}},\n",
      " 'CELVAL2': {(): {1: {'N': 1354,\n",
      "                      'R': 0.11503295388311534,\n",
      "                      'R2': 0.01323258047907494,\n",
      "                      'R2_folds': 0.0095934897204832843,\n",
      "                      'mae': 0.58689438700147711,\n",
      "                      'mae_folds': 0.58691610177212883,\n",
      "                      'mse': 0.6581949829722632,\n",
      "                      'mse_folds': 0.65826601748781377,\n",
      "                      'num_features': 1024,\n",
      "                      'r': 0.14792187890127662,\n",
      "                      'r_folds': 0.15745600055345385,\n",
      "                      'r_p': 4.5482745377305108e-08,\n",
      "                      'r_p_folds': 0.14814165230220627,\n",
      "                      'rho': 0.14019737842467142,\n",
      "                      'rho_folds': 0.14347581550184313,\n",
      "                      'rho_p': 2.2231134024302334e-07,\n",
      "                      'rho_p_folds': 0.18131026730496735,\n",
      "                      'se_R2_folds': 0.017084103077805515,\n",
      "                      'se_mae_folds': 0.012819827661938154,\n",
      "                      'se_mse_folds': 0.028146352719566635,\n",
      "                      'se_r_folds': 0.035335157560158564,\n",
      "                      'se_r_p_folds': 0.1163190255240073,\n",
      "                      'se_rho_folds': 0.042017670294737838,\n",
      "                      'se_rho_p_folds': 0.14110352841844478,\n",
      "                      'se_train_mean_mae_folds': 0.007048564210861287,\n",
      "                      'test_size': 270,\n",
      "                      'train_mean_mae': 0.13801187029404643,\n",
      "                      'train_mean_mae_folds': 0.59809211046865773,\n",
      "                      'train_size': 1084,\n",
      "                      '{modelFS_desc}': 'None',\n",
      "                      '{model_desc}': 'ExtraTreesRegressor(bootstrap=False, '\n",
      "                                      \"criterion='mse', max_depth=None,      \"\n",
      "                                      \"max_features='auto', \"\n",
      "                                      'max_leaf_nodes=None,      '\n",
      "                                      'min_impurity_split=1e-07, '\n",
      "                                      'min_samples_leaf=1,      '\n",
      "                                      'min_samples_split=2, '\n",
      "                                      'min_weight_fraction_leaf=0.0,      '\n",
      "                                      'n_estimators=1200, n_jobs=12, '\n",
      "                                      'oob_score=False, random_state=42,      '\n",
      "                                      'verbose=0, warm_start=False)'}}},\n",
      " 'CELVAL3': {(): {1: {'N': 1354,\n",
      "                      'R': 0.15248327932781733,\n",
      "                      'R2': 0.023251150474565163,\n",
      "                      'R2_folds': 0.011176823936977231,\n",
      "                      'mae': 0.61444423929098968,\n",
      "                      'mae_folds': 0.61448171837273935,\n",
      "                      'mse': 0.75129887627195147,\n",
      "                      'mse_folds': 0.75140068522314851,\n",
      "                      'num_features': 1024,\n",
      "                      'r': 0.17226900453611721,\n",
      "                      'r_folds': 0.18586555838216268,\n",
      "                      'r_p': 1.7611595759502784e-10,\n",
      "                      'r_p_folds': 0.14674275901614151,\n",
      "                      'rho': 0.19710819779453909,\n",
      "                      'rho_folds': 0.20880816962995255,\n",
      "                      'rho_p': 2.5141682481258128e-13,\n",
      "                      'rho_p_folds': 0.12957798417517535,\n",
      "                      'se_R2_folds': 0.029173311653513705,\n",
      "                      'se_mae_folds': 0.014484416427982018,\n",
      "                      'se_mse_folds': 0.037071060201406637,\n",
      "                      'se_r_folds': 0.05302442603385555,\n",
      "                      'se_r_p_folds': 0.12919519752067959,\n",
      "                      'se_rho_folds': 0.057589089797051997,\n",
      "                      'se_rho_p_folds': 0.11579519339265089,\n",
      "                      'se_train_mean_mae_folds': 0.019128562080640198,\n",
      "                      'test_size': 270,\n",
      "                      'train_mean_mae': 0.16913164179006784,\n",
      "                      'train_mean_mae_folds': 0.58268000713248136,\n",
      "                      'train_size': 1084,\n",
      "                      '{modelFS_desc}': 'None',\n",
      "                      '{model_desc}': 'ExtraTreesRegressor(bootstrap=False, '\n",
      "                                      \"criterion='mse', max_depth=None,      \"\n",
      "                                      \"max_features='auto', \"\n",
      "                                      'max_leaf_nodes=None,      '\n",
      "                                      'min_impurity_split=1e-07, '\n",
      "                                      'min_samples_leaf=1,      '\n",
      "                                      'min_samples_split=2, '\n",
      "                                      'min_weight_fraction_leaf=0.0,      '\n",
      "                                      'n_estimators=1200, n_jobs=12, '\n",
      "                                      'oob_score=False, random_state=42,      '\n",
      "                                      'verbose=0, warm_start=False)'}}},\n",
      " 'CEL_Total': {(): {1: {'N': 1354,\n",
      "                        'R': 0.18404057294635379,\n",
      "                        'R2': 0.033870932490422168,\n",
      "                        'R2_folds': 0.0295512369334082,\n",
      "                        'mae': 1.4478015755785327,\n",
      "                        'mae_folds': 1.4478537105371054,\n",
      "                        'mse': 3.7262360711061877,\n",
      "                        'mse_folds': 3.7267381953100083,\n",
      "                        'num_features': 1024,\n",
      "                        'r': 0.19958259330503031,\n",
      "                        'r_folds': 0.20564415244719472,\n",
      "                        'r_p': 1.2450578652203115e-13,\n",
      "                        'r_p_folds': 0.18308970330123966,\n",
      "                        'rho': 0.21034258040588194,\n",
      "                        'rho_folds': 0.22170310405423818,\n",
      "                        'rho_p': 5.2646052207842921e-15,\n",
      "                        'rho_p_folds': 0.13119189674805234,\n",
      "                        'se_R2_folds': 0.024507524967967889,\n",
      "                        'se_mae_folds': 0.025995042059349459,\n",
      "                        'se_mse_folds': 0.15512180066471112,\n",
      "                        'se_r_folds': 0.049923077358131965,\n",
      "                        'se_r_p_folds': 0.16359392618558255,\n",
      "                        'se_rho_folds': 0.063307210010564025,\n",
      "                        'se_rho_p_folds': 0.11723444304421583,\n",
      "                        'se_train_mean_mae_folds': 0.019988829500618772,\n",
      "                        'test_size': 270,\n",
      "                        'train_mean_mae': 0.40042028760999193,\n",
      "                        'train_mean_mae_folds': 1.4888360464398733,\n",
      "                        'train_size': 1084,\n",
      "                        '{modelFS_desc}': 'None',\n",
      "                        '{model_desc}': 'ExtraTreesRegressor(bootstrap=False, '\n",
      "                                        \"criterion='mse', max_depth=None,      \"\n",
      "                                        \"max_features='auto', \"\n",
      "                                        'max_leaf_nodes=None,      '\n",
      "                                        'min_impurity_split=1e-07, '\n",
      "                                        'min_samples_leaf=1,      '\n",
      "                                        'min_samples_split=2, '\n",
      "                                        'min_weight_fraction_leaf=0.0,      '\n",
      "                                        'n_estimators=1200, n_jobs=12, '\n",
      "                                        'oob_score=False, '\n",
      "                                        'random_state=42,      verbose=0, '\n",
      "                                        'warm_start=False)'}}}}\n",
      "-------\n",
      "Settings:\n",
      "\n",
      "Database - Audio_features\n",
      "Corpus - merged_data\n",
      "Group ID - message_id\n",
      "Feature table(s) - feat$trill_max$merged_data$message_id\n",
      "Outcome table - merged_data\n",
      "Outcome(s) - CEL_Total CELVAL1 CELVAL2 CELVAL3\n",
      "-------\n",
      "Interface Runtime: 548.29 seconds\n",
      "DLATK exits with success! A good day indeed  ¯\\_(ツ)_/¯.\n"
     ]
    }
   ],
   "source": [
    "!python /home/karthik9/TheDlatk/dlatk/dlatkInterface.py -d Audio_features -t merged_data -c message_id \\\n",
    "-f 'feat$trill_max$merged_data$message_id ' \\\n",
    "    --outcome_table merged_data  --group_freq_thresh 10 \\\n",
    "    --outcomes CEL_Total CELVAL1 CELVAL2 CELVAL3 \\\n",
    "    --nfold_test_regression --model extratrees --fold_column fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "/data/anaconda2/envs/dlatk/lib/python3.5/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n",
      "\n",
      "-----\n",
      "DLATK Interface Initiated: 2025-02-06 19:09:54\n",
      "-----\n",
      "Loading Outcomes and Getting Groups for: {'CELVAL1', 'CELVAL3', 'CELVAL2', 'CEL_Total'}\n",
      "    ***explicit fold labels specified, not splitting again***\n",
      "[number of groups: 1354 (5 Folds)]\n",
      "\n",
      "\n",
      "|COMBO: ()|\n",
      "===========\n",
      "\n",
      "= CELVAL1 (w/ lang.)=\n",
      "---------------------\n",
      "Fold 0 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('n_estimators', 1200), ('warm_start', False), ('n_outputs_', 1), ('max_depth', None), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_samples_split', 2), ('min_impurity_split', 1e-07), ('n_features_', 1024), ('verbose', 0), ('min_weight_fraction_leaf', 0.0), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('random_state', 42), ('bootstrap', False), ('min_samples_leaf', 1), ('n_jobs', 12), ('oob_score', False), ('max_leaf_nodes', None), ('class_weight', None)]\n",
      "  *FOLD R^2: 0.0442 (MSE: 0.6684; MAE: 0.5602; mean train mae: 0.6021)\n",
      "Fold 1 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('n_estimators', 1200), ('warm_start', False), ('n_outputs_', 1), ('max_depth', None), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_samples_split', 2), ('min_impurity_split', 1e-07), ('n_features_', 1024), ('verbose', 0), ('min_weight_fraction_leaf', 0.0), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('random_state', 42), ('bootstrap', False), ('min_samples_leaf', 1), ('n_jobs', 12), ('oob_score', False), ('max_leaf_nodes', None), ('class_weight', None)]\n",
      "  *FOLD R^2: -0.0132 (MSE: 0.6843; MAE: 0.6110; mean train mae: 0.6184)\n",
      "Fold 2 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('n_estimators', 1200), ('warm_start', False), ('n_outputs_', 1), ('max_depth', None), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_samples_split', 2), ('min_impurity_split', 1e-07), ('n_features_', 1024), ('verbose', 0), ('min_weight_fraction_leaf', 0.0), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('random_state', 42), ('bootstrap', False), ('min_samples_leaf', 1), ('n_jobs', 12), ('oob_score', False), ('max_leaf_nodes', None), ('class_weight', None)]\n",
      "  *FOLD R^2: 0.0033 (MSE: 0.4135; MAE: 0.4758; mean train mae: 0.4947)\n",
      "Fold 3 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('n_estimators', 1200), ('warm_start', False), ('n_outputs_', 1), ('max_depth', None), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_samples_split', 2), ('min_impurity_split', 1e-07), ('n_features_', 1024), ('verbose', 0), ('min_weight_fraction_leaf', 0.0), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('random_state', 42), ('bootstrap', False), ('min_samples_leaf', 1), ('n_jobs', 12), ('oob_score', False), ('max_leaf_nodes', None), ('class_weight', None)]\n",
      "  *FOLD R^2: -0.0137 (MSE: 0.5057; MAE: 0.5247; mean train mae: 0.5390)\n",
      "Fold 4 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1084    Test size: 270]\n",
      " X[0]: (N, features): (1084, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1084, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (270, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('n_estimators', 1200), ('warm_start', False), ('n_outputs_', 1), ('max_depth', None), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_samples_split', 2), ('min_impurity_split', 1e-07), ('n_features_', 1024), ('verbose', 0), ('min_weight_fraction_leaf', 0.0), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('random_state', 42), ('bootstrap', False), ('min_samples_leaf', 1), ('n_jobs', 12), ('oob_score', False), ('max_leaf_nodes', None), ('class_weight', None)]\n",
      "  *FOLD R^2: -0.0324 (MSE: 0.5868; MAE: 0.5360; mean train mae: 0.5454)\n",
      "*Overall R^2:          0.0034\n",
      "*Overall FOLDS R^2:    -0.0024 (+- 0.0116)\n",
      "*R (sqrt R^2):         0.0581\n",
      "*Pearson r:            0.1252 (p = 0.00000)\n",
      "*Folds Pearson r:      0.1302 (p = 0.14621)\n",
      "*Spearman rho:         0.1434 (p = 0.00000)\n",
      "*Mean Squared Error:   0.5717\n",
      "*Mean Absolute Error:  0.5415\n",
      "*Train_Mean MAE:       0.1363\n",
      "\n",
      "= CELVAL2 (w/ lang.)=\n",
      "---------------------\n",
      "Fold 0 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('n_estimators', 1200), ('warm_start', False), ('n_outputs_', 1), ('max_depth', None), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_samples_split', 2), ('min_impurity_split', 1e-07), ('n_features_', 1024), ('verbose', 0), ('min_weight_fraction_leaf', 0.0), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('random_state', 42), ('bootstrap', False), ('min_samples_leaf', 1), ('n_jobs', 12), ('oob_score', False), ('max_leaf_nodes', None), ('class_weight', None)]\n",
      "  *FOLD R^2: 0.0521 (MSE: 0.5837; MAE: 0.5393; mean train mae: 0.5735)\n",
      "Fold 1 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('n_estimators', 1200), ('warm_start', False), ('n_outputs_', 1), ('max_depth', None), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_samples_split', 2), ('min_impurity_split', 1e-07), ('n_features_', 1024), ('verbose', 0), ('min_weight_fraction_leaf', 0.0), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('random_state', 42), ('bootstrap', False), ('min_samples_leaf', 1), ('n_jobs', 12), ('oob_score', False), ('max_leaf_nodes', None), ('class_weight', None)]\n",
      "  *FOLD R^2: 0.0005 (MSE: 0.6047; MAE: 0.5898; mean train mae: 0.6141)\n",
      "Fold 2 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('n_estimators', 1200), ('warm_start', False), ('n_outputs_', 1), ('max_depth', None), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_samples_split', 2), ('min_impurity_split', 1e-07), ('n_features_', 1024), ('verbose', 0), ('min_weight_fraction_leaf', 0.0), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('random_state', 42), ('bootstrap', False), ('min_samples_leaf', 1), ('n_jobs', 12), ('oob_score', False), ('max_leaf_nodes', None), ('class_weight', None)]\n",
      "  *FOLD R^2: -0.0309 (MSE: 0.7234; MAE: 0.6169; mean train mae: 0.6139)\n",
      "Fold 3 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('n_estimators', 1200), ('warm_start', False), ('n_outputs_', 1), ('max_depth', None), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_samples_split', 2), ('min_impurity_split', 1e-07), ('n_features_', 1024), ('verbose', 0), ('min_weight_fraction_leaf', 0.0), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('random_state', 42), ('bootstrap', False), ('min_samples_leaf', 1), ('n_jobs', 12), ('oob_score', False), ('max_leaf_nodes', None), ('class_weight', None)]\n",
      "  *FOLD R^2: 0.0091 (MSE: 0.6709; MAE: 0.5698; mean train mae: 0.5873)\n",
      "Fold 4 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1084    Test size: 270]\n",
      " X[0]: (N, features): (1084, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1084, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (270, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('n_estimators', 1200), ('warm_start', False), ('n_outputs_', 1), ('max_depth', None), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_samples_split', 2), ('min_impurity_split', 1e-07), ('n_features_', 1024), ('verbose', 0), ('min_weight_fraction_leaf', 0.0), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('random_state', 42), ('bootstrap', False), ('min_samples_leaf', 1), ('n_jobs', 12), ('oob_score', False), ('max_leaf_nodes', None), ('class_weight', None)]\n",
      "  *FOLD R^2: -0.0899 (MSE: 0.7838; MAE: 0.6246; mean train mae: 0.6018)\n",
      "/home/karthik9/TheDlatk/dlatk/dlatk/regressionPredictor.py:1398: RuntimeWarning: invalid value encountered in sqrt\n",
      "  reportStats['R'] = sqrt(reportStats['R2'])\n",
      "*Overall R^2:          -0.0093\n",
      "*Overall FOLDS R^2:    -0.0118 (+- 0.0211)\n",
      "*R (sqrt R^2):         nan\n",
      "*Pearson r:            0.0985 (p = 0.00028)\n",
      "*Folds Pearson r:      0.1091 (p = 0.24335)\n",
      "*Spearman rho:         0.1127 (p = 0.00003)\n",
      "*Mean Squared Error:   0.6732\n",
      "*Mean Absolute Error:  0.5881\n",
      "*Train_Mean MAE:       0.1391\n",
      "\n",
      "= CELVAL3 (w/ lang.)=\n",
      "---------------------\n",
      "Fold 0 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('n_estimators', 1200), ('warm_start', False), ('n_outputs_', 1), ('max_depth', None), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_samples_split', 2), ('min_impurity_split', 1e-07), ('n_features_', 1024), ('verbose', 0), ('min_weight_fraction_leaf', 0.0), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('random_state', 42), ('bootstrap', False), ('min_samples_leaf', 1), ('n_jobs', 12), ('oob_score', False), ('max_leaf_nodes', None), ('class_weight', None)]\n",
      "  *FOLD R^2: 0.0765 (MSE: 0.7411; MAE: 0.6112; mean train mae: 0.6112)\n",
      "Fold 1 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('n_estimators', 1200), ('warm_start', False), ('n_outputs_', 1), ('max_depth', None), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_samples_split', 2), ('min_impurity_split', 1e-07), ('n_features_', 1024), ('verbose', 0), ('min_weight_fraction_leaf', 0.0), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('random_state', 42), ('bootstrap', False), ('min_samples_leaf', 1), ('n_jobs', 12), ('oob_score', False), ('max_leaf_nodes', None), ('class_weight', None)]\n",
      "  *FOLD R^2: 0.0428 (MSE: 0.7337; MAE: 0.6295; mean train mae: 0.5992)\n",
      "Fold 2 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('n_estimators', 1200), ('warm_start', False), ('n_outputs_', 1), ('max_depth', None), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_samples_split', 2), ('min_impurity_split', 1e-07), ('n_features_', 1024), ('verbose', 0), ('min_weight_fraction_leaf', 0.0), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('random_state', 42), ('bootstrap', False), ('min_samples_leaf', 1), ('n_jobs', 12), ('oob_score', False), ('max_leaf_nodes', None), ('class_weight', None)]\n",
      "  *FOLD R^2: 0.0168 (MSE: 0.7944; MAE: 0.6164; mean train mae: 0.5911)\n",
      "Fold 3 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('n_estimators', 1200), ('warm_start', False), ('n_outputs_', 1), ('max_depth', None), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_samples_split', 2), ('min_impurity_split', 1e-07), ('n_features_', 1024), ('verbose', 0), ('min_weight_fraction_leaf', 0.0), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('random_state', 42), ('bootstrap', False), ('min_samples_leaf', 1), ('n_jobs', 12), ('oob_score', False), ('max_leaf_nodes', None), ('class_weight', None)]\n",
      "  *FOLD R^2: -0.0867 (MSE: 0.6465; MAE: 0.5701; mean train mae: 0.4987)\n",
      "Fold 4 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1084    Test size: 270]\n",
      " X[0]: (N, features): (1084, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1084, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (270, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('n_estimators', 1200), ('warm_start', False), ('n_outputs_', 1), ('max_depth', None), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_samples_split', 2), ('min_impurity_split', 1e-07), ('n_features_', 1024), ('verbose', 0), ('min_weight_fraction_leaf', 0.0), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('random_state', 42), ('bootstrap', False), ('min_samples_leaf', 1), ('n_jobs', 12), ('oob_score', False), ('max_leaf_nodes', None), ('class_weight', None)]\n",
      "  *FOLD R^2: -0.0681 (MSE: 0.8979; MAE: 0.6657; mean train mae: 0.6132)\n",
      "*Overall R^2:          0.0085\n",
      "*Overall FOLDS R^2:    -0.0038 (+- 0.0283)\n",
      "*R (sqrt R^2):         0.0922\n",
      "*Pearson r:            0.1394 (p = 0.00000)\n",
      "*Folds Pearson r:      0.1572 (p = 0.12591)\n",
      "*Spearman rho:         0.1652 (p = 0.00000)\n",
      "*Mean Squared Error:   0.7626\n",
      "*Mean Absolute Error:  0.6186\n",
      "*Train_Mean MAE:       0.1666\n",
      "\n",
      "= CEL_Total (w/ lang.)=\n",
      "-----------------------\n",
      "Fold 0 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('n_estimators', 1200), ('warm_start', False), ('n_outputs_', 1), ('max_depth', None), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_samples_split', 2), ('min_impurity_split', 1e-07), ('n_features_', 1024), ('verbose', 0), ('min_weight_fraction_leaf', 0.0), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('random_state', 42), ('bootstrap', False), ('min_samples_leaf', 1), ('n_jobs', 12), ('oob_score', False), ('max_leaf_nodes', None), ('class_weight', None)]\n",
      "  *FOLD R^2: 0.0832 (MSE: 3.7191; MAE: 1.4143; mean train mae: 1.5187)\n",
      "Fold 1 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('n_estimators', 1200), ('warm_start', False), ('n_outputs_', 1), ('max_depth', None), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_samples_split', 2), ('min_impurity_split', 1e-07), ('n_features_', 1024), ('verbose', 0), ('min_weight_fraction_leaf', 0.0), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('random_state', 42), ('bootstrap', False), ('min_samples_leaf', 1), ('n_jobs', 12), ('oob_score', False), ('max_leaf_nodes', None), ('class_weight', None)]\n",
      "  *FOLD R^2: 0.0413 (MSE: 3.5871; MAE: 1.5046; mean train mae: 1.5526)\n",
      "Fold 2 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('n_estimators', 1200), ('warm_start', False), ('n_outputs_', 1), ('max_depth', None), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_samples_split', 2), ('min_impurity_split', 1e-07), ('n_features_', 1024), ('verbose', 0), ('min_weight_fraction_leaf', 0.0), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('random_state', 42), ('bootstrap', False), ('min_samples_leaf', 1), ('n_jobs', 12), ('oob_score', False), ('max_leaf_nodes', None), ('class_weight', None)]\n",
      "  *FOLD R^2: 0.0489 (MSE: 3.4876; MAE: 1.4226; mean train mae: 1.4633)\n",
      "Fold 3 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('n_estimators', 1200), ('warm_start', False), ('n_outputs_', 1), ('max_depth', None), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_samples_split', 2), ('min_impurity_split', 1e-07), ('n_features_', 1024), ('verbose', 0), ('min_weight_fraction_leaf', 0.0), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('random_state', 42), ('bootstrap', False), ('min_samples_leaf', 1), ('n_jobs', 12), ('oob_score', False), ('max_leaf_nodes', None), ('class_weight', None)]\n",
      "  *FOLD R^2: 0.0054 (MSE: 3.5345; MAE: 1.4113; mean train mae: 1.4227)\n",
      "Fold 4 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1084    Test size: 270]\n",
      " X[0]: (N, features): (1084, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1084, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (270, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('n_estimators', 1200), ('warm_start', False), ('n_outputs_', 1), ('max_depth', None), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_samples_split', 2), ('min_impurity_split', 1e-07), ('n_features_', 1024), ('verbose', 0), ('min_weight_fraction_leaf', 0.0), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('random_state', 42), ('bootstrap', False), ('min_samples_leaf', 1), ('n_jobs', 12), ('oob_score', False), ('max_leaf_nodes', None), ('class_weight', None)]\n",
      "  *FOLD R^2: -0.0737 (MSE: 4.4789; MAE: 1.5212; mean train mae: 1.4868)\n",
      "*Overall R^2:          0.0249\n",
      "*Overall FOLDS R^2:    0.0210 (+- 0.0239)\n",
      "*R (sqrt R^2):         0.1577\n",
      "*Pearson r:            0.1768 (p = 0.00000)\n",
      "*Folds Pearson r:      0.1906 (p = 0.16083)\n",
      "*Spearman rho:         0.1888 (p = 0.00000)\n",
      "*Mean Squared Error:   3.7609\n",
      "*Mean Absolute Error:  1.4548\n",
      "*Train_Mean MAE:       0.3802\n",
      "\n",
      "[TEST COMPLETE]\n",
      "\n",
      "{'CELVAL1': {(): {1: {'N': 1354,\n",
      "                      'R': 0.058134332695822605,\n",
      "                      'R2': 0.003379600637988589,\n",
      "                      'R2_folds': -0.0023635745743334048,\n",
      "                      'mae': 0.54154480551452489,\n",
      "                      'mae_folds': 0.54154072479613669,\n",
      "                      'mse': 0.57172557648120792,\n",
      "                      'mse_folds': 0.57173670134428189,\n",
      "                      'num_features': 1024,\n",
      "                      'r': 0.12521645289068548,\n",
      "                      'r_folds': 0.13018243366459453,\n",
      "                      'r_p': 3.8097229151330468e-06,\n",
      "                      'r_p_folds': 0.14621363731114473,\n",
      "                      'rho': 0.14336579040764297,\n",
      "                      'rho_folds': 0.15246327884144359,\n",
      "                      'rho_p': 1.1713503380383563e-07,\n",
      "                      'rho_p_folds': 0.11722388952108838,\n",
      "                      'se_R2_folds': 0.011573231819837422,\n",
      "                      'se_mae_folds': 0.01981046279353588,\n",
      "                      'se_mse_folds': 0.045449484899917708,\n",
      "                      'se_r_folds': 0.028623978979139861,\n",
      "                      'se_r_p_folds': 0.082158666930175983,\n",
      "                      'se_rho_folds': 0.040868145536972489,\n",
      "                      'se_rho_p_folds': 0.065550920998162829,\n",
      "                      'se_train_mean_mae_folds': 0.020099823370732458,\n",
      "                      'test_size': 270,\n",
      "                      'train_mean_mae': 0.13627301385394916,\n",
      "                      'train_mean_mae_folds': 0.55992981093245831,\n",
      "                      'train_size': 1084,\n",
      "                      '{modelFS_desc}': 'None',\n",
      "                      '{model_desc}': 'ExtraTreesRegressor(bootstrap=False, '\n",
      "                                      \"criterion='mse', max_depth=None,      \"\n",
      "                                      \"max_features='auto', \"\n",
      "                                      'max_leaf_nodes=None,      '\n",
      "                                      'min_impurity_split=1e-07, '\n",
      "                                      'min_samples_leaf=1,      '\n",
      "                                      'min_samples_split=2, '\n",
      "                                      'min_weight_fraction_leaf=0.0,      '\n",
      "                                      'n_estimators=1200, n_jobs=12, '\n",
      "                                      'oob_score=False, random_state=42,      '\n",
      "                                      'verbose=0, warm_start=False)'}}},\n",
      " 'CELVAL2': {(): {1: {'N': 1354,\n",
      "                      'R': nan,\n",
      "                      'R2': -0.0092790633047783455,\n",
      "                      'R2_folds': -0.011834402121959343,\n",
      "                      'mae': 0.58805822255046769,\n",
      "                      'mae_folds': 0.58808517607398281,\n",
      "                      'mse': 0.67321073106433615,\n",
      "                      'mse_folds': 0.67329233697401791,\n",
      "                      'num_features': 1024,\n",
      "                      'r': 0.098517083709631526,\n",
      "                      'r_folds': 0.10909050017720157,\n",
      "                      'r_p': 0.00028276944499303503,\n",
      "                      'r_p_folds': 0.24334962908232655,\n",
      "                      'rho': 0.11271967869539652,\n",
      "                      'rho_folds': 0.12111272799595585,\n",
      "                      'rho_p': 3.222554001236946e-05,\n",
      "                      'rho_p_folds': 0.11167811137791424,\n",
      "                      'se_R2_folds': 0.021104280303198324,\n",
      "                      'se_mae_folds': 0.01396531361423642,\n",
      "                      'se_mse_folds': 0.033142933389259013,\n",
      "                      'se_r_folds': 0.045291233139785197,\n",
      "                      'se_r_p_folds': 0.12537864337575949,\n",
      "                      'se_rho_folds': 0.063351678537527448,\n",
      "                      'se_rho_p_folds': 0.068742138325546903,\n",
      "                      'se_train_mean_mae_folds': 0.007048564210861287,\n",
      "                      'test_size': 270,\n",
      "                      'train_mean_mae': 0.1390665648111582,\n",
      "                      'train_mean_mae_folds': 0.59809211046865784,\n",
      "                      'train_size': 1084,\n",
      "                      '{modelFS_desc}': 'None',\n",
      "                      '{model_desc}': 'ExtraTreesRegressor(bootstrap=False, '\n",
      "                                      \"criterion='mse', max_depth=None,      \"\n",
      "                                      \"max_features='auto', \"\n",
      "                                      'max_leaf_nodes=None,      '\n",
      "                                      'min_impurity_split=1e-07, '\n",
      "                                      'min_samples_leaf=1,      '\n",
      "                                      'min_samples_split=2, '\n",
      "                                      'min_weight_fraction_leaf=0.0,      '\n",
      "                                      'n_estimators=1200, n_jobs=12, '\n",
      "                                      'oob_score=False, random_state=42,      '\n",
      "                                      'verbose=0, warm_start=False)'}}},\n",
      " 'CELVAL3': {(): {1: {'N': 1354,\n",
      "                      'R': 0.092178426554849993,\n",
      "                      'R2': 0.0084968623221278738,\n",
      "                      'R2_folds': -0.0037546397936466303,\n",
      "                      'mae': 0.61855797636632204,\n",
      "                      'mae_folds': 0.61859278620563973,\n",
      "                      'mse': 0.76264762791317897,\n",
      "                      'mse_folds': 0.76274744419198826,\n",
      "                      'num_features': 1024,\n",
      "                      'r': 0.1393669869229589,\n",
      "                      'r_folds': 0.15722676627593318,\n",
      "                      'r_p': 2.6235428108929107e-07,\n",
      "                      'r_p_folds': 0.12591132883422482,\n",
      "                      'rho': 0.16523557774511394,\n",
      "                      'rho_folds': 0.18160255381495216,\n",
      "                      'rho_p': 9.5589888115370287e-10,\n",
      "                      'rho_p_folds': 0.081135735881209078,\n",
      "                      'se_R2_folds': 0.028312754014148768,\n",
      "                      'se_mae_folds': 0.01378205898972102,\n",
      "                      'se_mse_folds': 0.036923456509610722,\n",
      "                      'se_r_folds': 0.048621305326002562,\n",
      "                      'se_r_p_folds': 0.10463908588517191,\n",
      "                      'se_rho_folds': 0.057497591797329439,\n",
      "                      'se_rho_p_folds': 0.071706699076212008,\n",
      "                      'se_train_mean_mae_folds': 0.019128562080640208,\n",
      "                      'test_size': 270,\n",
      "                      'train_mean_mae': 0.16659120322592141,\n",
      "                      'train_mean_mae_folds': 0.58268000713248136,\n",
      "                      'train_size': 1084,\n",
      "                      '{modelFS_desc}': 'None',\n",
      "                      '{model_desc}': 'ExtraTreesRegressor(bootstrap=False, '\n",
      "                                      \"criterion='mse', max_depth=None,      \"\n",
      "                                      \"max_features='auto', \"\n",
      "                                      'max_leaf_nodes=None,      '\n",
      "                                      'min_impurity_split=1e-07, '\n",
      "                                      'min_samples_leaf=1,      '\n",
      "                                      'min_samples_split=2, '\n",
      "                                      'min_weight_fraction_leaf=0.0,      '\n",
      "                                      'n_estimators=1200, n_jobs=12, '\n",
      "                                      'oob_score=False, random_state=42,      '\n",
      "                                      'verbose=0, warm_start=False)'}}},\n",
      " 'CEL_Total': {(): {1: {'N': 1354,\n",
      "                        'R': 0.15774939012014241,\n",
      "                        'R2': 0.024884870083276889,\n",
      "                        'R2_folds': 0.021038462581725724,\n",
      "                        'mae': 1.4547507385524372,\n",
      "                        'mae_folds': 1.4547997585531409,\n",
      "                        'mse': 3.7608941628713279,\n",
      "                        'mse_folds': 3.7614240283358384,\n",
      "                        'num_features': 1024,\n",
      "                        'r': 0.17680953680826964,\n",
      "                        'r_folds': 0.19063992908326852,\n",
      "                        'r_p': 5.6890438580821925e-11,\n",
      "                        'r_p_folds': 0.16083246389350098,\n",
      "                        'rho': 0.18876606647510238,\n",
      "                        'rho_folds': 0.20313644346091064,\n",
      "                        'rho_p': 2.5124525852639754e-12,\n",
      "                        'rho_p_folds': 0.10443318306886398,\n",
      "                        'se_R2_folds': 0.023886971322868593,\n",
      "                        'se_mae_folds': 0.02140770435136707,\n",
      "                        'se_mse_folds': 0.16411870862834954,\n",
      "                        'se_r_folds': 0.048396959287166447,\n",
      "                        'se_r_p_folds': 0.14361581712512003,\n",
      "                        'se_rho_folds': 0.059230923798008379,\n",
      "                        'se_rho_p_folds': 0.093278666161772855,\n",
      "                        'se_train_mean_mae_folds': 0.019988829500618789,\n",
      "                        'test_size': 270,\n",
      "                        'train_mean_mae': 0.38018311900403418,\n",
      "                        'train_mean_mae_folds': 1.4888360464398736,\n",
      "                        'train_size': 1084,\n",
      "                        '{modelFS_desc}': 'None',\n",
      "                        '{model_desc}': 'ExtraTreesRegressor(bootstrap=False, '\n",
      "                                        \"criterion='mse', max_depth=None,      \"\n",
      "                                        \"max_features='auto', \"\n",
      "                                        'max_leaf_nodes=None,      '\n",
      "                                        'min_impurity_split=1e-07, '\n",
      "                                        'min_samples_leaf=1,      '\n",
      "                                        'min_samples_split=2, '\n",
      "                                        'min_weight_fraction_leaf=0.0,      '\n",
      "                                        'n_estimators=1200, n_jobs=12, '\n",
      "                                        'oob_score=False, '\n",
      "                                        'random_state=42,      verbose=0, '\n",
      "                                        'warm_start=False)'}}}}\n",
      "-------\n",
      "Settings:\n",
      "\n",
      "Database - Audio_features\n",
      "Corpus - merged_data\n",
      "Group ID - message_id\n",
      "Feature table(s) - feat$trill_min$merged_data$message_id\n",
      "Outcome table - merged_data\n",
      "Outcome(s) - CEL_Total CELVAL1 CELVAL2 CELVAL3\n",
      "-------\n",
      "Interface Runtime: 728.11 seconds\n",
      "DLATK exits with success! A good day indeed  ¯\\_(ツ)_/¯.\n"
     ]
    }
   ],
   "source": [
    "!python /home/karthik9/TheDlatk/dlatk/dlatkInterface.py -d Audio_features -t merged_data -c message_id \\\n",
    "-f 'feat$trill_min$merged_data$message_id ' \\\n",
    "    --outcome_table merged_data  --group_freq_thresh 10 \\\n",
    "    --outcomes CEL_Total CELVAL1 CELVAL2 CELVAL3 \\\n",
    "    --nfold_test_regression --model extratrees --fold_column fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "/data/anaconda2/envs/dlatk/lib/python3.5/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n",
      "\n",
      "-----\n",
      "DLATK Interface Initiated: 2025-02-06 19:22:09\n",
      "-----\n",
      "Loading Outcomes and Getting Groups for: {'CELVAL3', 'CELVAL1', 'CEL_Total', 'CELVAL2'}\n",
      "    ***explicit fold labels specified, not splitting again***\n",
      "[number of groups: 1354 (5 Folds)]\n",
      "\n",
      "\n",
      "|COMBO: ()|\n",
      "===========\n",
      "\n",
      "= CELVAL1 (w/ lang.)=\n",
      "---------------------\n",
      "Fold 0 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('min_weight_fraction_leaf', 0.0), ('bootstrap', False), ('max_leaf_nodes', None), ('n_estimators', 1200), ('verbose', 0), ('warm_start', False), ('random_state', 42), ('min_samples_leaf', 1), ('n_outputs_', 1), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_impurity_split', 1e-07), ('max_depth', None), ('class_weight', None), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_features_', 1024), ('oob_score', False), ('n_jobs', 12), ('min_samples_split', 2)]\n",
      "  *FOLD R^2: 0.0530 (MSE: 0.6623; MAE: 0.5619; mean train mae: 0.6021)\n",
      "Fold 1 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('min_weight_fraction_leaf', 0.0), ('bootstrap', False), ('max_leaf_nodes', None), ('n_estimators', 1200), ('verbose', 0), ('warm_start', False), ('random_state', 42), ('min_samples_leaf', 1), ('n_outputs_', 1), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_impurity_split', 1e-07), ('max_depth', None), ('class_weight', None), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_features_', 1024), ('oob_score', False), ('n_jobs', 12), ('min_samples_split', 2)]\n",
      "  *FOLD R^2: -0.0493 (MSE: 0.7086; MAE: 0.6237; mean train mae: 0.6184)\n",
      "Fold 2 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('min_weight_fraction_leaf', 0.0), ('bootstrap', False), ('max_leaf_nodes', None), ('n_estimators', 1200), ('verbose', 0), ('warm_start', False), ('random_state', 42), ('min_samples_leaf', 1), ('n_outputs_', 1), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_impurity_split', 1e-07), ('max_depth', None), ('class_weight', None), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_features_', 1024), ('oob_score', False), ('n_jobs', 12), ('min_samples_split', 2)]\n",
      "  *FOLD R^2: -0.0261 (MSE: 0.4257; MAE: 0.4855; mean train mae: 0.4947)\n",
      "Fold 3 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('min_weight_fraction_leaf', 0.0), ('bootstrap', False), ('max_leaf_nodes', None), ('n_estimators', 1200), ('verbose', 0), ('warm_start', False), ('random_state', 42), ('min_samples_leaf', 1), ('n_outputs_', 1), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_impurity_split', 1e-07), ('max_depth', None), ('class_weight', None), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_features_', 1024), ('oob_score', False), ('n_jobs', 12), ('min_samples_split', 2)]\n",
      "  *FOLD R^2: -0.0676 (MSE: 0.5326; MAE: 0.5496; mean train mae: 0.5390)\n",
      "Fold 4 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1084    Test size: 270]\n",
      " X[0]: (N, features): (1084, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1084, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (270, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('min_weight_fraction_leaf', 0.0), ('bootstrap', False), ('max_leaf_nodes', None), ('n_estimators', 1200), ('verbose', 0), ('warm_start', False), ('random_state', 42), ('min_samples_leaf', 1), ('n_outputs_', 1), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_impurity_split', 1e-07), ('max_depth', None), ('class_weight', None), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_features_', 1024), ('oob_score', False), ('n_jobs', 12), ('min_samples_split', 2)]\n",
      "  *FOLD R^2: -0.0186 (MSE: 0.5790; MAE: 0.5403; mean train mae: 0.5454)\n",
      "/home/karthik9/TheDlatk/dlatk/dlatk/regressionPredictor.py:1398: RuntimeWarning: invalid value encountered in sqrt\n",
      "  reportStats['R'] = sqrt(reportStats['R2'])\n",
      "*Overall R^2:          -0.0139\n",
      "*Overall FOLDS R^2:    -0.0217 (+- 0.0184)\n",
      "*R (sqrt R^2):         nan\n",
      "*Pearson r:            0.1062 (p = 0.00009)\n",
      "*Folds Pearson r:      0.1108 (p = 0.23167)\n",
      "*Spearman rho:         0.1362 (p = 0.00000)\n",
      "*Mean Squared Error:   0.5816\n",
      "*Mean Absolute Error:  0.5522\n",
      "*Train_Mean MAE:       0.1495\n",
      "\n",
      "= CELVAL2 (w/ lang.)=\n",
      "---------------------\n",
      "Fold 0 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('min_weight_fraction_leaf', 0.0), ('bootstrap', False), ('max_leaf_nodes', None), ('n_estimators', 1200), ('verbose', 0), ('warm_start', False), ('random_state', 42), ('min_samples_leaf', 1), ('n_outputs_', 1), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_impurity_split', 1e-07), ('max_depth', None), ('class_weight', None), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_features_', 1024), ('oob_score', False), ('n_jobs', 12), ('min_samples_split', 2)]\n",
      "  *FOLD R^2: 0.0748 (MSE: 0.5697; MAE: 0.5431; mean train mae: 0.5735)\n",
      "Fold 1 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('min_weight_fraction_leaf', 0.0), ('bootstrap', False), ('max_leaf_nodes', None), ('n_estimators', 1200), ('verbose', 0), ('warm_start', False), ('random_state', 42), ('min_samples_leaf', 1), ('n_outputs_', 1), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_impurity_split', 1e-07), ('max_depth', None), ('class_weight', None), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_features_', 1024), ('oob_score', False), ('n_jobs', 12), ('min_samples_split', 2)]\n",
      "  *FOLD R^2: 0.0130 (MSE: 0.5972; MAE: 0.6029; mean train mae: 0.6141)\n",
      "Fold 2 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('min_weight_fraction_leaf', 0.0), ('bootstrap', False), ('max_leaf_nodes', None), ('n_estimators', 1200), ('verbose', 0), ('warm_start', False), ('random_state', 42), ('min_samples_leaf', 1), ('n_outputs_', 1), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_impurity_split', 1e-07), ('max_depth', None), ('class_weight', None), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_features_', 1024), ('oob_score', False), ('n_jobs', 12), ('min_samples_split', 2)]\n",
      "  *FOLD R^2: 0.0135 (MSE: 0.6922; MAE: 0.6198; mean train mae: 0.6139)\n",
      "Fold 3 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('min_weight_fraction_leaf', 0.0), ('bootstrap', False), ('max_leaf_nodes', None), ('n_estimators', 1200), ('verbose', 0), ('warm_start', False), ('random_state', 42), ('min_samples_leaf', 1), ('n_outputs_', 1), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_impurity_split', 1e-07), ('max_depth', None), ('class_weight', None), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_features_', 1024), ('oob_score', False), ('n_jobs', 12), ('min_samples_split', 2)]\n",
      "  *FOLD R^2: 0.0241 (MSE: 0.6607; MAE: 0.5819; mean train mae: 0.5873)\n",
      "Fold 4 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1084    Test size: 270]\n",
      " X[0]: (N, features): (1084, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1084, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (270, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('min_weight_fraction_leaf', 0.0), ('bootstrap', False), ('max_leaf_nodes', None), ('n_estimators', 1200), ('verbose', 0), ('warm_start', False), ('random_state', 42), ('min_samples_leaf', 1), ('n_outputs_', 1), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_impurity_split', 1e-07), ('max_depth', None), ('class_weight', None), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_features_', 1024), ('oob_score', False), ('n_jobs', 12), ('min_samples_split', 2)]\n",
      "  *FOLD R^2: -0.0666 (MSE: 0.7670; MAE: 0.6282; mean train mae: 0.6018)\n",
      "*Overall R^2:          0.0146\n",
      "*Overall FOLDS R^2:    0.0118 (+- 0.0203)\n",
      "*R (sqrt R^2):         0.1208\n",
      "*Pearson r:            0.1717 (p = 0.00000)\n",
      "*Folds Pearson r:      0.1795 (p = 0.11077)\n",
      "*Spearman rho:         0.1515 (p = 0.00000)\n",
      "*Mean Squared Error:   0.6573\n",
      "*Mean Absolute Error:  0.5951\n",
      "*Train_Mean MAE:       0.1762\n",
      "\n",
      "= CELVAL3 (w/ lang.)=\n",
      "---------------------\n",
      "Fold 0 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('min_weight_fraction_leaf', 0.0), ('bootstrap', False), ('max_leaf_nodes', None), ('n_estimators', 1200), ('verbose', 0), ('warm_start', False), ('random_state', 42), ('min_samples_leaf', 1), ('n_outputs_', 1), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_impurity_split', 1e-07), ('max_depth', None), ('class_weight', None), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_features_', 1024), ('oob_score', False), ('n_jobs', 12), ('min_samples_split', 2)]\n",
      "  *FOLD R^2: 0.1037 (MSE: 0.7193; MAE: 0.6134; mean train mae: 0.6112)\n",
      "Fold 1 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('min_weight_fraction_leaf', 0.0), ('bootstrap', False), ('max_leaf_nodes', None), ('n_estimators', 1200), ('verbose', 0), ('warm_start', False), ('random_state', 42), ('min_samples_leaf', 1), ('n_outputs_', 1), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_impurity_split', 1e-07), ('max_depth', None), ('class_weight', None), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_features_', 1024), ('oob_score', False), ('n_jobs', 12), ('min_samples_split', 2)]\n",
      "  *FOLD R^2: 0.0368 (MSE: 0.7383; MAE: 0.6412; mean train mae: 0.5992)\n",
      "Fold 2 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('min_weight_fraction_leaf', 0.0), ('bootstrap', False), ('max_leaf_nodes', None), ('n_estimators', 1200), ('verbose', 0), ('warm_start', False), ('random_state', 42), ('min_samples_leaf', 1), ('n_outputs_', 1), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_impurity_split', 1e-07), ('max_depth', None), ('class_weight', None), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_features_', 1024), ('oob_score', False), ('n_jobs', 12), ('min_samples_split', 2)]\n",
      "  *FOLD R^2: 0.0149 (MSE: 0.7959; MAE: 0.6356; mean train mae: 0.5911)\n",
      "Fold 3 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('min_weight_fraction_leaf', 0.0), ('bootstrap', False), ('max_leaf_nodes', None), ('n_estimators', 1200), ('verbose', 0), ('warm_start', False), ('random_state', 42), ('min_samples_leaf', 1), ('n_outputs_', 1), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_impurity_split', 1e-07), ('max_depth', None), ('class_weight', None), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_features_', 1024), ('oob_score', False), ('n_jobs', 12), ('min_samples_split', 2)]\n",
      "  *FOLD R^2: -0.1263 (MSE: 0.6701; MAE: 0.5913; mean train mae: 0.4987)\n",
      "Fold 4 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1084    Test size: 270]\n",
      " X[0]: (N, features): (1084, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1084, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (270, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('min_weight_fraction_leaf', 0.0), ('bootstrap', False), ('max_leaf_nodes', None), ('n_estimators', 1200), ('verbose', 0), ('warm_start', False), ('random_state', 42), ('min_samples_leaf', 1), ('n_outputs_', 1), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_impurity_split', 1e-07), ('max_depth', None), ('class_weight', None), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_features_', 1024), ('oob_score', False), ('n_jobs', 12), ('min_samples_split', 2)]\n",
      "  *FOLD R^2: -0.0251 (MSE: 0.8617; MAE: 0.6622; mean train mae: 0.6132)\n",
      "*Overall R^2:          0.0158\n",
      "*Overall FOLDS R^2:    0.0008 (+- 0.0340)\n",
      "*R (sqrt R^2):         0.1259\n",
      "*Pearson r:            0.1727 (p = 0.00000)\n",
      "*Folds Pearson r:      0.1848 (p = 0.06202)\n",
      "*Spearman rho:         0.1933 (p = 0.00000)\n",
      "*Mean Squared Error:   0.7570\n",
      "*Mean Absolute Error:  0.6287\n",
      "*Train_Mean MAE:       0.1925\n",
      "\n",
      "= CEL_Total (w/ lang.)=\n",
      "-----------------------\n",
      "Fold 0 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('min_weight_fraction_leaf', 0.0), ('bootstrap', False), ('max_leaf_nodes', None), ('n_estimators', 1200), ('verbose', 0), ('warm_start', False), ('random_state', 42), ('min_samples_leaf', 1), ('n_outputs_', 1), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_impurity_split', 1e-07), ('max_depth', None), ('class_weight', None), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_features_', 1024), ('oob_score', False), ('n_jobs', 12), ('min_samples_split', 2)]\n",
      "  *FOLD R^2: 0.1319 (MSE: 3.5217; MAE: 1.3984; mean train mae: 1.5187)\n",
      "Fold 1 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('min_weight_fraction_leaf', 0.0), ('bootstrap', False), ('max_leaf_nodes', None), ('n_estimators', 1200), ('verbose', 0), ('warm_start', False), ('random_state', 42), ('min_samples_leaf', 1), ('n_outputs_', 1), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_impurity_split', 1e-07), ('max_depth', None), ('class_weight', None), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_features_', 1024), ('oob_score', False), ('n_jobs', 12), ('min_samples_split', 2)]\n",
      "  *FOLD R^2: 0.0192 (MSE: 3.6698; MAE: 1.5265; mean train mae: 1.5526)\n",
      "Fold 2 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('min_weight_fraction_leaf', 0.0), ('bootstrap', False), ('max_leaf_nodes', None), ('n_estimators', 1200), ('verbose', 0), ('warm_start', False), ('random_state', 42), ('min_samples_leaf', 1), ('n_outputs_', 1), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_impurity_split', 1e-07), ('max_depth', None), ('class_weight', None), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_features_', 1024), ('oob_score', False), ('n_jobs', 12), ('min_samples_split', 2)]\n",
      "  *FOLD R^2: 0.0448 (MSE: 3.5025; MAE: 1.4404; mean train mae: 1.4633)\n",
      "Fold 3 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1083    Test size: 271]\n",
      " X[0]: (N, features): (1083, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1083, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (271, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('min_weight_fraction_leaf', 0.0), ('bootstrap', False), ('max_leaf_nodes', None), ('n_estimators', 1200), ('verbose', 0), ('warm_start', False), ('random_state', 42), ('min_samples_leaf', 1), ('n_outputs_', 1), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_impurity_split', 1e-07), ('max_depth', None), ('class_weight', None), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_features_', 1024), ('oob_score', False), ('n_jobs', 12), ('min_samples_split', 2)]\n",
      "  *FOLD R^2: -0.0311 (MSE: 3.6643; MAE: 1.4483; mean train mae: 1.4227)\n",
      "Fold 4 \n",
      "   (feature group: 0): [Initial size: 1354]\n",
      " [Train size: 1084    Test size: 270]\n",
      " X[0]: (N, features): (1084, 1024)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1084, 1024)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[PREDICT] combined X shape: (270, 1024)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=1200, n_jobs=12, oob_score=False, random_state=42,\n",
      "          verbose=0, warm_start=False)\n",
      "settings:  [('min_weight_fraction_leaf', 0.0), ('bootstrap', False), ('max_leaf_nodes', None), ('n_estimators', 1200), ('verbose', 0), ('warm_start', False), ('random_state', 42), ('min_samples_leaf', 1), ('n_outputs_', 1), ('base_estimator', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('min_impurity_split', 1e-07), ('max_depth', None), ('class_weight', None), ('base_estimator_', ExtraTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "          max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')), ('n_features_', 1024), ('oob_score', False), ('n_jobs', 12), ('min_samples_split', 2)]\n",
      "  *FOLD R^2: -0.0120 (MSE: 4.2217; MAE: 1.5307; mean train mae: 1.4868)\n",
      "*Overall R^2:          0.0366\n",
      "*Overall FOLDS R^2:    0.0306 (+- 0.0255)\n",
      "*R (sqrt R^2):         0.1914\n",
      "*Pearson r:            0.2136 (p = 0.00000)\n",
      "*Folds Pearson r:      0.2200 (p = 0.01376)\n",
      "*Spearman rho:         0.2183 (p = 0.00000)\n",
      "*Mean Squared Error:   3.7156\n",
      "*Mean Absolute Error:  1.4688\n",
      "*Train_Mean MAE:       0.4527\n",
      "\n",
      "[TEST COMPLETE]\n",
      "\n",
      "{'CELVAL1': {(): {1: {'N': 1354,\n",
      "                      'R': nan,\n",
      "                      'R2': -0.013905611432915688,\n",
      "                      'R2_folds': -0.021740683550788842,\n",
      "                      'mae': 0.55221811915312657,\n",
      "                      'mae_folds': 0.55220935948248362,\n",
      "                      'mse': 0.58164148613162636,\n",
      "                      'mse_folds': 0.58163952626114224,\n",
      "                      'num_features': 1024,\n",
      "                      'r': 0.10621913216213605,\n",
      "                      'r_folds': 0.11081240566135031,\n",
      "                      'r_p': 9.0033741521084292e-05,\n",
      "                      'r_p_folds': 0.23166809840284999,\n",
      "                      'rho': 0.13616379991898467,\n",
      "                      'rho_folds': 0.14461247273202976,\n",
      "                      'rho_p': 4.92540403290423e-07,\n",
      "                      'rho_p_folds': 0.16155775225316377,\n",
      "                      'se_R2_folds': 0.018418113446474788,\n",
      "                      'se_mae_folds': 0.019802375936515133,\n",
      "                      'se_mse_folds': 0.044436117367419765,\n",
      "                      'se_r_folds': 0.03207277810210947,\n",
      "                      'se_r_p_folds': 0.13706756765356018,\n",
      "                      'se_rho_folds': 0.041868364274935732,\n",
      "                      'se_rho_p_folds': 0.092060270990090357,\n",
      "                      'se_train_mean_mae_folds': 0.020099823370732448,\n",
      "                      'test_size': 270,\n",
      "                      'train_mean_mae': 0.14948380239231354,\n",
      "                      'train_mean_mae_folds': 0.55992981093245831,\n",
      "                      'train_size': 1084,\n",
      "                      '{modelFS_desc}': 'None',\n",
      "                      '{model_desc}': 'ExtraTreesRegressor(bootstrap=False, '\n",
      "                                      \"criterion='mse', max_depth=None,      \"\n",
      "                                      \"max_features='auto', \"\n",
      "                                      'max_leaf_nodes=None,      '\n",
      "                                      'min_impurity_split=1e-07, '\n",
      "                                      'min_samples_leaf=1,      '\n",
      "                                      'min_samples_split=2, '\n",
      "                                      'min_weight_fraction_leaf=0.0,      '\n",
      "                                      'n_estimators=1200, n_jobs=12, '\n",
      "                                      'oob_score=False, random_state=42,      '\n",
      "                                      'verbose=0, warm_start=False)'}}},\n",
      " 'CELVAL2': {(): {1: {'N': 1354,\n",
      "                      'R': 0.12082862270575989,\n",
      "                      'R2': 0.014599556064970876,\n",
      "                      'R2_folds': 0.011755944305883115,\n",
      "                      'mae': 0.59513478581979318,\n",
      "                      'mae_folds': 0.59515915448043377,\n",
      "                      'mse': 0.6572831810068932,\n",
      "                      'mse_folds': 0.65736418559898568,\n",
      "                      'num_features': 1024,\n",
      "                      'r': 0.1717347923852266,\n",
      "                      'r_folds': 0.1795414188199535,\n",
      "                      'r_p': 2.0076316989077341e-10,\n",
      "                      'r_p_folds': 0.110771559230972,\n",
      "                      'rho': 0.15145419120102038,\n",
      "                      'rho_folds': 0.15427585427274534,\n",
      "                      'rho_p': 2.1409520262716414e-08,\n",
      "                      'rho_p_folds': 0.16238713865548488,\n",
      "                      'se_R2_folds': 0.020274838582489307,\n",
      "                      'se_mae_folds': 0.013621249912001074,\n",
      "                      'se_mse_folds': 0.031350361449564185,\n",
      "                      'se_r_folds': 0.036388597250234432,\n",
      "                      'se_r_p_folds': 0.096854577087920349,\n",
      "                      'se_rho_folds': 0.045461571484219372,\n",
      "                      'se_rho_p_folds': 0.13233523866956759,\n",
      "                      'se_train_mean_mae_folds': 0.0070485642108612826,\n",
      "                      'test_size': 270,\n",
      "                      'train_mean_mae': 0.17615023542040759,\n",
      "                      'train_mean_mae_folds': 0.59809211046865784,\n",
      "                      'train_size': 1084,\n",
      "                      '{modelFS_desc}': 'None',\n",
      "                      '{model_desc}': 'ExtraTreesRegressor(bootstrap=False, '\n",
      "                                      \"criterion='mse', max_depth=None,      \"\n",
      "                                      \"max_features='auto', \"\n",
      "                                      'max_leaf_nodes=None,      '\n",
      "                                      'min_impurity_split=1e-07, '\n",
      "                                      'min_samples_leaf=1,      '\n",
      "                                      'min_samples_split=2, '\n",
      "                                      'min_weight_fraction_leaf=0.0,      '\n",
      "                                      'n_estimators=1200, n_jobs=12, '\n",
      "                                      'oob_score=False, random_state=42,      '\n",
      "                                      'verbose=0, warm_start=False)'}}},\n",
      " 'CELVAL3': {(): {1: {'N': 1354,\n",
      "                      'R': 0.12589304900521633,\n",
      "                      'R2': 0.0158490597878298,\n",
      "                      'R2_folds': 0.00080919176912386259,\n",
      "                      'mae': 0.62869583948793695,\n",
      "                      'mae_folds': 0.6287205412054121,\n",
      "                      'mse': 0.7569924406080748,\n",
      "                      'mse_folds': 0.75706971569252735,\n",
      "                      'num_features': 1024,\n",
      "                      'r': 0.17266796752578512,\n",
      "                      'r_folds': 0.18476547681631025,\n",
      "                      'r_p': 1.5966075311115468e-10,\n",
      "                      'r_p_folds': 0.062020061014519935,\n",
      "                      'rho': 0.19326333154164782,\n",
      "                      'rho_folds': 0.2067600391947168,\n",
      "                      'rho_p': 7.357764693496804e-13,\n",
      "                      'rho_p_folds': 0.055413200423433492,\n",
      "                      'se_R2_folds': 0.034009357587744128,\n",
      "                      'se_mae_folds': 0.010880781455925677,\n",
      "                      'se_mse_folds': 0.029527546060125292,\n",
      "                      'se_r_folds': 0.042546498124431495,\n",
      "                      'se_r_p_folds': 0.035015463735366396,\n",
      "                      'se_rho_folds': 0.051161513971901044,\n",
      "                      'se_rho_p_folds': 0.041792356105600163,\n",
      "                      'se_train_mean_mae_folds': 0.019128562080640205,\n",
      "                      'test_size': 270,\n",
      "                      'train_mean_mae': 0.19249580632398708,\n",
      "                      'train_mean_mae_folds': 0.58268000713248136,\n",
      "                      'train_size': 1084,\n",
      "                      '{modelFS_desc}': 'None',\n",
      "                      '{model_desc}': 'ExtraTreesRegressor(bootstrap=False, '\n",
      "                                      \"criterion='mse', max_depth=None,      \"\n",
      "                                      \"max_features='auto', \"\n",
      "                                      'max_leaf_nodes=None,      '\n",
      "                                      'min_impurity_split=1e-07, '\n",
      "                                      'min_samples_leaf=1,      '\n",
      "                                      'min_samples_split=2, '\n",
      "                                      'min_weight_fraction_leaf=0.0,      '\n",
      "                                      'n_estimators=1200, n_jobs=12, '\n",
      "                                      'oob_score=False, random_state=42,      '\n",
      "                                      'verbose=0, warm_start=False)'}}},\n",
      " 'CEL_Total': {(): {1: {'N': 1354,\n",
      "                        'R': 0.19136771937180547,\n",
      "                        'R2': 0.03662160401756609,\n",
      "                        'R2_folds': 0.030559673683694676,\n",
      "                        'mae': 1.4687912358444115,\n",
      "                        'mae_folds': 1.4688369072024055,\n",
      "                        'mse': 3.7156270833333336,\n",
      "                        'mse_folds': 3.716000578760648,\n",
      "                        'num_features': 1024,\n",
      "                        'r': 0.21363119571959738,\n",
      "                        'r_folds': 0.22002588922017602,\n",
      "                        'r_p': 1.9330067729793233e-15,\n",
      "                        'r_p_folds': 0.013763816438302864,\n",
      "                        'rho': 0.2183144113413128,\n",
      "                        'rho_folds': 0.22465873127417368,\n",
      "                        'rho_p': 4.5096777583494351e-16,\n",
      "                        'rho_p_folds': 0.063014317162276887,\n",
      "                        'se_R2_folds': 0.025464376795496006,\n",
      "                        'se_mae_folds': 0.023109607412067568,\n",
      "                        'se_mse_folds': 0.11728589471108684,\n",
      "                        'se_r_folds': 0.041428804728667189,\n",
      "                        'se_r_p_folds': 0.010417405624930137,\n",
      "                        'se_rho_folds': 0.051277896844848653,\n",
      "                        'se_rho_p_folds': 0.055934908225891693,\n",
      "                        'se_train_mean_mae_folds': 0.019988829500618772,\n",
      "                        'test_size': 270,\n",
      "                        'train_mean_mae': 0.45265534146868297,\n",
      "                        'train_mean_mae_folds': 1.4888360464398733,\n",
      "                        'train_size': 1084,\n",
      "                        '{modelFS_desc}': 'None',\n",
      "                        '{model_desc}': 'ExtraTreesRegressor(bootstrap=False, '\n",
      "                                        \"criterion='mse', max_depth=None,      \"\n",
      "                                        \"max_features='auto', \"\n",
      "                                        'max_leaf_nodes=None,      '\n",
      "                                        'min_impurity_split=1e-07, '\n",
      "                                        'min_samples_leaf=1,      '\n",
      "                                        'min_samples_split=2, '\n",
      "                                        'min_weight_fraction_leaf=0.0,      '\n",
      "                                        'n_estimators=1200, n_jobs=12, '\n",
      "                                        'oob_score=False, '\n",
      "                                        'random_state=42,      verbose=0, '\n",
      "                                        'warm_start=False)'}}}}\n",
      "-------\n",
      "Settings:\n",
      "\n",
      "Database - Audio_features\n",
      "Corpus - merged_data\n",
      "Group ID - message_id\n",
      "Feature table(s) - feat$trill_mstd$merged_data$message_id\n",
      "Outcome table - merged_data\n",
      "Outcome(s) - CEL_Total CELVAL1 CELVAL2 CELVAL3\n",
      "-------\n",
      "Interface Runtime: 546.90 seconds\n",
      "DLATK exits with success! A good day indeed  ¯\\_(ツ)_/¯.\n"
     ]
    }
   ],
   "source": [
    "!python /home/karthik9/TheDlatk/dlatk/dlatkInterface.py -d Audio_features -t merged_data -c message_id \\\n",
    "-f 'feat$trill_mstd$merged_data$message_id ' \\\n",
    "    --outcome_table merged_data  --group_freq_thresh 10 \\\n",
    "    --outcomes CEL_Total CELVAL1 CELVAL2 CELVAL3 \\\n",
    "    --nfold_test_regression --model extratrees --fold_column fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>librosa</th>\n",
       "      <th>opensmile</th>\n",
       "      <th>whisper</th>\n",
       "      <th>ldasenten</th>\n",
       "      <th>Liwc2022</th>\n",
       "      <th>1to3grams</th>\n",
       "      <th>CEL_Total_trues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103_2021-04-21</td>\n",
       "      <td>3.433333333333333</td>\n",
       "      <td>3.935</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.195833333333334</td>\n",
       "      <td>2.925</td>\n",
       "      <td>3.8625</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105_2021-04-29</td>\n",
       "      <td>2.1508333333333334</td>\n",
       "      <td>2.1733333333333333</td>\n",
       "      <td>4.75</td>\n",
       "      <td>2.0733333333333333</td>\n",
       "      <td>2.1083333333333334</td>\n",
       "      <td>2.3575</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106_2021-04-28</td>\n",
       "      <td>2.776666666666667</td>\n",
       "      <td>2.4225</td>\n",
       "      <td>3.6233333333333335</td>\n",
       "      <td>3.0058333333333334</td>\n",
       "      <td>3.8775</td>\n",
       "      <td>3.1733333333333333</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107_2021-04-12</td>\n",
       "      <td>3.9091666666666667</td>\n",
       "      <td>4.221666666666667</td>\n",
       "      <td>3.6791666666666667</td>\n",
       "      <td>3.4158333333333335</td>\n",
       "      <td>3.484166666666667</td>\n",
       "      <td>3.4075</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>107_2021-04-20</td>\n",
       "      <td>2.140833333333333</td>\n",
       "      <td>2.859166666666667</td>\n",
       "      <td>2.4633333333333334</td>\n",
       "      <td>2.19</td>\n",
       "      <td>2.3475</td>\n",
       "      <td>2.7408333333333332</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>941934_2024-11-07</td>\n",
       "      <td>3.6483333333333334</td>\n",
       "      <td>3.7191666666666667</td>\n",
       "      <td>2.85</td>\n",
       "      <td>2.441666666666667</td>\n",
       "      <td>2.404166666666667</td>\n",
       "      <td>2.9558333333333335</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>952421_2024-11-19</td>\n",
       "      <td>1.8741666666666668</td>\n",
       "      <td>1.7216666666666667</td>\n",
       "      <td>2.66</td>\n",
       "      <td>3.595833333333333</td>\n",
       "      <td>2.285833333333333</td>\n",
       "      <td>2.985</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>981476_2024-11-01</td>\n",
       "      <td>2.816666666666667</td>\n",
       "      <td>3.31</td>\n",
       "      <td>2.3008333333333333</td>\n",
       "      <td>2.7916666666666665</td>\n",
       "      <td>2.7133333333333334</td>\n",
       "      <td>2.5641666666666665</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>983777_2024-11-22</td>\n",
       "      <td>1.9025</td>\n",
       "      <td>2.0625</td>\n",
       "      <td>2.6275</td>\n",
       "      <td>2.1266666666666665</td>\n",
       "      <td>1.5058333333333334</td>\n",
       "      <td>2.0591666666666666</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>997606_2024-10-25</td>\n",
       "      <td>3.109166666666667</td>\n",
       "      <td>2.9683333333333333</td>\n",
       "      <td>3.4175</td>\n",
       "      <td>2.5991666666666666</td>\n",
       "      <td>2.7591666666666668</td>\n",
       "      <td>2.3308333333333335</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1468 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               group_id             librosa           opensmile  \\\n",
       "0        103_2021-04-21   3.433333333333333               3.935   \n",
       "1        105_2021-04-29  2.1508333333333334  2.1733333333333333   \n",
       "2        106_2021-04-28   2.776666666666667              2.4225   \n",
       "3        107_2021-04-12  3.9091666666666667   4.221666666666667   \n",
       "4        107_2021-04-20   2.140833333333333   2.859166666666667   \n",
       "...                 ...                 ...                 ...   \n",
       "1463  941934_2024-11-07  3.6483333333333334  3.7191666666666667   \n",
       "1464  952421_2024-11-19  1.8741666666666668  1.7216666666666667   \n",
       "1465  981476_2024-11-01   2.816666666666667                3.31   \n",
       "1466  983777_2024-11-22              1.9025              2.0625   \n",
       "1467  997606_2024-10-25   3.109166666666667  2.9683333333333333   \n",
       "\n",
       "                 whisper           ldasenten            Liwc2022  \\\n",
       "0                    2.6   4.195833333333334               2.925   \n",
       "1                   4.75  2.0733333333333333  2.1083333333333334   \n",
       "2     3.6233333333333335  3.0058333333333334              3.8775   \n",
       "3     3.6791666666666667  3.4158333333333335   3.484166666666667   \n",
       "4     2.4633333333333334                2.19              2.3475   \n",
       "...                  ...                 ...                 ...   \n",
       "1463                2.85   2.441666666666667   2.404166666666667   \n",
       "1464                2.66   3.595833333333333   2.285833333333333   \n",
       "1465  2.3008333333333333  2.7916666666666665  2.7133333333333334   \n",
       "1466              2.6275  2.1266666666666665  1.5058333333333334   \n",
       "1467              3.4175  2.5991666666666666  2.7591666666666668   \n",
       "\n",
       "               1to3grams  CEL_Total_trues  \n",
       "0                 3.8625                1  \n",
       "1                 2.3575                3  \n",
       "2     3.1733333333333333                8  \n",
       "3                 3.4075                6  \n",
       "4     2.7408333333333332                2  \n",
       "...                  ...              ...  \n",
       "1463  2.9558333333333335                1  \n",
       "1464               2.985                5  \n",
       "1465  2.5641666666666665                2  \n",
       "1466  2.0591666666666666                2  \n",
       "1467  2.3308333333333335                9  \n",
       "\n",
       "[1468 rows x 8 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_and_combine_csv(file_names):\n",
    "    combined_df = None\n",
    "\n",
    "    for file in file_names:\n",
    "        # Load the CSV file without headers\n",
    "        df = pd.read_csv(file, header=None)\n",
    "        \n",
    "        # Set the first row as column headers\n",
    "        new_header = df.iloc[1]  # Take the first row as header\n",
    "        df = df[2:]  # Remove the first row from the data\n",
    "        df.columns = new_header  # Set the new header\n",
    "        \n",
    "        # Extract the file name and get the part after the first '_'\n",
    "        file_name = file.split('/')[-1]  # Extract file name from path if given\n",
    "        base_name = file_name.split('_')[1].split('.')[0]  # Get the part after the first '_'\n",
    "        # Rename columns based on the extracted base name (librosa, opensmile, etc.)\n",
    "        if 'CEL_Total__withLanguage' in df.columns:\n",
    "            df[base_name] = df['CEL_Total__withLanguage']\n",
    "            df['CEL_Total__withLanguage'] = df['CEL_Total__withLanguage'].rename(base_name)\n",
    "        \n",
    "        df.to_csv('combined_data1.csv', index=False)\n",
    "        \n",
    "        df = df[[ 'Id', base_name]]\n",
    "        # Reset the index\n",
    "        df = df.reset_index(drop=True)\n",
    "        \n",
    "        # Merge with the combined dataframe\n",
    "        if combined_df is None:\n",
    "            combined_df = df\n",
    "        else:\n",
    "            # Merge based on 'Id'\n",
    "            combined_df = pd.merge(combined_df, df, on='Id', how='inner')\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "# Example usage with the list of files\n",
    "file_names = ['Klatch_librosa.predicted_data.csv', 'Klatch_opensmile.predicted_data.csv', 'Klatch_whisper_mean.predicted_data.csv', 'Klatch_ldasenten.predicted_data.csv', 'Klatch_Liwc2022.predicted_data.csv' , 'Klatch_1to3grams.predicted_data.csv']  \n",
    "combined_df = process_and_combine_csv(file_names)\n",
    "\n",
    "# Save the combined DataFrame to a CSV file\n",
    "combined_df.to_csv('combined_data.csv', index=False)\n",
    "combined_data1 = pd.read_csv('combined_data1.csv')\n",
    "combined_df = pd.merge(combined_df,combined_data1[['Id','CEL_Total_trues']] , on='Id', how='inner')\n",
    "\n",
    "combined_df.rename(columns={\"Id\": \"group_id\"}, inplace=True)\n",
    "# Display the combined DataFrame\n",
    "combined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>top_k_experts</th>\n",
       "      <th>final_prediction</th>\n",
       "      <th>CEL_Total_trues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103_2021-04-21</td>\n",
       "      <td>[(ldasenten, 4.195833333333334), (opensmile, 3...</td>\n",
       "      <td>3.997778</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105_2021-04-29</td>\n",
       "      <td>[(whisper, 4.75), (1to3grams, 2.3575), (opensm...</td>\n",
       "      <td>3.093611</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106_2021-04-28</td>\n",
       "      <td>[(Liwc2022, 3.8775), (whisper, 3.6233333333333...</td>\n",
       "      <td>3.558056</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107_2021-04-12</td>\n",
       "      <td>[(opensmile, 4.221666666666667), (librosa, 3.9...</td>\n",
       "      <td>3.936667</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>107_2021-04-20</td>\n",
       "      <td>[(opensmile, 2.859166666666667), (1to3grams, 2...</td>\n",
       "      <td>2.687778</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>941934_2024-11-07</td>\n",
       "      <td>[(opensmile, 3.7191666666666667), (librosa, 3....</td>\n",
       "      <td>3.441111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>952421_2024-11-19</td>\n",
       "      <td>[(ldasenten, 3.595833333333333), (1to3grams, 2...</td>\n",
       "      <td>3.080278</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>981476_2024-11-01</td>\n",
       "      <td>[(opensmile, 3.31), (librosa, 2.81666666666666...</td>\n",
       "      <td>2.972778</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>983777_2024-11-22</td>\n",
       "      <td>[(whisper, 2.6275), (ldasenten, 2.126666666666...</td>\n",
       "      <td>2.272222</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>997606_2024-10-25</td>\n",
       "      <td>[(whisper, 3.4175), (librosa, 3.10916666666666...</td>\n",
       "      <td>3.165000</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1468 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               group_id                                      top_k_experts  \\\n",
       "0        103_2021-04-21  [(ldasenten, 4.195833333333334), (opensmile, 3...   \n",
       "1        105_2021-04-29  [(whisper, 4.75), (1to3grams, 2.3575), (opensm...   \n",
       "2        106_2021-04-28  [(Liwc2022, 3.8775), (whisper, 3.6233333333333...   \n",
       "3        107_2021-04-12  [(opensmile, 4.221666666666667), (librosa, 3.9...   \n",
       "4        107_2021-04-20  [(opensmile, 2.859166666666667), (1to3grams, 2...   \n",
       "...                 ...                                                ...   \n",
       "1463  941934_2024-11-07  [(opensmile, 3.7191666666666667), (librosa, 3....   \n",
       "1464  952421_2024-11-19  [(ldasenten, 3.595833333333333), (1to3grams, 2...   \n",
       "1465  981476_2024-11-01  [(opensmile, 3.31), (librosa, 2.81666666666666...   \n",
       "1466  983777_2024-11-22  [(whisper, 2.6275), (ldasenten, 2.126666666666...   \n",
       "1467  997606_2024-10-25  [(whisper, 3.4175), (librosa, 3.10916666666666...   \n",
       "\n",
       "      final_prediction  CEL_Total_trues  \n",
       "0             3.997778                1  \n",
       "1             3.093611                3  \n",
       "2             3.558056                8  \n",
       "3             3.936667                6  \n",
       "4             2.687778                2  \n",
       "...                ...              ...  \n",
       "1463          3.441111                1  \n",
       "1464          3.080278                5  \n",
       "1465          2.972778                2  \n",
       "1466          2.272222                2  \n",
       "1467          3.165000                9  \n",
       "\n",
       "[1468 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'combined_df' is the original dataframe you have\n",
    "df = pd.DataFrame(combined_df)\n",
    "\n",
    "# Extract features and target\n",
    "X = df[['librosa', 'opensmile', 'whisper', 'ldasenten', 'Liwc2022', '1to3grams']]\n",
    "y = df['CEL_Total_trues']\n",
    "\n",
    "# Standardize the features for the gating network\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train a simple linear regression model as the gating network\n",
    "gating_model = LinearRegression()\n",
    "gating_model.fit(X_scaled, y)\n",
    "\n",
    "# Get the gating network weights for each input\n",
    "gating_weights = gating_model.predict(X_scaled)\n",
    "\n",
    "# Combine gating weights with expert predictions\n",
    "df['gating_weights'] = gating_weights\n",
    "\n",
    "# Define k (top-k experts)\n",
    "k = 3\n",
    "\n",
    "# Now for each input, we'll calculate the top-k experts based on the gating weights\n",
    "df['top_k_experts'] = df.apply(\n",
    "    lambda row: sorted(\n",
    "        zip(['librosa', 'opensmile', 'whisper', 'ldasenten', 'Liwc2022', '1to3grams'], \n",
    "            row[['librosa', 'opensmile', 'whisper', 'ldasenten', 'Liwc2022', '1to3grams']]), \n",
    "        key=lambda x: x[1], reverse=True)[:k], axis=1\n",
    ")\n",
    "\n",
    "# Function to calculate weighted average of top-k expert predictions\n",
    "def weighted_average(row):\n",
    "    # Extract top-k expert names and their predictions\n",
    "    top_k_predictions = np.array([x[1] for x in row['top_k_experts']], dtype=np.float64)\n",
    "    \n",
    "    # Get the gating weights for each expert (from the model's output)\n",
    "    top_k_weights = np.array([gating_weights[row.name]] * len(top_k_predictions), dtype=np.float64)  # Use the row's gating weight for each expert\n",
    "    \n",
    "    # Calculate weighted average\n",
    "    weighted_avg = np.average(top_k_predictions, weights=top_k_weights)\n",
    "    return weighted_avg\n",
    "\n",
    "# Apply weighted average to calculate the final prediction\n",
    "df['final_prediction'] = df.apply(weighted_average, axis=1)\n",
    "\n",
    "\n",
    "df[['group_id', 'top_k_experts', 'final_prediction', 'CEL_Total_trues']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson's r: 0.26190844010665393\n",
      "R² (R-squared): 0.022395055794804164\n",
      "Mean Absolute Error (MAE): 1.5163069557977598\n",
      "p-values: const    0.000000e+00\n",
      "x1       3.362338e-01\n",
      "x2       2.230959e-02\n",
      "x3       9.823214e-04\n",
      "x4       3.948360e-02\n",
      "x5       5.233366e-10\n",
      "x6       3.152899e-06\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'df' is your dataframe and 'final_prediction' is the column with model predictions\n",
    "\n",
    "# Calculate Pearson's r (correlation coefficient) between actual and predicted values\n",
    "pearson_r, _ = pearsonr(df['CEL_Total_trues'], df['final_prediction'])\n",
    "\n",
    "# Calculate R² (R-squared) for the model's performance\n",
    "r_squared = r2_score(df['CEL_Total_trues'], df['final_prediction'])\n",
    "\n",
    "# Calculate MAE (Mean Absolute Error)\n",
    "mae = mean_absolute_error(df['CEL_Total_trues'], df['final_prediction'])\n",
    "\n",
    "# Add a constant to the features for the p-value calculation\n",
    "X_with_constant = sm.add_constant(X_scaled)\n",
    "\n",
    "# Fit an Ordinary Least Squares (OLS) model to get p-values\n",
    "ols_model = sm.OLS(df['CEL_Total_trues'], X_with_constant).fit()\n",
    "\n",
    "# Get the p-values of the coefficients (including the constant)\n",
    "p_values = ols_model.pvalues\n",
    "\n",
    "# Display the results\n",
    "print(\"Pearson's r:\", pearson_r)\n",
    "print(\"R² (R-squared):\", r_squared)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"p-values:\", p_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>feat</th>\n",
       "      <th>value</th>\n",
       "      <th>group_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103_2021-04-21</td>\n",
       "      <td>librosa</td>\n",
       "      <td>3.433333333333333</td>\n",
       "      <td>3.433333333333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105_2021-04-29</td>\n",
       "      <td>librosa</td>\n",
       "      <td>2.1508333333333334</td>\n",
       "      <td>2.1508333333333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106_2021-04-28</td>\n",
       "      <td>librosa</td>\n",
       "      <td>2.776666666666667</td>\n",
       "      <td>2.776666666666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107_2021-04-12</td>\n",
       "      <td>librosa</td>\n",
       "      <td>3.9091666666666667</td>\n",
       "      <td>3.9091666666666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>107_2021-04-20</td>\n",
       "      <td>librosa</td>\n",
       "      <td>2.140833333333333</td>\n",
       "      <td>2.140833333333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8803</th>\n",
       "      <td>941934_2024-11-07</td>\n",
       "      <td>1to3grams</td>\n",
       "      <td>2.9558333333333335</td>\n",
       "      <td>2.9558333333333335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8804</th>\n",
       "      <td>952421_2024-11-19</td>\n",
       "      <td>1to3grams</td>\n",
       "      <td>2.985</td>\n",
       "      <td>2.985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8805</th>\n",
       "      <td>981476_2024-11-01</td>\n",
       "      <td>1to3grams</td>\n",
       "      <td>2.5641666666666665</td>\n",
       "      <td>2.5641666666666665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8806</th>\n",
       "      <td>983777_2024-11-22</td>\n",
       "      <td>1to3grams</td>\n",
       "      <td>2.0591666666666666</td>\n",
       "      <td>2.0591666666666666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8807</th>\n",
       "      <td>997606_2024-10-25</td>\n",
       "      <td>1to3grams</td>\n",
       "      <td>2.3308333333333335</td>\n",
       "      <td>2.3308333333333335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8808 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               group_id       feat               value          group_norm\n",
       "0        103_2021-04-21    librosa   3.433333333333333   3.433333333333333\n",
       "1        105_2021-04-29    librosa  2.1508333333333334  2.1508333333333334\n",
       "2        106_2021-04-28    librosa   2.776666666666667   2.776666666666667\n",
       "3        107_2021-04-12    librosa  3.9091666666666667  3.9091666666666667\n",
       "4        107_2021-04-20    librosa   2.140833333333333   2.140833333333333\n",
       "...                 ...        ...                 ...                 ...\n",
       "8803  941934_2024-11-07  1to3grams  2.9558333333333335  2.9558333333333335\n",
       "8804  952421_2024-11-19  1to3grams               2.985               2.985\n",
       "8805  981476_2024-11-01  1to3grams  2.5641666666666665  2.5641666666666665\n",
       "8806  983777_2024-11-22  1to3grams  2.0591666666666666  2.0591666666666666\n",
       "8807  997606_2024-10-25  1to3grams  2.3308333333333335  2.3308333333333335\n",
       "\n",
       "[8808 rows x 4 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melted_df = combined_df.melt(\n",
    "    id_vars=[\"group_id\"],  # Columns to keep as is\n",
    "    var_name=\"feat\",            # Name for the feature column\n",
    "    value_name=\"value\"          # Name for the value column\n",
    ")\n",
    "\n",
    "# Optionally, calculate `group_norm` (if needed)\n",
    "melted_df[\"group_norm\"] = melted_df[\"value\"]\n",
    "\n",
    "melted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "def insert_feature_table_into_db(connection, dataframe, table_name):\n",
    "    \n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    # Generate the column placeholders for the query\n",
    "    columns = ', '.join(dataframe.columns)\n",
    "    placeholders = ', '.join(['%s'] * len(dataframe.columns))\n",
    "    \n",
    "    # Prepare the SQL query for insertion\n",
    "    query = f\"\"\"\n",
    "    INSERT INTO {table_name} ({columns})\n",
    "    VALUES ({placeholders})\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert the DataFrame rows to a list of tuples\n",
    "    records = list(dataframe.itertuples(index=False, name=None))\n",
    "    \n",
    "    # Insert the records into the database\n",
    "    cursor.executemany(query, records)\n",
    "    connection.commit()\n",
    "    print(f\"{cursor.rowcount} rows inserted into {table_name}.\")\n",
    "    cursor.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Establish connection to MySQL database\n",
    "def connect_to_db():\n",
    "    connection = mysql.connector.connect(\n",
    "        host='localhost',\n",
    "        user='karthik9',\n",
    "        password='I:nRLgAQvEb|SkJ!',\n",
    "        database='Audio_features'\n",
    "    )\n",
    "    return connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4404 rows inserted into feat$combined_text$merged_data$message_id.\n"
     ]
    }
   ],
   "source": [
    "connection = connect_to_db()\n",
    "\n",
    "# Insert the DataFrame into the database\n",
    "insert_feature_table_into_db(connection, melted_df, 'feat$combined_text$merged_data$message_id')\n",
    "\n",
    "# Close the connection\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Warning: Cannot import langid (cannot use addLanguageFilterTable)\n",
      "TopicExtractor: gensim Mallet wrapper unavailable, using Mallet directly.\n",
      "\n",
      "-----\n",
      "DLATK Interface Initiated: 2025-03-18 05:58:52\n",
      "-----\n",
      "Loading Outcomes and Getting Groups for: {'CEL_Total'}\n",
      "    ***explicit fold labels specified, not splitting again***\n",
      "[number of groups: 1468 (5 Folds)]\n",
      "\n",
      "\n",
      "|COMBO: ()|\n",
      "===========\n",
      "\n",
      "= CEL_Total (w/ lang.)=\n",
      "-----------------------\n",
      "Fold 0 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1175    Test size: 293]\n",
      " X[0]: (N, features): (1175, 3)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1175, 3)\n",
      "![COMBINED FEATS] number of features is small enough (feats: 3, observations: 1175), backing off to: 'linear'!\n",
      "[COMBINED FEATS: Training regression model: linear]\n",
      "model: LinearRegression() \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (293, 3)\n",
      "[PREDICT] regressor: LinearRegression()\n",
      "settings:  [('fit_intercept', True), ('copy_X', True), ('n_jobs', None), ('positive', False), ('n_features_in_', 3), ('rank_', 3), ('intercept_', np.float64(2.6085106382978744))]\n",
      "  *FOLD R^2: 0.0404 (MSE: 2.7443; MAE: 1.3195; mean train mae: 1.3558)\n",
      "Fold 1 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1175    Test size: 293]\n",
      " X[0]: (N, features): (1175, 3)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1175, 3)\n",
      "![COMBINED FEATS] number of features is small enough (feats: 3, observations: 1175), backing off to: 'linear'!\n",
      "[COMBINED FEATS: Training regression model: linear]\n",
      "model: LinearRegression() \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (293, 3)\n",
      "[PREDICT] regressor: LinearRegression()\n",
      "settings:  [('fit_intercept', True), ('copy_X', True), ('n_jobs', None), ('positive', False), ('n_features_in_', 3), ('rank_', 3), ('intercept_', np.float64(2.5838297872340434))]\n",
      "  *FOLD R^2: 0.0481 (MSE: 4.4085; MAE: 1.5994; mean train mae: 1.6470)\n",
      "Fold 2 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1174    Test size: 294]\n",
      " X[0]: (N, features): (1174, 3)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1174, 3)\n",
      "![COMBINED FEATS] number of features is small enough (feats: 3, observations: 1174), backing off to: 'linear'!\n",
      "[COMBINED FEATS: Training regression model: linear]\n",
      "model: LinearRegression() \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (294, 3)\n",
      "[PREDICT] regressor: LinearRegression()\n",
      "settings:  [('fit_intercept', True), ('copy_X', True), ('n_jobs', None), ('positive', False), ('n_features_in_', 3), ('rank_', 3), ('intercept_', np.float64(2.4770017035775123))]\n",
      "  *FOLD R^2: -0.0682 (MSE: 4.6633; MAE: 1.5433; mean train mae: 1.5240)\n",
      "Fold 3 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1174    Test size: 294]\n",
      " X[0]: (N, features): (1174, 3)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1174, 3)\n",
      "![COMBINED FEATS] number of features is small enough (feats: 3, observations: 1174), backing off to: 'linear'!\n",
      "[COMBINED FEATS: Training regression model: linear]\n",
      "model: LinearRegression() \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (294, 3)\n",
      "[PREDICT] regressor: LinearRegression()\n",
      "settings:  [('fit_intercept', True), ('copy_X', True), ('n_jobs', None), ('positive', False), ('n_features_in_', 3), ('rank_', 3), ('intercept_', np.float64(2.59710391822828))]\n",
      "  *FOLD R^2: 0.0388 (MSE: 4.7322; MAE: 1.6622; mean train mae: 1.7162)\n",
      "Fold 4 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1174    Test size: 294]\n",
      " X[0]: (N, features): (1174, 3)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1174, 3)\n",
      "![COMBINED FEATS] number of features is small enough (feats: 3, observations: 1174), backing off to: 'linear'!\n",
      "[COMBINED FEATS: Training regression model: linear]\n",
      "model: LinearRegression() \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (294, 3)\n",
      "[PREDICT] regressor: LinearRegression()\n",
      "settings:  [('fit_intercept', True), ('copy_X', True), ('n_jobs', None), ('positive', False), ('n_features_in_', 3), ('rank_', 3), ('intercept_', np.float64(2.6013628620102223))]\n",
      "  *FOLD R^2: 0.0431 (MSE: 3.0370; MAE: 1.2958; mean train mae: 1.3278)\n",
      "*Overall R^2:          0.0278\n",
      "*Overall FOLDS R^2:    0.0204 (+- 0.0199)\n",
      "*R (sqrt R^2):         0.1666\n",
      "*Pearson r:            0.1717 (p = 0.00000)\n",
      "*Folds Pearson r:      0.2007 (p = 0.01675)\n",
      "*Spearman rho:         0.1839 (p = 0.00000)\n",
      "*Mean Squared Error:   3.9175\n",
      "*Mean Absolute Error:  1.4841\n",
      "*Train_Mean MAE:       0.3331\n",
      "\n",
      "[TEST COMPLETE]\n",
      "\n",
      "{'CEL_Total': {(): {1: {'N': 1468,\n",
      "                        'R': np.float64(0.16658919977941503),\n",
      "                        'R2': 0.02775196148314585,\n",
      "                        'R2_folds': np.float64(0.02044305364385639),\n",
      "                        'mae': 1.4840807913215048,\n",
      "                        'mae_folds': np.float64(1.4840472992899214),\n",
      "                        'mse': 3.9175069014792405,\n",
      "                        'mse_folds': np.float64(3.9170428017961916),\n",
      "                        'num_features': 3,\n",
      "                        'r': np.float64(0.17171493443531027),\n",
      "                        'r_folds': np.float64(0.20074090792684754),\n",
      "                        'r_p': np.float64(3.524219980074209e-11),\n",
      "                        'r_p_folds': np.float64(0.016752438726237447),\n",
      "                        'rho': np.float64(0.1838997174586052),\n",
      "                        'rho_folds': np.float64(0.20700497687554925),\n",
      "                        'rho_p': np.float64(1.2416014568374892e-12),\n",
      "                        'rho_p_folds': np.float64(0.013313100126279096),\n",
      "                        'se_R2_folds': np.float64(0.01986535954816819),\n",
      "                        'se_mae_folds': np.float64(0.06665421855648443),\n",
      "                        'se_mse_folds': np.float64(0.38013561263338996),\n",
      "                        'se_r_folds': np.float64(0.02265333807966674),\n",
      "                        'se_r_p_folds': np.float64(0.014878246511494143),\n",
      "                        'se_rho_folds': np.float64(0.02296695657341917),\n",
      "                        'se_rho_p_folds': np.float64(0.01181621440107663),\n",
      "                        'se_train_mean_mae_folds': np.float64(0.06881004248493686),\n",
      "                        'test_size': 294,\n",
      "                        'train_mean_mae': 0.33308003012562476,\n",
      "                        'train_mean_mae_folds': np.float64(1.5141649201924878),\n",
      "                        'train_size': 1174,\n",
      "                        '{modelFS_desc}': 'None',\n",
      "                        '{model_desc}': 'LinearRegression()'}}}}\n",
      "-------\n",
      "Settings:\n",
      "\n",
      "Database - Audio_features\n",
      "Corpus - merged_data\n",
      "Group ID - message_id\n",
      "Feature table(s) - feat$combined_audio$merged_data$message_id\n",
      "Outcome table - merged_data\n",
      "Outcome(s) - CEL_Total\n",
      "-------\n",
      "Interface Runtime: 0.16 seconds\n",
      "DLATK exits with success! A good day indeed  ¯\\_(ツ)_/¯.\n"
     ]
    }
   ],
   "source": [
    "!python /home/karthik9/TheDlatk/dlatk/dlatkInterface.py -d Audio_features -t merged_data -c message_id \\\n",
    "-f 'feat$combined_audio$merged_data$message_id' \\\n",
    "    --outcome_table merged_data  --group_freq_thresh 0 \\\n",
    "    --outcomes CEL_Total  \\\n",
    "    --nfold_test_regression --model extratrees --fold_column fold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Warning: Cannot import langid (cannot use addLanguageFilterTable)\n",
      "TopicExtractor: gensim Mallet wrapper unavailable, using Mallet directly.\n",
      "\n",
      "-----\n",
      "DLATK Interface Initiated: 2025-03-18 04:51:49\n",
      "-----\n",
      "Loading Outcomes and Getting Groups for: {'CEL_Total'}\n",
      "    ***explicit fold labels specified, not splitting again***\n",
      "[number of groups: 1468 (5 Folds)]\n",
      "\n",
      "\n",
      "|COMBO: ()|\n",
      "===========\n",
      "\n",
      "= CEL_Total (w/ lang.)=\n",
      "-----------------------\n",
      "Fold 0 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1175    Test size: 293]\n",
      " X[0]: (N, features): (1175, 3)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1175, 3)\n",
      "![COMBINED FEATS] number of features is small enough (feats: 3, observations: 1175), backing off to: 'linear'!\n",
      "[COMBINED FEATS: Training regression model: linear]\n",
      "model: LinearRegression() \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (293, 3)\n",
      "[PREDICT] regressor: LinearRegression()\n",
      "settings:  [('fit_intercept', True), ('copy_X', True), ('n_jobs', None), ('positive', False), ('n_features_in_', 3), ('rank_', 3), ('intercept_', np.float64(2.6085106382978767))]\n",
      "  *FOLD R^2: 0.0833 (MSE: 2.6218; MAE: 1.2581; mean train mae: 1.3558)\n",
      "Fold 1 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1175    Test size: 293]\n",
      " X[0]: (N, features): (1175, 3)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1175, 3)\n",
      "![COMBINED FEATS] number of features is small enough (feats: 3, observations: 1175), backing off to: 'linear'!\n",
      "[COMBINED FEATS: Training regression model: linear]\n",
      "model: LinearRegression() \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (293, 3)\n",
      "[PREDICT] regressor: LinearRegression()\n",
      "settings:  [('fit_intercept', True), ('copy_X', True), ('n_jobs', None), ('positive', False), ('n_features_in_', 3), ('rank_', 3), ('intercept_', np.float64(2.5838297872340448))]\n",
      "  *FOLD R^2: 0.1121 (MSE: 4.1122; MAE: 1.5317; mean train mae: 1.6470)\n",
      "Fold 2 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1174    Test size: 294]\n",
      " X[0]: (N, features): (1174, 3)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1174, 3)\n",
      "![COMBINED FEATS] number of features is small enough (feats: 3, observations: 1174), backing off to: 'linear'!\n",
      "[COMBINED FEATS: Training regression model: linear]\n",
      "model: LinearRegression() \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (294, 3)\n",
      "[PREDICT] regressor: LinearRegression()\n",
      "settings:  [('fit_intercept', True), ('copy_X', True), ('n_jobs', None), ('positive', False), ('n_features_in_', 3), ('rank_', 3), ('intercept_', np.float64(2.477001703577518))]\n",
      "  *FOLD R^2: -0.0287 (MSE: 4.4908; MAE: 1.5295; mean train mae: 1.5240)\n",
      "Fold 3 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1174    Test size: 294]\n",
      " X[0]: (N, features): (1174, 3)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1174, 3)\n",
      "![COMBINED FEATS] number of features is small enough (feats: 3, observations: 1174), backing off to: 'linear'!\n",
      "[COMBINED FEATS: Training regression model: linear]\n",
      "model: LinearRegression() \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (294, 3)\n",
      "[PREDICT] regressor: LinearRegression()\n",
      "settings:  [('fit_intercept', True), ('copy_X', True), ('n_jobs', None), ('positive', False), ('n_features_in_', 3), ('rank_', 3), ('intercept_', np.float64(2.597103918228283))]\n",
      "  *FOLD R^2: 0.0872 (MSE: 4.4938; MAE: 1.5919; mean train mae: 1.7162)\n",
      "Fold 4 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1174    Test size: 294]\n",
      " X[0]: (N, features): (1174, 3)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1174, 3)\n",
      "![COMBINED FEATS] number of features is small enough (feats: 3, observations: 1174), backing off to: 'linear'!\n",
      "[COMBINED FEATS: Training regression model: linear]\n",
      "model: LinearRegression() \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (294, 3)\n",
      "[PREDICT] regressor: LinearRegression()\n",
      "settings:  [('fit_intercept', True), ('copy_X', True), ('n_jobs', None), ('positive', False), ('n_features_in_', 3), ('rank_', 3), ('intercept_', np.float64(2.6013628620102245))]\n",
      "  *FOLD R^2: 0.0739 (MSE: 2.9393; MAE: 1.2893; mean train mae: 1.3278)\n",
      "*Overall R^2:          0.0738\n",
      "*Overall FOLDS R^2:    0.0655 (+- 0.0218)\n",
      "*R (sqrt R^2):         0.2716\n",
      "*Pearson r:            0.2732 (p = 0.00000)\n",
      "*Folds Pearson r:      0.2905 (p = 0.00021)\n",
      "*Spearman rho:         0.2945 (p = 0.00000)\n",
      "*Mean Squared Error:   3.7321\n",
      "*Mean Absolute Error:  1.4402\n",
      "*Train_Mean MAE:       0.4719\n",
      "\n",
      "[TEST COMPLETE]\n",
      "\n",
      "{'CEL_Total': {(): {1: {'N': 1468,\n",
      "                        'R': np.float64(0.271608845444406),\n",
      "                        'R2': 0.07377136492364322,\n",
      "                        'R2_folds': np.float64(0.06554537242067886),\n",
      "                        'mae': 1.4401689446761416,\n",
      "                        'mae_folds': np.float64(1.4401073733381256),\n",
      "                        'mse': 3.7320795995583023,\n",
      "                        'mse_folds': np.float64(3.731582899357953),\n",
      "                        'num_features': 3,\n",
      "                        'r': np.float64(0.27317214245280724),\n",
      "                        'r_folds': np.float64(0.2905255713716002),\n",
      "                        'r_p': np.float64(1.5501347849246927e-26),\n",
      "                        'r_p_folds': np.float64(0.00021078878347314126),\n",
      "                        'rho': np.float64(0.2944840847749223),\n",
      "                        'rho_folds': np.float64(0.301793176702742),\n",
      "                        'rho_p': np.float64(9.312436811791522e-31),\n",
      "                        'rho_p_folds': np.float64(0.00013535135734309562),\n",
      "                        'se_R2_folds': np.float64(0.021810797479482936),\n",
      "                        'se_mae_folds': np.float64(0.061736271703542976),\n",
      "                        'se_mse_folds': np.float64(0.35561558391996345),\n",
      "                        'se_r_folds': np.float64(0.02362944063306652),\n",
      "                        'se_r_p_folds': np.float64(0.0001884692567724647),\n",
      "                        'se_rho_folds': np.float64(0.02560295053846349),\n",
      "                        'se_rho_p_folds': np.float64(0.00012090210054982662),\n",
      "                        'se_train_mean_mae_folds': np.float64(0.06881004248493686),\n",
      "                        'test_size': 294,\n",
      "                        'train_mean_mae': 0.47188833099552613,\n",
      "                        'train_mean_mae_folds': np.float64(1.5141649201924878),\n",
      "                        'train_size': 1174,\n",
      "                        '{modelFS_desc}': 'None',\n",
      "                        '{model_desc}': 'LinearRegression()'}}}}\n",
      "-------\n",
      "Settings:\n",
      "\n",
      "Database - Audio_features\n",
      "Corpus - merged_data\n",
      "Group ID - message_id\n",
      "Feature table(s) - feat$combined_text$merged_data$message_id\n",
      "Outcome table - merged_data\n",
      "Outcome(s) - CEL_Total\n",
      "-------\n",
      "Interface Runtime: 0.15 seconds\n",
      "DLATK exits with success! A good day indeed  ¯\\_(ツ)_/¯.\n"
     ]
    }
   ],
   "source": [
    "!python /home/karthik9/TheDlatk/dlatk/dlatkInterface.py -d Audio_features -t merged_data -c message_id \\\n",
    "-f 'feat$combined_text$merged_data$message_id' \\\n",
    "    --outcome_table merged_data  --group_freq_thresh 0 \\\n",
    "    --outcomes CEL_Total  \\\n",
    "    --nfold_test_regression --model extratrees --fold_column fold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Warning: Cannot import langid (cannot use addLanguageFilterTable)\n",
      "TopicExtractor: gensim Mallet wrapper unavailable, using Mallet directly.\n",
      "\n",
      "-----\n",
      "DLATK Interface Initiated: 2025-03-18 04:51:56\n",
      "-----\n",
      "Loading Outcomes and Getting Groups for: {'CEL_Total'}\n",
      "    ***explicit fold labels specified, not splitting again***\n",
      "[number of groups: 1468 (5 Folds)]\n",
      "\n",
      "\n",
      "|COMBO: ()|\n",
      "===========\n",
      "\n",
      "= CEL_Total (w/ lang.)=\n",
      "-----------------------\n",
      "Fold 0 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1175    Test size: 293]\n",
      " X[0]: (N, features): (1175, 6)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1175, 6)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (293, 6)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 6), ('_n_samples', 1175), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: -0.0301 (MSE: 2.9461; MAE: 1.3552; mean train mae: 1.3558)\n",
      "Fold 1 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1175    Test size: 293]\n",
      " X[0]: (N, features): (1175, 6)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1175, 6)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (293, 6)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 6), ('_n_samples', 1175), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: 0.0784 (MSE: 4.2679; MAE: 1.5635; mean train mae: 1.6470)\n",
      "Fold 2 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1174    Test size: 294]\n",
      " X[0]: (N, features): (1174, 6)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1174, 6)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (294, 6)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 6), ('_n_samples', 1174), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: -0.0220 (MSE: 4.4617; MAE: 1.5519; mean train mae: 1.5240)\n",
      "Fold 3 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1174    Test size: 294]\n",
      " X[0]: (N, features): (1174, 6)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1174, 6)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (294, 6)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 6), ('_n_samples', 1174), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: 0.1106 (MSE: 4.3786; MAE: 1.5917; mean train mae: 1.7162)\n",
      "Fold 4 \n",
      "   (feature group: 0): [Initial size: 1468]\n",
      " [Train size: 1174    Test size: 294]\n",
      " X[0]: (N, features): (1174, 6)\n",
      "  [Applying StandardScaler to X[0]: StandardScaler()]\n",
      "[COMBINED FEATS (from multiX)] Combined size: (1174, 6)\n",
      "[COMBINED FEATS: Training regression model: extratrees]\n",
      "model: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42) \n",
      "[PREDICT] applying *existing* standard scaler to X[0]: StandardScaler()\n",
      "[PREDICT] combined X shape: (294, 6)\n",
      "[PREDICT] regressor: ExtraTreesRegressor(n_estimators=1200, n_jobs=12, random_state=42)\n",
      "settings:  [('estimator', ExtraTreeRegressor()), ('n_estimators', 1200), ('bootstrap', False), ('oob_score', False), ('n_jobs', 12), ('random_state', 42), ('verbose', 0), ('warm_start', False), ('class_weight', None), ('max_samples', None), ('max_depth', None), ('min_samples_split', 2), ('min_samples_leaf', 1), ('min_weight_fraction_leaf', 0.0), ('max_features', 1.0), ('max_leaf_nodes', None), ('min_impurity_decrease', 0.0), ('ccp_alpha', 0.0), ('monotonic_cst', None), ('n_features_in_', 6), ('_n_samples', 1174), ('n_outputs_', 1), ('_n_samples_bootstrap', None), ('estimator_', ExtraTreeRegressor())]\n",
      "  *FOLD R^2: -0.0593 (MSE: 3.3620; MAE: 1.3847; mean train mae: 1.3278)\n",
      "*Overall R^2:          0.0362\n",
      "*Overall FOLDS R^2:    0.0155 (+- 0.0297)\n",
      "*R (sqrt R^2):         0.1902\n",
      "*Pearson r:            0.2571 (p = 0.00000)\n",
      "*Folds Pearson r:      0.2758 (p = 0.00002)\n",
      "*Spearman rho:         0.2864 (p = 0.00000)\n",
      "*Mean Squared Error:   3.8836\n",
      "*Mean Absolute Error:  1.4894\n",
      "*Train_Mean MAE:       0.6714\n",
      "\n",
      "[TEST COMPLETE]\n",
      "\n",
      "{'CEL_Total': {(): {1: {'N': 1468,\n",
      "                        'R': np.float64(0.19015561749770374),\n",
      "                        'R2': 0.03615915886593302,\n",
      "                        'R2_folds': np.float64(0.015520176704641741),\n",
      "                        'mae': 1.4894442552225249,\n",
      "                        'mae_folds': np.float64(1.489403316616749),\n",
      "                        'mse': 3.8836315399825914,\n",
      "                        'mse_folds': np.float64(3.8832551544816822),\n",
      "                        'num_features': 6,\n",
      "                        'r': np.float64(0.257138064626365),\n",
      "                        'r_folds': np.float64(0.2757699974630063),\n",
      "                        'r_p': np.float64(1.342496438954408e-23),\n",
      "                        'r_p_folds': np.float64(2.0259522658598117e-05),\n",
      "                        'rho': np.float64(0.2863518392171148),\n",
      "                        'rho_folds': np.float64(0.2944554275610551),\n",
      "                        'rho_p': np.float64(4.1999397617033615e-29),\n",
      "                        'rho_p_folds': np.float64(1.757315231676068e-05),\n",
      "                        'se_R2_folds': np.float64(0.029727544136041072),\n",
      "                        'se_mae_folds': np.float64(0.044189385813423764),\n",
      "                        'se_mse_folds': np.float64(0.2740678028010576),\n",
      "                        'se_r_folds': np.float64(0.017431137441821416),\n",
      "                        'se_r_p_folds': np.float64(1.4808088817972928e-05),\n",
      "                        'se_rho_folds': np.float64(0.02153398114829968),\n",
      "                        'se_rho_p_folds': np.float64(1.5402990827941903e-05),\n",
      "                        'se_train_mean_mae_folds': np.float64(0.06881004248493683),\n",
      "                        'test_size': 294,\n",
      "                        'train_mean_mae': 0.6713833426758433,\n",
      "                        'train_mean_mae_folds': np.float64(1.5141649201924878),\n",
      "                        'train_size': 1174,\n",
      "                        '{modelFS_desc}': 'None',\n",
      "                        '{model_desc}': 'ExtraTreesRegressor(n_estimators=1200, '\n",
      "                                        'n_jobs=12, random_state=42)'}}}}\n",
      "-------\n",
      "Settings:\n",
      "\n",
      "Database - Audio_features\n",
      "Corpus - merged_data\n",
      "Group ID - message_id\n",
      "Feature table(s) - feat$combined$merged_data$message_id\n",
      "Outcome table - merged_data\n",
      "Outcome(s) - CEL_Total\n",
      "-------\n",
      "Interface Runtime: 10.17 seconds\n",
      "DLATK exits with success! A good day indeed  ¯\\_(ツ)_/¯.\n"
     ]
    }
   ],
   "source": [
    "!python /home/karthik9/TheDlatk/dlatk/dlatkInterface.py -d Audio_features -t merged_data -c message_id \\\n",
    "-f 'feat$combined$merged_data$message_id' \\\n",
    "    --outcome_table merged_data  --group_freq_thresh 0 \\\n",
    "    --outcomes CEL_Total  \\\n",
    "    --nfold_test_regression --model extratrees --fold_column fold "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
